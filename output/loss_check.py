# Author: Haruko386
# Last modified: 2025-10-16
# If you don't have or can't use wandb, you can paste the training log in terminal
# and run `python loss_check.py`, you will see the loss change with time

import matplotlib.pyplot as plt
import re

# 从日志中提取数据
log_data = """
 2025-10-07 09:34:51,412 - INFO -marigold_trainer.py - train >> iter 16475 (epoch  8): loss=0.05925
 2025-10-07 09:35:06,743 - INFO -marigold_trainer.py - train >> iter 16476 (epoch  8): loss=0.06189
 2025-10-07 09:35:21,417 - INFO -marigold_trainer.py - train >> iter 16477 (epoch  8): loss=0.06168
 2025-10-07 09:35:37,376 - INFO -marigold_trainer.py - train >> iter 16478 (epoch  8): loss=0.05829
 2025-10-07 09:35:52,691 - INFO -marigold_trainer.py - train >> iter 16479 (epoch  8): loss=0.06787
 2025-10-07 09:36:09,979 - INFO -marigold_trainer.py - train >> iter 16480 (epoch  8): loss=0.05682
 2025-10-07 09:36:25,323 - INFO -marigold_trainer.py - train >> iter 16481 (epoch  8): loss=0.06186
 2025-10-07 09:36:41,312 - INFO -marigold_trainer.py - train >> iter 16482 (epoch  8): loss=0.06574
 2025-10-07 09:36:57,958 - INFO -marigold_trainer.py - train >> iter 16483 (epoch  8): loss=0.06547
 2025-10-07 09:37:12,641 - INFO -marigold_trainer.py - train >> iter 16484 (epoch  8): loss=0.06518
 2025-10-07 09:37:27,948 - INFO -marigold_trainer.py - train >> iter 16485 (epoch  8): loss=0.04755
 2025-10-07 09:37:42,633 - INFO -marigold_trainer.py - train >> iter 16486 (epoch  8): loss=0.05288
 2025-10-07 09:37:59,702 - INFO -marigold_trainer.py - train >> iter 16487 (epoch  8): loss=0.05734
 2025-10-07 09:38:14,588 - INFO -marigold_trainer.py - train >> iter 16488 (epoch  8): loss=0.04565
 2025-10-07 09:38:29,242 - INFO -marigold_trainer.py - train >> iter 16489 (epoch  8): loss=0.06240
 2025-10-07 09:38:45,202 - INFO -marigold_trainer.py - train >> iter 16490 (epoch  8): loss=0.06240
 2025-10-07 09:39:00,537 - INFO -marigold_trainer.py - train >> iter 16491 (epoch  8): loss=0.06122
 2025-10-07 09:39:17,823 - INFO -marigold_trainer.py - train >> iter 16492 (epoch  8): loss=0.05814
 2025-10-07 09:39:33,154 - INFO -marigold_trainer.py - train >> iter 16493 (epoch  8): loss=0.05731
 2025-10-07 09:39:48,477 - INFO -marigold_trainer.py - train >> iter 16494 (epoch  8): loss=0.05306
 2025-10-07 09:40:03,804 - INFO -marigold_trainer.py - train >> iter 16495 (epoch  8): loss=0.06607
 2025-10-07 09:40:19,789 - INFO -marigold_trainer.py - train >> iter 16496 (epoch  8): loss=0.06525
 2025-10-07 09:40:36,221 - INFO -marigold_trainer.py - train >> iter 16497 (epoch  8): loss=0.05522
 2025-10-07 09:40:51,755 - INFO -marigold_trainer.py - train >> iter 16498 (epoch  8): loss=0.05489
 2025-10-07 09:41:07,089 - INFO -marigold_trainer.py - train >> iter 16499 (epoch  8): loss=0.04897
 2025-10-07 09:41:23,071 - INFO -marigold_trainer.py - train >> iter 16500 (epoch  8): loss=0.04987
 2025-10-07 09:41:23,072 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: output/train_marigold/checkpoint/latest
 2025-10-07 09:41:23,072 - DEBUG -marigold_trainer.py - save_checkpoint >> Old checkpoint is backed up at: output/train_marigold/checkpoint/_old_latest
 2025-10-07 09:41:26,467 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: output/train_marigold/checkpoint/latest/unet
 2025-10-07 09:41:32,891 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: output/train_marigold/checkpoint/latest/trainer.ckpt
 2025-10-07 09:41:33,682 - DEBUG -marigold_trainer.py - save_checkpoint >> Old checkpoint backup is removed.
 2025-10-07 09:41:48,056 - INFO -marigold_trainer.py - train >> iter 16501 (epoch  8): loss=0.05568
 2025-10-07 09:42:04,024 - INFO -marigold_trainer.py - train >> iter 16502 (epoch  8): loss=0.05816
 2025-10-07 09:42:20,657 - INFO -marigold_trainer.py - train >> iter 16503 (epoch  8): loss=0.05859
 2025-10-07 09:42:35,985 - INFO -marigold_trainer.py - train >> iter 16504 (epoch  8): loss=0.05718
 2025-10-07 09:42:52,618 - INFO -marigold_trainer.py - train >> iter 16505 (epoch  8): loss=0.06944
 2025-10-07 09:43:08,603 - INFO -marigold_trainer.py - train >> iter 16506 (epoch  8): loss=0.05451
 2025-10-07 09:43:23,284 - INFO -marigold_trainer.py - train >> iter 16507 (epoch  8): loss=0.04918
 2025-10-07 09:43:39,237 - INFO -marigold_trainer.py - train >> iter 16508 (epoch  8): loss=0.05027
 2025-10-07 09:43:55,011 - INFO -marigold_trainer.py - train >> iter 16509 (epoch  8): loss=0.05789
 2025-10-07 09:44:11,206 - INFO -marigold_trainer.py - train >> iter 16510 (epoch  8): loss=0.05702
 2025-10-07 09:44:26,531 - INFO -marigold_trainer.py - train >> iter 16511 (epoch  8): loss=0.06066
 2025-10-07 09:44:41,860 - INFO -marigold_trainer.py - train >> iter 16512 (epoch  8): loss=0.05349
 2025-10-07 09:44:57,836 - INFO -marigold_trainer.py - train >> iter 16513 (epoch  8): loss=0.05848
 2025-10-07 09:45:13,166 - INFO -marigold_trainer.py - train >> iter 16514 (epoch  8): loss=0.05585
 2025-10-07 09:45:29,807 - INFO -marigold_trainer.py - train >> iter 16515 (epoch  8): loss=0.06600
 2025-10-07 09:45:45,786 - INFO -marigold_trainer.py - train >> iter 16516 (epoch  8): loss=0.07808
 2025-10-07 09:46:01,113 - INFO -marigold_trainer.py - train >> iter 16517 (epoch  8): loss=0.06154
 2025-10-07 09:46:17,875 - INFO -marigold_trainer.py - train >> iter 16518 (epoch  8): loss=0.07339
 2025-10-07 09:46:33,197 - INFO -marigold_trainer.py - train >> iter 16519 (epoch  8): loss=0.05923
 2025-10-07 09:46:48,974 - INFO -marigold_trainer.py - train >> iter 16520 (epoch  8): loss=0.05986
 2025-10-07 09:47:05,149 - INFO -marigold_trainer.py - train >> iter 16521 (epoch  8): loss=0.05000
 2025-10-07 09:47:20,463 - INFO -marigold_trainer.py - train >> iter 16522 (epoch  8): loss=0.05726
 2025-10-07 09:47:38,387 - INFO -marigold_trainer.py - train >> iter 16523 (epoch  8): loss=0.05159
 2025-10-07 09:47:54,807 - INFO -marigold_trainer.py - train >> iter 16524 (epoch  8): loss=0.05415
 2025-10-07 09:48:09,674 - INFO -marigold_trainer.py - train >> iter 16525 (epoch  8): loss=0.06473
 2025-10-07 09:48:24,974 - INFO -marigold_trainer.py - train >> iter 16526 (epoch  8): loss=0.06132
 2025-10-07 09:48:39,651 - INFO -marigold_trainer.py - train >> iter 16527 (epoch  8): loss=0.05797
 2025-10-07 09:48:55,602 - INFO -marigold_trainer.py - train >> iter 16528 (epoch  8): loss=0.05459
 2025-10-07 09:49:12,235 - INFO -marigold_trainer.py - train >> iter 16529 (epoch  8): loss=0.05830
 2025-10-07 09:49:27,571 - INFO -marigold_trainer.py - train >> iter 16530 (epoch  8): loss=0.05909
 2025-10-07 09:49:42,901 - INFO -marigold_trainer.py - train >> iter 16531 (epoch  8): loss=0.05700
 2025-10-07 09:49:59,529 - INFO -marigold_trainer.py - train >> iter 16532 (epoch  8): loss=0.06621
 2025-10-07 09:50:16,160 - INFO -marigold_trainer.py - train >> iter 16533 (epoch  8): loss=0.05507
 2025-10-07 09:50:31,482 - INFO -marigold_trainer.py - train >> iter 16534 (epoch  8): loss=0.05388
 2025-10-07 09:50:47,263 - INFO -marigold_trainer.py - train >> iter 16535 (epoch  8): loss=0.04976
 2025-10-07 09:51:04,744 - INFO -marigold_trainer.py - train >> iter 16536 (epoch  8): loss=0.05527
 2025-10-07 09:51:21,370 - INFO -marigold_trainer.py - train >> iter 16537 (epoch  8): loss=0.05041
 2025-10-07 09:51:37,806 - INFO -marigold_trainer.py - train >> iter 16538 (epoch  8): loss=0.05397
 2025-10-07 09:51:53,459 - INFO -marigold_trainer.py - train >> iter 16539 (epoch  8): loss=0.06147
 2025-10-07 09:52:08,635 - INFO -marigold_trainer.py - train >> iter 16540 (epoch  8): loss=0.05351
 2025-10-07 09:52:23,760 - INFO -marigold_trainer.py - train >> iter 16541 (epoch  8): loss=0.05639
 2025-10-07 09:52:39,269 - INFO -marigold_trainer.py - train >> iter 16542 (epoch  8): loss=0.05096
 2025-10-07 09:52:55,898 - INFO -marigold_trainer.py - train >> iter 16543 (epoch  8): loss=0.05368
 2025-10-07 09:53:11,226 - INFO -marigold_trainer.py - train >> iter 16544 (epoch  8): loss=0.05140
 2025-10-07 09:53:25,891 - INFO -marigold_trainer.py - train >> iter 16545 (epoch  8): loss=0.06095
 2025-10-07 09:53:41,183 - INFO -marigold_trainer.py - train >> iter 16546 (epoch  8): loss=0.05640
 2025-10-07 09:53:57,136 - INFO -marigold_trainer.py - train >> iter 16547 (epoch  8): loss=0.05881
 2025-10-07 09:54:14,213 - INFO -marigold_trainer.py - train >> iter 16548 (epoch  8): loss=0.04646
 2025-10-07 09:54:29,533 - INFO -marigold_trainer.py - train >> iter 16549 (epoch  8): loss=0.05070
 2025-10-07 09:54:45,709 - INFO -marigold_trainer.py - train >> iter 16550 (epoch  8): loss=0.05612
 2025-10-07 09:55:01,028 - INFO -marigold_trainer.py - train >> iter 16551 (epoch  8): loss=0.05272
 2025-10-07 09:55:17,666 - INFO -marigold_trainer.py - train >> iter 16552 (epoch  8): loss=0.05563
 2025-10-07 09:55:33,647 - INFO -marigold_trainer.py - train >> iter 16553 (epoch  8): loss=0.05762
 2025-10-07 09:55:48,970 - INFO -marigold_trainer.py - train >> iter 16554 (epoch  8): loss=0.06153
 2025-10-07 09:56:04,299 - INFO -marigold_trainer.py - train >> iter 16555 (epoch  8): loss=0.05901
 2025-10-07 09:56:20,267 - INFO -marigold_trainer.py - train >> iter 16556 (epoch  8): loss=0.06191
 2025-10-07 09:56:38,184 - INFO -marigold_trainer.py - train >> iter 16557 (epoch  8): loss=0.06364
 2025-10-07 09:56:55,268 - INFO -marigold_trainer.py - train >> iter 16558 (epoch  8): loss=0.05378
 2025-10-07 09:57:11,453 - INFO -marigold_trainer.py - train >> iter 16559 (epoch  8): loss=0.06005
 2025-10-07 09:57:28,079 - INFO -marigold_trainer.py - train >> iter 16560 (epoch  8): loss=0.05307
 2025-10-07 09:57:44,050 - INFO -marigold_trainer.py - train >> iter 16561 (epoch  8): loss=0.05598
 2025-10-07 09:57:58,725 - INFO -marigold_trainer.py - train >> iter 16562 (epoch  8): loss=0.05450
 2025-10-07 09:58:14,029 - INFO -marigold_trainer.py - train >> iter 16563 (epoch  8): loss=0.06119
 2025-10-07 09:58:28,694 - INFO -marigold_trainer.py - train >> iter 16564 (epoch  8): loss=0.05730
 2025-10-07 09:58:43,342 - INFO -marigold_trainer.py - train >> iter 16565 (epoch  8): loss=0.05152
 2025-10-07 09:58:59,294 - INFO -marigold_trainer.py - train >> iter 16566 (epoch  8): loss=0.06482
 2025-10-07 09:59:15,731 - INFO -marigold_trainer.py - train >> iter 16567 (epoch  8): loss=0.05735
 2025-10-07 09:59:30,601 - INFO -marigold_trainer.py - train >> iter 16568 (epoch  8): loss=0.05861
 2025-10-07 09:59:45,900 - INFO -marigold_trainer.py - train >> iter 16569 (epoch  8): loss=0.05837
 2025-10-07 10:00:01,860 - INFO -marigold_trainer.py - train >> iter 16570 (epoch  8): loss=0.06867
 2025-10-07 10:00:19,161 - INFO -marigold_trainer.py - train >> iter 16571 (epoch  8): loss=0.06688
 2025-10-07 10:00:33,935 - INFO -marigold_trainer.py - train >> iter 16572 (epoch  8): loss=0.05566
 2025-10-07 10:00:50,786 - INFO -marigold_trainer.py - train >> iter 16573 (epoch  8): loss=0.05293
 2025-10-07 10:01:07,052 - INFO -marigold_trainer.py - train >> iter 16574 (epoch  8): loss=0.05681
 2025-10-07 10:01:21,967 - INFO -marigold_trainer.py - train >> iter 16575 (epoch  8): loss=0.06006
 2025-10-07 10:01:38,175 - INFO -marigold_trainer.py - train >> iter 16576 (epoch  8): loss=0.05599
 2025-10-07 10:01:53,071 - INFO -marigold_trainer.py - train >> iter 16577 (epoch  8): loss=0.05673
 2025-10-07 10:02:08,612 - INFO -marigold_trainer.py - train >> iter 16578 (epoch  8): loss=0.06524
 2025-10-07 10:02:24,167 - INFO -marigold_trainer.py - train >> iter 16579 (epoch  8): loss=0.06282
 2025-10-07 10:02:40,142 - INFO -marigold_trainer.py - train >> iter 16580 (epoch  8): loss=0.06043
 2025-10-07 10:02:54,823 - INFO -marigold_trainer.py - train >> iter 16581 (epoch  8): loss=0.06031
 2025-10-07 10:03:10,594 - INFO -marigold_trainer.py - train >> iter 16582 (epoch  8): loss=0.06232
 2025-10-07 10:03:27,236 - INFO -marigold_trainer.py - train >> iter 16583 (epoch  8): loss=0.06352
 2025-10-07 10:03:42,769 - INFO -marigold_trainer.py - train >> iter 16584 (epoch  8): loss=0.06193
 2025-10-07 10:03:58,557 - INFO -marigold_trainer.py - train >> iter 16585 (epoch  8): loss=0.06329
 2025-10-07 10:04:14,086 - INFO -marigold_trainer.py - train >> iter 16586 (epoch  8): loss=0.05690
 2025-10-07 10:04:31,366 - INFO -marigold_trainer.py - train >> iter 16587 (epoch  8): loss=0.06765
 2025-10-07 10:04:46,043 - INFO -marigold_trainer.py - train >> iter 16588 (epoch  8): loss=0.06430
 2025-10-07 10:05:01,805 - INFO -marigold_trainer.py - train >> iter 16589 (epoch  8): loss=0.05218
 2025-10-07 10:05:17,326 - INFO -marigold_trainer.py - train >> iter 16590 (epoch  8): loss=0.05566
 2025-10-07 10:05:33,310 - INFO -marigold_trainer.py - train >> iter 16591 (epoch  8): loss=0.05818
 2025-10-07 10:05:49,943 - INFO -marigold_trainer.py - train >> iter 16592 (epoch  8): loss=0.05150
 2025-10-07 10:06:04,615 - INFO -marigold_trainer.py - train >> iter 16593 (epoch  8): loss=0.05568
 2025-10-07 10:06:20,582 - INFO -marigold_trainer.py - train >> iter 16594 (epoch  8): loss=0.06145
 2025-10-07 10:06:36,570 - INFO -marigold_trainer.py - train >> iter 16595 (epoch  8): loss=0.06271
 2025-10-07 10:06:51,242 - INFO -marigold_trainer.py - train >> iter 16596 (epoch  8): loss=0.05484
 2025-10-07 10:07:06,551 - INFO -marigold_trainer.py - train >> iter 16597 (epoch  8): loss=0.05327
 2025-10-07 10:07:22,327 - INFO -marigold_trainer.py - train >> iter 16598 (epoch  8): loss=0.06073
 2025-10-07 10:07:38,497 - INFO -marigold_trainer.py - train >> iter 16599 (epoch  8): loss=0.05850
 2025-10-07 10:07:53,169 - INFO -marigold_trainer.py - train >> iter 16600 (epoch  8): loss=0.05520
 2025-10-07 10:08:09,792 - INFO -marigold_trainer.py - train >> iter 16601 (epoch  8): loss=0.05682
 2025-10-07 10:08:25,136 - INFO -marigold_trainer.py - train >> iter 16602 (epoch  8): loss=0.05647
 2025-10-07 10:08:39,809 - INFO -marigold_trainer.py - train >> iter 16603 (epoch  8): loss=0.06869
 2025-10-07 10:08:55,580 - INFO -marigold_trainer.py - train >> iter 16604 (epoch  8): loss=0.05932
 2025-10-07 10:09:11,113 - INFO -marigold_trainer.py - train >> iter 16605 (epoch  8): loss=0.06083
 2025-10-07 10:09:28,414 - INFO -marigold_trainer.py - train >> iter 16606 (epoch  8): loss=0.05955
 2025-10-07 10:09:44,393 - INFO -marigold_trainer.py - train >> iter 16607 (epoch  8): loss=0.06122
 2025-10-07 10:09:59,714 - INFO -marigold_trainer.py - train >> iter 16608 (epoch  8): loss=0.05702
 2025-10-07 10:10:15,492 - INFO -marigold_trainer.py - train >> iter 16609 (epoch  8): loss=0.05827
 2025-10-07 10:10:31,680 - INFO -marigold_trainer.py - train >> iter 16610 (epoch  8): loss=0.05662
 2025-10-07 10:10:46,351 - INFO -marigold_trainer.py - train >> iter 16611 (epoch  8): loss=0.05062
 2025-10-07 10:11:01,008 - INFO -marigold_trainer.py - train >> iter 16612 (epoch  8): loss=0.05622
 2025-10-07 10:11:15,666 - INFO -marigold_trainer.py - train >> iter 16613 (epoch  8): loss=0.06142
 2025-10-07 10:11:32,285 - INFO -marigold_trainer.py - train >> iter 16614 (epoch  8): loss=0.05411
 2025-10-07 10:11:47,608 - INFO -marigold_trainer.py - train >> iter 16615 (epoch  8): loss=0.05863
 2025-10-07 10:12:02,275 - INFO -marigold_trainer.py - train >> iter 16616 (epoch  8): loss=0.05674
 2025-10-07 10:12:16,928 - INFO -marigold_trainer.py - train >> iter 16617 (epoch  8): loss=0.06301
 2025-10-07 10:12:32,241 - INFO -marigold_trainer.py - train >> iter 16618 (epoch  8): loss=0.05781
 2025-10-07 10:12:47,566 - INFO -marigold_trainer.py - train >> iter 16619 (epoch  8): loss=0.05586
 2025-10-07 10:13:03,547 - INFO -marigold_trainer.py - train >> iter 16620 (epoch  8): loss=0.05942
 2025-10-07 10:13:18,216 - INFO -marigold_trainer.py - train >> iter 16621 (epoch  8): loss=0.05274
 2025-10-07 10:13:34,839 - INFO -marigold_trainer.py - train >> iter 16622 (epoch  8): loss=0.06382
 2025-10-07 10:13:50,810 - INFO -marigold_trainer.py - train >> iter 16623 (epoch  8): loss=0.05274
 2025-10-07 10:14:07,444 - INFO -marigold_trainer.py - train >> iter 16624 (epoch  8): loss=0.06849
 2025-10-07 10:14:22,778 - INFO -marigold_trainer.py - train >> iter 16625 (epoch  8): loss=0.05779
 2025-10-07 10:14:38,748 - INFO -marigold_trainer.py - train >> iter 16626 (epoch  8): loss=0.05988
 2025-10-07 10:14:53,431 - INFO -marigold_trainer.py - train >> iter 16627 (epoch  8): loss=0.05541
 2025-10-07 10:15:08,085 - INFO -marigold_trainer.py - train >> iter 16628 (epoch  8): loss=0.05714
 2025-10-07 10:15:23,851 - INFO -marigold_trainer.py - train >> iter 16629 (epoch  8): loss=0.05806
 2025-10-07 10:15:40,035 - INFO -marigold_trainer.py - train >> iter 16630 (epoch  8): loss=0.05189
 2025-10-07 10:15:55,355 - INFO -marigold_trainer.py - train >> iter 16631 (epoch  8): loss=0.06162
 2025-10-07 10:16:10,669 - INFO -marigold_trainer.py - train >> iter 16632 (epoch  8): loss=0.05738
 2025-10-07 10:16:25,975 - INFO -marigold_trainer.py - train >> iter 16633 (epoch  8): loss=0.05912
 2025-10-07 10:16:41,955 - INFO -marigold_trainer.py - train >> iter 16634 (epoch  8): loss=0.04929
 2025-10-07 10:16:57,280 - INFO -marigold_trainer.py - train >> iter 16635 (epoch  8): loss=0.05154
 2025-10-07 10:17:13,912 - INFO -marigold_trainer.py - train >> iter 16636 (epoch  8): loss=0.06384
 2025-10-07 10:17:29,406 - INFO -marigold_trainer.py - train >> iter 16637 (epoch  8): loss=0.05301
 2025-10-07 10:17:44,723 - INFO -marigold_trainer.py - train >> iter 16638 (epoch  8): loss=0.05539
 2025-10-07 10:18:00,037 - INFO -marigold_trainer.py - train >> iter 16639 (epoch  8): loss=0.05920
 2025-10-07 10:18:15,467 - INFO -marigold_trainer.py - train >> iter 16640 (epoch  8): loss=0.05546
 2025-10-07 10:18:30,015 - INFO -marigold_trainer.py - train >> iter 16641 (epoch  8): loss=0.05146
 2025-10-07 10:18:45,970 - INFO -marigold_trainer.py - train >> iter 16642 (epoch  8): loss=0.05647
 2025-10-07 10:19:01,279 - INFO -marigold_trainer.py - train >> iter 16643 (epoch  8): loss=0.05860
 2025-10-07 10:19:15,945 - INFO -marigold_trainer.py - train >> iter 16644 (epoch  8): loss=0.05755
 2025-10-07 10:19:31,252 - INFO -marigold_trainer.py - train >> iter 16645 (epoch  8): loss=0.05077
 2025-10-07 10:19:47,876 - INFO -marigold_trainer.py - train >> iter 16646 (epoch  8): loss=0.06158
 2025-10-07 10:20:03,850 - INFO -marigold_trainer.py - train >> iter 16647 (epoch  8): loss=0.06433
 2025-10-07 10:20:19,171 - INFO -marigold_trainer.py - train >> iter 16648 (epoch  8): loss=0.05991
 2025-10-07 10:20:33,841 - INFO -marigold_trainer.py - train >> iter 16649 (epoch  8): loss=0.06392
 2025-10-07 10:20:49,793 - INFO -marigold_trainer.py - train >> iter 16650 (epoch  8): loss=0.05721
 2025-10-07 10:21:04,464 - INFO -marigold_trainer.py - train >> iter 16651 (epoch  8): loss=0.06141
 2025-10-07 10:21:21,075 - INFO -marigold_trainer.py - train >> iter 16652 (epoch  8): loss=0.05899
 2025-10-07 10:21:36,390 - INFO -marigold_trainer.py - train >> iter 16653 (epoch  8): loss=0.05662
 2025-10-07 10:21:51,716 - INFO -marigold_trainer.py - train >> iter 16654 (epoch  8): loss=0.05947
 2025-10-07 10:22:06,383 - INFO -marigold_trainer.py - train >> iter 16655 (epoch  8): loss=0.05429
 2025-10-07 10:22:22,789 - INFO -marigold_trainer.py - train >> iter 16656 (epoch  8): loss=0.05806
 2025-10-07 10:22:38,318 - INFO -marigold_trainer.py - train >> iter 16657 (epoch  8): loss=0.05488
 2025-10-07 10:22:54,282 - INFO -marigold_trainer.py - train >> iter 16658 (epoch  8): loss=0.05679
 2025-10-07 10:23:09,607 - INFO -marigold_trainer.py - train >> iter 16659 (epoch  8): loss=0.05849
 2025-10-07 10:23:24,281 - INFO -marigold_trainer.py - train >> iter 16660 (epoch  8): loss=0.06128
 2025-10-07 10:23:40,234 - INFO -marigold_trainer.py - train >> iter 16661 (epoch  8): loss=0.05652
 2025-10-07 10:23:55,559 - INFO -marigold_trainer.py - train >> iter 16662 (epoch  8): loss=0.06250
 2025-10-07 10:24:11,341 - INFO -marigold_trainer.py - train >> iter 16663 (epoch  8): loss=0.06100
 2025-10-07 10:24:26,859 - INFO -marigold_trainer.py - train >> iter 16664 (epoch  8): loss=0.04871
 2025-10-07 10:24:41,517 - INFO -marigold_trainer.py - train >> iter 16665 (epoch  8): loss=0.06545
 2025-10-07 10:24:57,925 - INFO -marigold_trainer.py - train >> iter 16666 (epoch  8): loss=0.05838
 2025-10-07 10:25:12,787 - INFO -marigold_trainer.py - train >> iter 16667 (epoch  8): loss=0.04943
 2025-10-07 10:25:29,395 - INFO -marigold_trainer.py - train >> iter 16668 (epoch  8): loss=0.06625
 2025-10-07 10:25:46,483 - INFO -marigold_trainer.py - train >> iter 16669 (epoch  8): loss=0.07010
 2025-10-07 10:26:02,665 - INFO -marigold_trainer.py - train >> iter 16670 (epoch  8): loss=0.05201
 2025-10-07 10:26:17,985 - INFO -marigold_trainer.py - train >> iter 16671 (epoch  8): loss=0.05439
 2025-10-07 10:26:33,744 - INFO -marigold_trainer.py - train >> iter 16672 (epoch  8): loss=0.05939
 2025-10-07 10:26:50,585 - INFO -marigold_trainer.py - train >> iter 16673 (epoch  8): loss=0.05579
 2025-10-07 10:27:06,574 - INFO -marigold_trainer.py - train >> iter 16674 (epoch  8): loss=0.05267
 2025-10-07 10:27:22,554 - INFO -marigold_trainer.py - train >> iter 16675 (epoch  8): loss=0.06549
 2025-10-07 10:27:37,217 - INFO -marigold_trainer.py - train >> iter 16676 (epoch  8): loss=0.05824
 2025-10-07 10:27:52,520 - INFO -marigold_trainer.py - train >> iter 16677 (epoch  8): loss=0.06364
 2025-10-07 10:28:08,501 - INFO -marigold_trainer.py - train >> iter 16678 (epoch  8): loss=0.06187
 2025-10-07 10:28:25,134 - INFO -marigold_trainer.py - train >> iter 16679 (epoch  8): loss=0.06133
 2025-10-07 10:28:40,906 - INFO -marigold_trainer.py - train >> iter 16680 (epoch  8): loss=0.05630
 2025-10-07 10:28:55,786 - INFO -marigold_trainer.py - train >> iter 16681 (epoch  8): loss=0.06202
 2025-10-07 10:29:10,885 - INFO -marigold_trainer.py - train >> iter 16682 (epoch  8): loss=0.05211
 2025-10-07 10:29:25,753 - INFO -marigold_trainer.py - train >> iter 16683 (epoch  8): loss=0.06220
 2025-10-07 10:29:40,403 - INFO -marigold_trainer.py - train >> iter 16684 (epoch  8): loss=0.07133
 2025-10-07 10:29:56,355 - INFO -marigold_trainer.py - train >> iter 16685 (epoch  8): loss=0.05070
 2025-10-07 10:30:12,331 - INFO -marigold_trainer.py - train >> iter 16686 (epoch  8): loss=0.05242
 2025-10-07 10:30:26,998 - INFO -marigold_trainer.py - train >> iter 16687 (epoch  8): loss=0.05758
 2025-10-07 10:30:43,610 - INFO -marigold_trainer.py - train >> iter 16688 (epoch  8): loss=0.05721
 2025-10-07 10:30:58,932 - INFO -marigold_trainer.py - train >> iter 16689 (epoch  8): loss=0.05851
 2025-10-07 10:31:14,264 - INFO -marigold_trainer.py - train >> iter 16690 (epoch  8): loss=0.05661
 2025-10-07 10:31:29,589 - INFO -marigold_trainer.py - train >> iter 16691 (epoch  8): loss=0.05655
 2025-10-07 10:31:44,925 - INFO -marigold_trainer.py - train >> iter 16692 (epoch  8): loss=0.05728
 2025-10-07 10:32:00,249 - INFO -marigold_trainer.py - train >> iter 16693 (epoch  8): loss=0.05191
 2025-10-07 10:32:16,891 - INFO -marigold_trainer.py - train >> iter 16694 (epoch  8): loss=0.06342
 2025-10-07 10:32:31,570 - INFO -marigold_trainer.py - train >> iter 16695 (epoch  8): loss=0.05125
 2025-10-07 10:32:46,882 - INFO -marigold_trainer.py - train >> iter 16696 (epoch  8): loss=0.05712
 2025-10-07 10:33:01,554 - INFO -marigold_trainer.py - train >> iter 16697 (epoch  8): loss=0.05894
 2025-10-07 10:33:16,858 - INFO -marigold_trainer.py - train >> iter 16698 (epoch  8): loss=0.05279
 2025-10-07 10:33:32,184 - INFO -marigold_trainer.py - train >> iter 16699 (epoch  8): loss=0.06298
 2025-10-07 10:33:47,511 - INFO -marigold_trainer.py - train >> iter 16700 (epoch  8): loss=0.05364
 2025-10-07 10:34:02,171 - INFO -marigold_trainer.py - train >> iter 16701 (epoch  8): loss=0.05413
 2025-10-07 10:34:16,818 - INFO -marigold_trainer.py - train >> iter 16702 (epoch  8): loss=0.05425
 2025-10-07 10:34:32,121 - INFO -marigold_trainer.py - train >> iter 16703 (epoch  8): loss=0.05757
 2025-10-07 10:34:48,759 - INFO -marigold_trainer.py - train >> iter 16704 (epoch  8): loss=0.05796
 2025-10-07 10:35:04,744 - INFO -marigold_trainer.py - train >> iter 16705 (epoch  8): loss=0.05974
 2025-10-07 10:35:20,076 - INFO -marigold_trainer.py - train >> iter 16706 (epoch  8): loss=0.05679
 2025-10-07 10:35:37,359 - INFO -marigold_trainer.py - train >> iter 16707 (epoch  8): loss=0.05328
 2025-10-07 10:35:54,452 - INFO -marigold_trainer.py - train >> iter 16708 (epoch  8): loss=0.07382
 2025-10-07 10:36:11,288 - INFO -marigold_trainer.py - train >> iter 16709 (epoch  8): loss=0.05476
 2025-10-07 10:36:27,905 - INFO -marigold_trainer.py - train >> iter 16710 (epoch  8): loss=0.05412
 2025-10-07 10:36:43,881 - INFO -marigold_trainer.py - train >> iter 16711 (epoch  8): loss=0.05057
 2025-10-07 10:36:59,858 - INFO -marigold_trainer.py - train >> iter 16712 (epoch  8): loss=0.05326
 2025-10-07 10:37:15,188 - INFO -marigold_trainer.py - train >> iter 16713 (epoch  8): loss=0.05670
 2025-10-07 10:37:30,510 - INFO -marigold_trainer.py - train >> iter 16714 (epoch  8): loss=0.05594
 2025-10-07 10:37:45,823 - INFO -marigold_trainer.py - train >> iter 16715 (epoch  8): loss=0.06138
 2025-10-07 10:38:02,442 - INFO -marigold_trainer.py - train >> iter 16716 (epoch  8): loss=0.06666
 2025-10-07 10:38:17,766 - INFO -marigold_trainer.py - train >> iter 16717 (epoch  8): loss=0.04919
 2025-10-07 10:38:33,754 - INFO -marigold_trainer.py - train >> iter 16718 (epoch  8): loss=0.05937
 2025-10-07 10:38:51,021 - INFO -marigold_trainer.py - train >> iter 16719 (epoch  8): loss=0.06423
 2025-10-07 10:39:06,339 - INFO -marigold_trainer.py - train >> iter 16720 (epoch  8): loss=0.05652
 2025-10-07 10:39:22,308 - INFO -marigold_trainer.py - train >> iter 16721 (epoch  8): loss=0.05762
 2025-10-07 10:39:38,093 - INFO -marigold_trainer.py - train >> iter 16722 (epoch  8): loss=0.05335
 2025-10-07 10:39:56,032 - INFO -marigold_trainer.py - train >> iter 16723 (epoch  8): loss=0.06011
 2025-10-07 10:40:11,560 - INFO -marigold_trainer.py - train >> iter 16724 (epoch  8): loss=0.06175
 2025-10-07 10:40:27,546 - INFO -marigold_trainer.py - train >> iter 16725 (epoch  8): loss=0.05820
 2025-10-07 10:40:42,878 - INFO -marigold_trainer.py - train >> iter 16726 (epoch  8): loss=0.05713
 2025-10-07 10:40:58,003 - INFO -marigold_trainer.py - train >> iter 16727 (epoch  8): loss=0.07044
 2025-10-07 10:41:13,523 - INFO -marigold_trainer.py - train >> iter 16728 (epoch  8): loss=0.06191
 2025-10-07 10:41:31,451 - INFO -marigold_trainer.py - train >> iter 16729 (epoch  8): loss=0.05358
 2025-10-07 10:41:46,116 - INFO -marigold_trainer.py - train >> iter 16730 (epoch  8): loss=0.05882
 2025-10-07 10:42:02,074 - INFO -marigold_trainer.py - train >> iter 16731 (epoch  8): loss=0.05554
 2025-10-07 10:42:16,738 - INFO -marigold_trainer.py - train >> iter 16732 (epoch  8): loss=0.05208
 2025-10-07 10:42:32,043 - INFO -marigold_trainer.py - train >> iter 16733 (epoch  8): loss=0.05531
 2025-10-07 10:42:48,028 - INFO -marigold_trainer.py - train >> iter 16734 (epoch  8): loss=0.06306
 2025-10-07 10:43:03,800 - INFO -marigold_trainer.py - train >> iter 16735 (epoch  8): loss=0.06274
 2025-10-07 10:43:20,639 - INFO -marigold_trainer.py - train >> iter 16736 (epoch  8): loss=0.06206
 2025-10-07 10:43:37,713 - INFO -marigold_trainer.py - train >> iter 16737 (epoch  8): loss=0.05420
 2025-10-07 10:43:53,889 - INFO -marigold_trainer.py - train >> iter 16738 (epoch  8): loss=0.06521
 2025-10-07 10:44:10,519 - INFO -marigold_trainer.py - train >> iter 16739 (epoch  8): loss=0.04981
 2025-10-07 10:44:27,146 - INFO -marigold_trainer.py - train >> iter 16740 (epoch  8): loss=0.05727
 2025-10-07 10:44:43,254 - INFO -marigold_trainer.py - train >> iter 16741 (epoch  8): loss=0.05585
 2025-10-07 10:45:00,411 - INFO -marigold_trainer.py - train >> iter 16742 (epoch  8): loss=0.05987
 2025-10-07 10:45:15,732 - INFO -marigold_trainer.py - train >> iter 16743 (epoch  8): loss=0.06079
 2025-10-07 10:45:32,823 - INFO -marigold_trainer.py - train >> iter 16744 (epoch  8): loss=0.05743
 2025-10-07 10:45:49,017 - INFO -marigold_trainer.py - train >> iter 16745 (epoch  8): loss=0.05342
 2025-10-07 10:46:05,644 - INFO -marigold_trainer.py - train >> iter 16746 (epoch  8): loss=0.05210
 2025-10-07 10:46:20,969 - INFO -marigold_trainer.py - train >> iter 16747 (epoch  8): loss=0.05859
 2025-10-07 10:46:36,946 - INFO -marigold_trainer.py - train >> iter 16748 (epoch  8): loss=0.05192
 2025-10-07 10:46:52,924 - INFO -marigold_trainer.py - train >> iter 16749 (epoch  8): loss=0.06187
 2025-10-07 10:47:08,251 - INFO -marigold_trainer.py - train >> iter 16750 (epoch  8): loss=0.06189
 2025-10-07 10:47:08,251 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: output/train_marigold/checkpoint/latest
 2025-10-07 10:47:08,251 - DEBUG -marigold_trainer.py - save_checkpoint >> Old checkpoint is backed up at: output/train_marigold/checkpoint/_old_latest
 2025-10-07 10:47:11,543 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: output/train_marigold/checkpoint/latest/unet
 2025-10-07 10:47:17,820 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: output/train_marigold/checkpoint/latest/trainer.ckpt
 2025-10-07 10:47:18,382 - DEBUG -marigold_trainer.py - save_checkpoint >> Old checkpoint backup is removed.
 2025-10-07 10:47:34,048 - INFO -marigold_trainer.py - train >> iter 16751 (epoch  8): loss=0.05670
 2025-10-07 10:47:49,378 - INFO -marigold_trainer.py - train >> iter 16752 (epoch  8): loss=0.05744
 2025-10-07 10:48:04,712 - INFO -marigold_trainer.py - train >> iter 16753 (epoch  8): loss=0.06544
 2025-10-07 10:48:20,696 - INFO -marigold_trainer.py - train >> iter 16754 (epoch  8): loss=0.05782
 2025-10-07 10:48:36,036 - INFO -marigold_trainer.py - train >> iter 16755 (epoch  8): loss=0.05769
 2025-10-07 10:48:50,717 - INFO -marigold_trainer.py - train >> iter 16756 (epoch  8): loss=0.05264
 2025-10-07 10:49:06,680 - INFO -marigold_trainer.py - train >> iter 16757 (epoch  8): loss=0.05741
 2025-10-07 10:49:23,117 - INFO -marigold_trainer.py - train >> iter 16758 (epoch  8): loss=0.05766
 2025-10-07 10:49:39,960 - INFO -marigold_trainer.py - train >> iter 16759 (epoch  8): loss=0.06733
 2025-10-07 10:49:56,592 - INFO -marigold_trainer.py - train >> iter 16760 (epoch  8): loss=0.05632
 2025-10-07 10:50:13,878 - INFO -marigold_trainer.py - train >> iter 16761 (epoch  8): loss=0.06025
 2025-10-07 10:50:29,207 - INFO -marigold_trainer.py - train >> iter 16762 (epoch  8): loss=0.06188
 2025-10-07 10:50:43,880 - INFO -marigold_trainer.py - train >> iter 16763 (epoch  8): loss=0.05942
 2025-10-07 10:51:00,289 - INFO -marigold_trainer.py - train >> iter 16764 (epoch  8): loss=0.04909
 2025-10-07 10:51:17,110 - INFO -marigold_trainer.py - train >> iter 16765 (epoch  8): loss=0.06037
 2025-10-07 10:51:32,872 - INFO -marigold_trainer.py - train >> iter 16766 (epoch  8): loss=0.05167
 2025-10-07 10:51:48,391 - INFO -marigold_trainer.py - train >> iter 16767 (epoch  8): loss=0.04921
 2025-10-07 10:52:03,054 - INFO -marigold_trainer.py - train >> iter 16768 (epoch  8): loss=0.06258
 2025-10-07 10:52:18,358 - INFO -marigold_trainer.py - train >> iter 16769 (epoch  8): loss=0.05555
 2025-10-07 10:52:34,333 - INFO -marigold_trainer.py - train >> iter 16770 (epoch  8): loss=0.06367
 2025-10-07 10:52:50,966 - INFO -marigold_trainer.py - train >> iter 16771 (epoch  8): loss=0.04753
 2025-10-07 10:53:08,241 - INFO -marigold_trainer.py - train >> iter 16772 (epoch  8): loss=0.06563
 2025-10-07 10:53:22,917 - INFO -marigold_trainer.py - train >> iter 16773 (epoch  8): loss=0.05583
 2025-10-07 10:53:38,021 - INFO -marigold_trainer.py - train >> iter 16774 (epoch  8): loss=0.05989
 2025-10-07 10:53:53,546 - INFO -marigold_trainer.py - train >> iter 16775 (epoch  8): loss=0.05389
 2025-10-07 10:54:08,220 - INFO -marigold_trainer.py - train >> iter 16776 (epoch  8): loss=0.05830
 2025-10-07 10:54:24,838 - INFO -marigold_trainer.py - train >> iter 16777 (epoch  8): loss=0.04499
 2025-10-07 10:54:40,175 - INFO -marigold_trainer.py - train >> iter 16778 (epoch  8): loss=0.05600
 2025-10-07 10:54:54,846 - INFO -marigold_trainer.py - train >> iter 16779 (epoch  8): loss=0.05685
 2025-10-07 10:55:10,150 - INFO -marigold_trainer.py - train >> iter 16780 (epoch  8): loss=0.05854
 2025-10-07 10:55:24,815 - INFO -marigold_trainer.py - train >> iter 16781 (epoch  8): loss=0.05877
 2025-10-07 10:55:40,774 - INFO -marigold_trainer.py - train >> iter 16782 (epoch  8): loss=0.06135
 2025-10-07 10:55:57,869 - INFO -marigold_trainer.py - train >> iter 16783 (epoch  8): loss=0.05427
 2025-10-07 10:56:13,406 - INFO -marigold_trainer.py - train >> iter 16784 (epoch  8): loss=0.06256
 2025-10-07 10:56:28,065 - INFO -marigold_trainer.py - train >> iter 16785 (epoch  8): loss=0.06599
 2025-10-07 10:56:43,363 - INFO -marigold_trainer.py - train >> iter 16786 (epoch  8): loss=0.06158
 2025-10-07 10:56:58,692 - INFO -marigold_trainer.py - train >> iter 16787 (epoch  8): loss=0.05875
 2025-10-07 10:57:14,477 - INFO -marigold_trainer.py - train >> iter 16788 (epoch  8): loss=0.06125
 2025-10-07 10:57:31,322 - INFO -marigold_trainer.py - train >> iter 16789 (epoch  8): loss=0.05524
 2025-10-07 10:57:47,307 - INFO -marigold_trainer.py - train >> iter 16790 (epoch  8): loss=0.05543
 2025-10-07 10:58:02,642 - INFO -marigold_trainer.py - train >> iter 16791 (epoch  8): loss=0.05185
 2025-10-07 10:58:17,309 - INFO -marigold_trainer.py - train >> iter 16792 (epoch  8): loss=0.05566
 2025-10-07 10:58:31,962 - INFO -marigold_trainer.py - train >> iter 16793 (epoch  8): loss=0.05793
 2025-10-07 10:58:47,914 - INFO -marigold_trainer.py - train >> iter 16794 (epoch  8): loss=0.06158
 2025-10-07 10:59:03,230 - INFO -marigold_trainer.py - train >> iter 16795 (epoch  8): loss=0.06356
 2025-10-07 10:59:19,205 - INFO -marigold_trainer.py - train >> iter 16796 (epoch  8): loss=0.05928
 2025-10-07 10:59:35,835 - INFO -marigold_trainer.py - train >> iter 16797 (epoch  8): loss=0.06684
 2025-10-07 10:59:52,466 - INFO -marigold_trainer.py - train >> iter 16798 (epoch  8): loss=0.05213
 2025-10-07 11:00:08,887 - INFO -marigold_trainer.py - train >> iter 16799 (epoch  8): loss=0.05851
 2025-10-07 11:00:24,406 - INFO -marigold_trainer.py - train >> iter 16800 (epoch  8): loss=0.05293
 2025-10-07 11:00:40,389 - INFO -marigold_trainer.py - train >> iter 16801 (epoch  8): loss=0.05377
 2025-10-07 11:00:56,807 - INFO -marigold_trainer.py - train >> iter 16802 (epoch  8): loss=0.05763
 2025-10-07 11:01:14,289 - INFO -marigold_trainer.py - train >> iter 16803 (epoch  8): loss=0.05582
 2025-10-07 11:01:29,614 - INFO -marigold_trainer.py - train >> iter 16804 (epoch  8): loss=0.05616
 2025-10-07 11:01:45,591 - INFO -marigold_trainer.py - train >> iter 16805 (epoch  8): loss=0.06358
 2025-10-07 11:02:01,568 - INFO -marigold_trainer.py - train >> iter 16806 (epoch  8): loss=0.05538
 2025-10-07 11:02:17,538 - INFO -marigold_trainer.py - train >> iter 16807 (epoch  8): loss=0.06214
 2025-10-07 11:02:33,521 - INFO -marigold_trainer.py - train >> iter 16808 (epoch  8): loss=0.05401
 2025-10-07 11:02:50,144 - INFO -marigold_trainer.py - train >> iter 16809 (epoch  8): loss=0.05018
 2025-10-07 11:03:06,115 - INFO -marigold_trainer.py - train >> iter 16810 (epoch  8): loss=0.06400
 2025-10-07 11:03:23,415 - INFO -marigold_trainer.py - train >> iter 16811 (epoch  8): loss=0.06455
 2025-10-07 11:03:38,742 - INFO -marigold_trainer.py - train >> iter 16812 (epoch  8): loss=0.05803
 2025-10-07 11:03:54,693 - INFO -marigold_trainer.py - train >> iter 16813 (epoch  8): loss=0.06163
 2025-10-07 11:04:11,343 - INFO -marigold_trainer.py - train >> iter 16814 (epoch  8): loss=0.05271
 2025-10-07 11:04:27,327 - INFO -marigold_trainer.py - train >> iter 16815 (epoch  8): loss=0.05632
 2025-10-07 11:04:42,649 - INFO -marigold_trainer.py - train >> iter 16816 (epoch  8): loss=0.06368
 2025-10-07 11:04:59,722 - INFO -marigold_trainer.py - train >> iter 16817 (epoch  8): loss=0.06450
 2025-10-07 11:05:15,903 - INFO -marigold_trainer.py - train >> iter 16818 (epoch  8): loss=0.05614
 2025-10-07 11:05:30,562 - INFO -marigold_trainer.py - train >> iter 16819 (epoch  8): loss=0.06236
 2025-10-07 11:05:46,517 - INFO -marigold_trainer.py - train >> iter 16820 (epoch  8): loss=0.06415
 2025-10-07 11:06:01,837 - INFO -marigold_trainer.py - train >> iter 16821 (epoch  8): loss=0.05537
 2025-10-07 11:06:17,157 - INFO -marigold_trainer.py - train >> iter 16822 (epoch  8): loss=0.06163
 2025-10-07 11:06:31,823 - INFO -marigold_trainer.py - train >> iter 16823 (epoch  8): loss=0.05981
 2025-10-07 11:06:48,880 - INFO -marigold_trainer.py - train >> iter 16824 (epoch  8): loss=0.05043
 2025-10-07 11:07:05,065 - INFO -marigold_trainer.py - train >> iter 16825 (epoch  8): loss=0.05988
 2025-10-07 11:07:20,403 - INFO -marigold_trainer.py - train >> iter 16826 (epoch  8): loss=0.06004
 2025-10-07 11:07:36,356 - INFO -marigold_trainer.py - train >> iter 16827 (epoch  8): loss=0.05268
 2025-10-07 11:07:52,323 - INFO -marigold_trainer.py - train >> iter 16828 (epoch  8): loss=0.05266
 2025-10-07 11:08:08,309 - INFO -marigold_trainer.py - train >> iter 16829 (epoch  8): loss=0.06451
 2025-10-07 11:08:24,941 - INFO -marigold_trainer.py - train >> iter 16830 (epoch  8): loss=0.05004
 2025-10-07 11:08:40,261 - INFO -marigold_trainer.py - train >> iter 16831 (epoch  8): loss=0.05709
 2025-10-07 11:08:54,939 - INFO -marigold_trainer.py - train >> iter 16832 (epoch  8): loss=0.05129
 2025-10-07 11:09:09,586 - INFO -marigold_trainer.py - train >> iter 16833 (epoch  8): loss=0.05872
 2025-10-07 11:09:24,238 - INFO -marigold_trainer.py - train >> iter 16834 (epoch  8): loss=0.04871
 2025-10-07 11:09:40,202 - INFO -marigold_trainer.py - train >> iter 16835 (epoch  8): loss=0.05165
 2025-10-07 11:09:54,868 - INFO -marigold_trainer.py - train >> iter 16836 (epoch  8): loss=0.05473
 2025-10-07 11:10:10,821 - INFO -marigold_trainer.py - train >> iter 16837 (epoch  8): loss=0.05746
 2025-10-07 11:10:25,585 - INFO -marigold_trainer.py - train >> iter 16838 (epoch  8): loss=0.05439
 2025-10-07 11:10:40,234 - INFO -marigold_trainer.py - train >> iter 16839 (epoch  8): loss=0.05698
 2025-10-07 11:10:54,882 - INFO -marigold_trainer.py - train >> iter 16840 (epoch  8): loss=0.05354
 2025-10-07 11:11:11,490 - INFO -marigold_trainer.py - train >> iter 16841 (epoch  8): loss=0.06499
 2025-10-07 11:11:26,817 - INFO -marigold_trainer.py - train >> iter 16842 (epoch  8): loss=0.05958
 2025-10-07 11:11:42,784 - INFO -marigold_trainer.py - train >> iter 16843 (epoch  8): loss=0.05987
 2025-10-07 11:11:59,416 - INFO -marigold_trainer.py - train >> iter 16844 (epoch  8): loss=0.06073
 2025-10-07 11:12:16,040 - INFO -marigold_trainer.py - train >> iter 16845 (epoch  8): loss=0.06547
 2025-10-07 11:12:30,700 - INFO -marigold_trainer.py - train >> iter 16846 (epoch  8): loss=0.05221
 2025-10-07 11:12:46,655 - INFO -marigold_trainer.py - train >> iter 16847 (epoch  8): loss=0.06249
 2025-10-07 11:13:01,975 - INFO -marigold_trainer.py - train >> iter 16848 (epoch  8): loss=0.05657
 2025-10-07 11:13:17,941 - INFO -marigold_trainer.py - train >> iter 16849 (epoch  8): loss=0.06011
 2025-10-07 11:13:33,714 - INFO -marigold_trainer.py - train >> iter 16850 (epoch  8): loss=0.06619
 2025-10-07 11:13:49,889 - INFO -marigold_trainer.py - train >> iter 16851 (epoch  8): loss=0.05834
 2025-10-07 11:14:05,862 - INFO -marigold_trainer.py - train >> iter 16852 (epoch  8): loss=0.05759
 2025-10-07 11:14:20,530 - INFO -marigold_trainer.py - train >> iter 16853 (epoch  8): loss=0.06900
 2025-10-07 11:14:36,283 - INFO -marigold_trainer.py - train >> iter 16854 (epoch  8): loss=0.05053
 2025-10-07 11:14:53,115 - INFO -marigold_trainer.py - train >> iter 16855 (epoch  8): loss=0.06261
 2025-10-07 11:15:09,754 - INFO -marigold_trainer.py - train >> iter 16856 (epoch  8): loss=0.06293
 2025-10-07 11:15:25,071 - INFO -marigold_trainer.py - train >> iter 16857 (epoch  8): loss=0.06029
 2025-10-07 11:15:40,390 - INFO -marigold_trainer.py - train >> iter 16858 (epoch  8): loss=0.05765
 2025-10-07 11:15:55,056 - INFO -marigold_trainer.py - train >> iter 16859 (epoch  8): loss=0.05361
 2025-10-07 11:16:12,324 - INFO -marigold_trainer.py - train >> iter 16860 (epoch  8): loss=0.06037
 2025-10-07 11:16:26,999 - INFO -marigold_trainer.py - train >> iter 16861 (epoch  8): loss=0.05960
 2025-10-07 11:16:42,303 - INFO -marigold_trainer.py - train >> iter 16862 (epoch  8): loss=0.06305
 2025-10-07 11:16:57,623 - INFO -marigold_trainer.py - train >> iter 16863 (epoch  8): loss=0.06131
 2025-10-07 11:17:13,600 - INFO -marigold_trainer.py - train >> iter 16864 (epoch  8): loss=0.05547
 2025-10-07 11:17:28,925 - INFO -marigold_trainer.py - train >> iter 16865 (epoch  8): loss=0.05685
 2025-10-07 11:17:44,708 - INFO -marigold_trainer.py - train >> iter 16866 (epoch  8): loss=0.05557
 2025-10-07 11:17:59,580 - INFO -marigold_trainer.py - train >> iter 16867 (epoch  8): loss=0.05527
 2025-10-07 11:18:14,880 - INFO -marigold_trainer.py - train >> iter 16868 (epoch  8): loss=0.06073
 2025-10-07 11:18:31,510 - INFO -marigold_trainer.py - train >> iter 16869 (epoch  8): loss=0.06446
 2025-10-07 11:18:46,826 - INFO -marigold_trainer.py - train >> iter 16870 (epoch  8): loss=0.05676
 2025-10-07 11:19:02,787 - INFO -marigold_trainer.py - train >> iter 16871 (epoch  8): loss=0.05809
 2025-10-07 11:19:18,109 - INFO -marigold_trainer.py - train >> iter 16872 (epoch  8): loss=0.05388
 2025-10-07 11:19:33,426 - INFO -marigold_trainer.py - train >> iter 16873 (epoch  8): loss=0.05866
 2025-10-07 11:19:48,739 - INFO -marigold_trainer.py - train >> iter 16874 (epoch  8): loss=0.06345
 2025-10-07 11:20:03,400 - INFO -marigold_trainer.py - train >> iter 16875 (epoch  8): loss=0.06668
 2025-10-07 11:20:19,155 - INFO -marigold_trainer.py - train >> iter 16876 (epoch  8): loss=0.05285
 2025-10-07 11:20:34,680 - INFO -marigold_trainer.py - train >> iter 16877 (epoch  8): loss=0.07014
 2025-10-07 11:20:51,106 - INFO -marigold_trainer.py - train >> iter 16878 (epoch  8): loss=0.05715
 2025-10-07 11:21:05,984 - INFO -marigold_trainer.py - train >> iter 16879 (epoch  8): loss=0.05264
 2025-10-07 11:21:20,633 - INFO -marigold_trainer.py - train >> iter 16880 (epoch  8): loss=0.05673
 2025-10-07 11:21:37,036 - INFO -marigold_trainer.py - train >> iter 16881 (epoch  8): loss=0.06276
 2025-10-07 11:21:53,858 - INFO -marigold_trainer.py - train >> iter 16882 (epoch  8): loss=0.05266
 2025-10-07 11:22:08,526 - INFO -marigold_trainer.py - train >> iter 16883 (epoch  8): loss=0.06317
 2025-10-07 11:22:24,475 - INFO -marigold_trainer.py - train >> iter 16884 (epoch  8): loss=0.05308
 2025-10-07 11:22:39,792 - INFO -marigold_trainer.py - train >> iter 16885 (epoch  8): loss=0.05945
 2025-10-07 11:22:56,423 - INFO -marigold_trainer.py - train >> iter 16886 (epoch  8): loss=0.06332
 2025-10-07 11:23:11,750 - INFO -marigold_trainer.py - train >> iter 16887 (epoch  8): loss=0.06734
 2025-10-07 11:23:28,372 - INFO -marigold_trainer.py - train >> iter 16888 (epoch  8): loss=0.05915
 2025-10-07 11:23:44,332 - INFO -marigold_trainer.py - train >> iter 16889 (epoch  8): loss=0.05510
 2025-10-07 11:24:00,300 - INFO -marigold_trainer.py - train >> iter 16890 (epoch  8): loss=0.06365
 2025-10-07 11:24:16,721 - INFO -marigold_trainer.py - train >> iter 16891 (epoch  8): loss=0.06029
 2025-10-07 11:24:33,352 - INFO -marigold_trainer.py - train >> iter 16892 (epoch  8): loss=0.06497
 2025-10-07 11:24:49,526 - INFO -marigold_trainer.py - train >> iter 16893 (epoch  8): loss=0.06460
 2025-10-07 11:25:06,162 - INFO -marigold_trainer.py - train >> iter 16894 (epoch  8): loss=0.05526
 2025-10-07 11:25:22,130 - INFO -marigold_trainer.py - train >> iter 16895 (epoch  8): loss=0.05830
 2025-10-07 11:25:37,456 - INFO -marigold_trainer.py - train >> iter 16896 (epoch  8): loss=0.06089
 2025-10-07 11:25:52,128 - INFO -marigold_trainer.py - train >> iter 16897 (epoch  8): loss=0.06158
 2025-10-07 11:26:09,390 - INFO -marigold_trainer.py - train >> iter 16898 (epoch  8): loss=0.06008
 2025-10-07 11:26:24,715 - INFO -marigold_trainer.py - train >> iter 16899 (epoch  8): loss=0.06250
 2025-10-07 11:26:39,386 - INFO -marigold_trainer.py - train >> iter 16900 (epoch  8): loss=0.05654
 2025-10-07 11:26:54,036 - INFO -marigold_trainer.py - train >> iter 16901 (epoch  8): loss=0.05692
 2025-10-07 11:27:09,793 - INFO -marigold_trainer.py - train >> iter 16902 (epoch  8): loss=0.05542
 2025-10-07 11:27:25,963 - INFO -marigold_trainer.py - train >> iter 16903 (epoch  8): loss=0.05778
 2025-10-07 11:27:41,295 - INFO -marigold_trainer.py - train >> iter 16904 (epoch  8): loss=0.05480
 2025-10-07 11:27:56,412 - INFO -marigold_trainer.py - train >> iter 16905 (epoch  8): loss=0.05347
 2025-10-07 11:28:12,598 - INFO -marigold_trainer.py - train >> iter 16906 (epoch  8): loss=0.06355
 2025-10-07 11:28:28,586 - INFO -marigold_trainer.py - train >> iter 16907 (epoch  8): loss=0.04698
 2025-10-07 11:28:43,251 - INFO -marigold_trainer.py - train >> iter 16908 (epoch  8): loss=0.06265
 2025-10-07 11:28:59,856 - INFO -marigold_trainer.py - train >> iter 16909 (epoch  8): loss=0.05711
 2025-10-07 11:29:17,790 - INFO -marigold_trainer.py - train >> iter 16910 (epoch  8): loss=0.05954
 2025-10-07 11:29:32,462 - INFO -marigold_trainer.py - train >> iter 16911 (epoch  8): loss=0.05772
 2025-10-07 11:29:48,421 - INFO -marigold_trainer.py - train >> iter 16912 (epoch  8): loss=0.06480
 2025-10-07 11:30:03,091 - INFO -marigold_trainer.py - train >> iter 16913 (epoch  8): loss=0.05192
 2025-10-07 11:30:17,749 - INFO -marigold_trainer.py - train >> iter 16914 (epoch  8): loss=0.06537
 2025-10-07 11:30:33,708 - INFO -marigold_trainer.py - train >> iter 16915 (epoch  8): loss=0.05666
 2025-10-07 11:30:49,680 - INFO -marigold_trainer.py - train >> iter 16916 (epoch  8): loss=0.05713
 2025-10-07 11:31:04,354 - INFO -marigold_trainer.py - train >> iter 16917 (epoch  8): loss=0.05914
 2025-10-07 11:31:19,460 - INFO -marigold_trainer.py - train >> iter 16918 (epoch  8): loss=0.06024
 2025-10-07 11:31:36,103 - INFO -marigold_trainer.py - train >> iter 16919 (epoch  8): loss=0.05971
 2025-10-07 11:31:53,399 - INFO -marigold_trainer.py - train >> iter 16920 (epoch  8): loss=0.06398
 2025-10-07 11:32:08,931 - INFO -marigold_trainer.py - train >> iter 16921 (epoch  8): loss=0.05657
 2025-10-07 11:32:25,580 - INFO -marigold_trainer.py - train >> iter 16922 (epoch  8): loss=0.05945
 2025-10-07 11:32:40,253 - INFO -marigold_trainer.py - train >> iter 16923 (epoch  8): loss=0.05604
 2025-10-07 11:32:56,869 - INFO -marigold_trainer.py - train >> iter 16924 (epoch  8): loss=0.05496
 2025-10-07 11:33:11,543 - INFO -marigold_trainer.py - train >> iter 16925 (epoch  8): loss=0.06219
 2025-10-07 11:33:26,851 - INFO -marigold_trainer.py - train >> iter 16926 (epoch  8): loss=0.05534
 2025-10-07 11:33:42,835 - INFO -marigold_trainer.py - train >> iter 16927 (epoch  8): loss=0.04855
 2025-10-07 11:33:57,505 - INFO -marigold_trainer.py - train >> iter 16928 (epoch  8): loss=0.05622
 2025-10-07 11:34:14,114 - INFO -marigold_trainer.py - train >> iter 16929 (epoch  8): loss=0.06232
 2025-10-07 11:34:29,445 - INFO -marigold_trainer.py - train >> iter 16930 (epoch  8): loss=0.06506
 2025-10-07 11:34:44,771 - INFO -marigold_trainer.py - train >> iter 16931 (epoch  8): loss=0.05446
 2025-10-07 11:35:00,751 - INFO -marigold_trainer.py - train >> iter 16932 (epoch  8): loss=0.04741
 2025-10-07 11:35:16,080 - INFO -marigold_trainer.py - train >> iter 16933 (epoch  8): loss=0.06607
 2025-10-07 11:35:33,163 - INFO -marigold_trainer.py - train >> iter 16934 (epoch  8): loss=0.07050
 2025-10-07 11:35:49,340 - INFO -marigold_trainer.py - train >> iter 16935 (epoch  8): loss=0.05359
 2025-10-07 11:36:05,331 - INFO -marigold_trainer.py - train >> iter 16936 (epoch  8): loss=0.05513
 2025-10-07 11:36:20,658 - INFO -marigold_trainer.py - train >> iter 16937 (epoch  8): loss=0.06041
 2025-10-07 11:36:36,076 - INFO -marigold_trainer.py - train >> iter 16938 (epoch  8): loss=0.05154
 2025-10-07 11:36:51,407 - INFO -marigold_trainer.py - train >> iter 16939 (epoch  8): loss=0.05939
 2025-10-07 11:37:07,174 - INFO -marigold_trainer.py - train >> iter 16940 (epoch  8): loss=0.05074
 2025-10-07 11:37:23,352 - INFO -marigold_trainer.py - train >> iter 16941 (epoch  8): loss=0.05245
 2025-10-07 11:37:38,021 - INFO -marigold_trainer.py - train >> iter 16942 (epoch  8): loss=0.05591
 2025-10-07 11:37:55,284 - INFO -marigold_trainer.py - train >> iter 16943 (epoch  8): loss=0.05734
 2025-10-07 11:38:11,917 - INFO -marigold_trainer.py - train >> iter 16944 (epoch  8): loss=0.05277
 2025-10-07 11:38:27,902 - INFO -marigold_trainer.py - train >> iter 16945 (epoch  8): loss=0.06442
 2025-10-07 11:38:44,520 - INFO -marigold_trainer.py - train >> iter 16946 (epoch  8): loss=0.05298
 2025-10-07 11:38:59,184 - INFO -marigold_trainer.py - train >> iter 16947 (epoch  8): loss=0.06227
 2025-10-07 11:39:15,792 - INFO -marigold_trainer.py - train >> iter 16948 (epoch  8): loss=0.05662
 2025-10-07 11:39:30,473 - INFO -marigold_trainer.py - train >> iter 16949 (epoch  8): loss=0.05619
 2025-10-07 11:39:46,878 - INFO -marigold_trainer.py - train >> iter 16950 (epoch  8): loss=0.05678
 2025-10-07 11:40:02,397 - INFO -marigold_trainer.py - train >> iter 16951 (epoch  8): loss=0.05853
 2025-10-07 11:40:17,704 - INFO -marigold_trainer.py - train >> iter 16952 (epoch  8): loss=0.05513
 2025-10-07 11:40:32,382 - INFO -marigold_trainer.py - train >> iter 16953 (epoch  8): loss=0.06242
 2025-10-07 11:40:48,137 - INFO -marigold_trainer.py - train >> iter 16954 (epoch  8): loss=0.05740
 2025-10-07 11:41:03,457 - INFO -marigold_trainer.py - train >> iter 16955 (epoch  8): loss=0.06045
 2025-10-07 11:41:18,989 - INFO -marigold_trainer.py - train >> iter 16956 (epoch  8): loss=0.05628
 2025-10-07 11:41:33,639 - INFO -marigold_trainer.py - train >> iter 16957 (epoch  8): loss=0.06067
 2025-10-07 11:41:49,600 - INFO -marigold_trainer.py - train >> iter 16958 (epoch  8): loss=0.06207
 2025-10-07 11:42:05,580 - INFO -marigold_trainer.py - train >> iter 16959 (epoch  8): loss=0.06581
 2025-10-07 11:42:20,910 - INFO -marigold_trainer.py - train >> iter 16960 (epoch  8): loss=0.06300
 2025-10-07 11:42:35,570 - INFO -marigold_trainer.py - train >> iter 16961 (epoch  8): loss=0.05434
 2025-10-07 11:42:51,521 - INFO -marigold_trainer.py - train >> iter 16962 (epoch  8): loss=0.05944
 2025-10-07 11:43:08,801 - INFO -marigold_trainer.py - train >> iter 16963 (epoch  8): loss=0.04872
 2025-10-07 11:43:23,470 - INFO -marigold_trainer.py - train >> iter 16964 (epoch  8): loss=0.06082
 2025-10-07 11:43:38,777 - INFO -marigold_trainer.py - train >> iter 16965 (epoch  8): loss=0.05787
 2025-10-07 11:43:54,099 - INFO -marigold_trainer.py - train >> iter 16966 (epoch  8): loss=0.06581
 2025-10-07 11:44:10,072 - INFO -marigold_trainer.py - train >> iter 16967 (epoch  8): loss=0.06267
 2025-10-07 11:44:26,053 - INFO -marigold_trainer.py - train >> iter 16968 (epoch  8): loss=0.05560
 2025-10-07 11:44:42,034 - INFO -marigold_trainer.py - train >> iter 16969 (epoch  8): loss=0.05750
 2025-10-07 11:44:57,364 - INFO -marigold_trainer.py - train >> iter 16970 (epoch  8): loss=0.06075
 2025-10-07 11:45:12,030 - INFO -marigold_trainer.py - train >> iter 16971 (epoch  8): loss=0.06262
 2025-10-07 11:45:27,988 - INFO -marigold_trainer.py - train >> iter 16972 (epoch  8): loss=0.04685
 2025-10-07 11:45:43,309 - INFO -marigold_trainer.py - train >> iter 16973 (epoch  8): loss=0.05460
 2025-10-07 11:45:59,944 - INFO -marigold_trainer.py - train >> iter 16974 (epoch  8): loss=0.05481
 2025-10-07 11:46:17,240 - INFO -marigold_trainer.py - train >> iter 16975 (epoch  8): loss=0.06077
 2025-10-07 11:46:32,552 - INFO -marigold_trainer.py - train >> iter 16976 (epoch  8): loss=0.06230
 2025-10-07 11:46:49,628 - INFO -marigold_trainer.py - train >> iter 16977 (epoch  8): loss=0.06202
 2025-10-07 11:47:06,912 - INFO -marigold_trainer.py - train >> iter 16978 (epoch  8): loss=0.05823
 2025-10-07 11:47:22,434 - INFO -marigold_trainer.py - train >> iter 16979 (epoch  8): loss=0.05453
 2025-10-07 11:47:39,059 - INFO -marigold_trainer.py - train >> iter 16980 (epoch  8): loss=0.06035
 2025-10-07 11:47:55,026 - INFO -marigold_trainer.py - train >> iter 16981 (epoch  8): loss=0.05854
 2025-10-07 11:48:11,655 - INFO -marigold_trainer.py - train >> iter 16982 (epoch  8): loss=0.05768
 2025-10-07 11:48:27,632 - INFO -marigold_trainer.py - train >> iter 16983 (epoch  8): loss=0.05269
 2025-10-07 11:48:42,306 - INFO -marigold_trainer.py - train >> iter 16984 (epoch  8): loss=0.05930
 2025-10-07 11:48:56,951 - INFO -marigold_trainer.py - train >> iter 16985 (epoch  8): loss=0.05967
 2025-10-07 11:49:12,906 - INFO -marigold_trainer.py - train >> iter 16986 (epoch  8): loss=0.05930
 2025-10-07 11:49:28,880 - INFO -marigold_trainer.py - train >> iter 16987 (epoch  8): loss=0.06429
 2025-10-07 11:49:44,214 - INFO -marigold_trainer.py - train >> iter 16988 (epoch  8): loss=0.06779
 2025-10-07 11:49:59,968 - INFO -marigold_trainer.py - train >> iter 16989 (epoch  8): loss=0.06249
 2025-10-07 11:50:14,840 - INFO -marigold_trainer.py - train >> iter 16990 (epoch  8): loss=0.05148
 2025-10-07 11:50:30,791 - INFO -marigold_trainer.py - train >> iter 16991 (epoch  8): loss=0.05871
 2025-10-07 11:50:46,765 - INFO -marigold_trainer.py - train >> iter 16992 (epoch  8): loss=0.06563
 2025-10-07 11:51:02,089 - INFO -marigold_trainer.py - train >> iter 16993 (epoch  8): loss=0.06380
 2025-10-07 11:51:16,761 - INFO -marigold_trainer.py - train >> iter 16994 (epoch  8): loss=0.06180
 2025-10-07 11:51:32,064 - INFO -marigold_trainer.py - train >> iter 16995 (epoch  8): loss=0.05922
 2025-10-07 11:51:47,367 - INFO -marigold_trainer.py - train >> iter 16996 (epoch  8): loss=0.05379
 2025-10-07 11:52:02,699 - INFO -marigold_trainer.py - train >> iter 16997 (epoch  8): loss=0.06040
 2025-10-07 11:52:18,038 - INFO -marigold_trainer.py - train >> iter 16998 (epoch  8): loss=0.05468
 2025-10-07 11:52:34,672 - INFO -marigold_trainer.py - train >> iter 16999 (epoch  8): loss=0.05800
 2025-10-07 11:52:49,347 - INFO -marigold_trainer.py - train >> iter 17000 (epoch  8): loss=0.06730
 2025-10-07 11:52:49,347 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: output/train_marigold/checkpoint/latest
 2025-10-07 11:52:49,347 - DEBUG -marigold_trainer.py - save_checkpoint >> Old checkpoint is backed up at: output/train_marigold/checkpoint/_old_latest
 2025-10-07 11:52:52,619 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: output/train_marigold/checkpoint/latest/unet
 2025-10-07 11:52:58,884 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: output/train_marigold/checkpoint/latest/trainer.ckpt
 2025-10-07 11:52:59,552 - DEBUG -marigold_trainer.py - save_checkpoint >> Old checkpoint backup is removed.
 2025-10-07 11:53:15,874 - INFO -marigold_trainer.py - train >> iter 17001 (epoch  8): loss=0.05871
 2025-10-07 11:53:31,198 - INFO -marigold_trainer.py - train >> iter 17002 (epoch  8): loss=0.06174
 2025-10-07 11:53:47,832 - INFO -marigold_trainer.py - train >> iter 17003 (epoch  8): loss=0.05959
 2025-10-07 11:54:03,808 - INFO -marigold_trainer.py - train >> iter 17004 (epoch  8): loss=0.05807
 2025-10-07 11:54:18,482 - INFO -marigold_trainer.py - train >> iter 17005 (epoch  8): loss=0.06122
 2025-10-07 11:54:34,439 - INFO -marigold_trainer.py - train >> iter 17006 (epoch  8): loss=0.06197
 2025-10-07 11:54:49,110 - INFO -marigold_trainer.py - train >> iter 17007 (epoch  8): loss=0.05636
 2025-10-07 11:55:04,409 - INFO -marigold_trainer.py - train >> iter 17008 (epoch  8): loss=0.06156
 2025-10-07 11:55:21,692 - INFO -marigold_trainer.py - train >> iter 17009 (epoch  8): loss=0.05903
 2025-10-07 11:55:37,018 - INFO -marigold_trainer.py - train >> iter 17010 (epoch  8): loss=0.05587
 2025-10-07 11:55:53,452 - INFO -marigold_trainer.py - train >> iter 17011 (epoch  8): loss=0.05732
 2025-10-07 11:56:10,290 - INFO -marigold_trainer.py - train >> iter 17012 (epoch  8): loss=0.06431
 2025-10-07 11:56:26,916 - INFO -marigold_trainer.py - train >> iter 17013 (epoch  8): loss=0.06362
 2025-10-07 11:56:42,691 - INFO -marigold_trainer.py - train >> iter 17014 (epoch  8): loss=0.06033
 2025-10-07 11:56:58,861 - INFO -marigold_trainer.py - train >> iter 17015 (epoch  8): loss=0.06395
 2025-10-07 11:57:15,278 - INFO -marigold_trainer.py - train >> iter 17016 (epoch  8): loss=0.05468
 2025-10-07 11:57:31,435 - INFO -marigold_trainer.py - train >> iter 17017 (epoch  8): loss=0.05412
 2025-10-07 11:57:48,061 - INFO -marigold_trainer.py - train >> iter 17018 (epoch  8): loss=0.05551
 2025-10-07 11:58:03,375 - INFO -marigold_trainer.py - train >> iter 17019 (epoch  8): loss=0.06399
 2025-10-07 11:58:18,699 - INFO -marigold_trainer.py - train >> iter 17020 (epoch  8): loss=0.05528
 2025-10-07 11:58:34,025 - INFO -marigold_trainer.py - train >> iter 17021 (epoch  8): loss=0.05556
 2025-10-07 11:58:50,000 - INFO -marigold_trainer.py - train >> iter 17022 (epoch  8): loss=0.06358
 2025-10-07 11:59:05,980 - INFO -marigold_trainer.py - train >> iter 17023 (epoch  8): loss=0.05372
 2025-10-07 11:59:21,955 - INFO -marigold_trainer.py - train >> iter 17024 (epoch  8): loss=0.05987
 2025-10-07 11:59:38,586 - INFO -marigold_trainer.py - train >> iter 17025 (epoch  8): loss=0.06171
 2025-10-07 11:59:53,911 - INFO -marigold_trainer.py - train >> iter 17026 (epoch  8): loss=0.06017
 2025-10-07 12:00:09,250 - INFO -marigold_trainer.py - train >> iter 17027 (epoch  8): loss=0.05742
 2025-10-07 12:00:25,882 - INFO -marigold_trainer.py - train >> iter 17028 (epoch  8): loss=0.06588
 2025-10-07 12:00:41,207 - INFO -marigold_trainer.py - train >> iter 17029 (epoch  8): loss=0.05712
 2025-10-07 12:00:57,845 - INFO -marigold_trainer.py - train >> iter 17030 (epoch  8): loss=0.05678
 2025-10-07 12:01:13,172 - INFO -marigold_trainer.py - train >> iter 17031 (epoch  8): loss=0.06270
 2025-10-07 12:01:27,923 - INFO -marigold_trainer.py - train >> iter 17032 (epoch  8): loss=0.05149
 2025-10-07 12:01:44,984 - INFO -marigold_trainer.py - train >> iter 17033 (epoch  8): loss=0.05642
 2025-10-07 12:02:01,815 - INFO -marigold_trainer.py - train >> iter 17034 (epoch  8): loss=0.05574
 2025-10-07 12:02:18,442 - INFO -marigold_trainer.py - train >> iter 17035 (epoch  8): loss=0.05762
 2025-10-07 12:02:33,758 - INFO -marigold_trainer.py - train >> iter 17036 (epoch  8): loss=0.06631
 2025-10-07 12:02:49,735 - INFO -marigold_trainer.py - train >> iter 17037 (epoch  8): loss=0.05870
 2025-10-07 12:03:05,045 - INFO -marigold_trainer.py - train >> iter 17038 (epoch  8): loss=0.06307
 2025-10-07 12:03:19,714 - INFO -marigold_trainer.py - train >> iter 17039 (epoch  8): loss=0.06418
 2025-10-07 12:03:35,669 - INFO -marigold_trainer.py - train >> iter 17040 (epoch  8): loss=0.06437
 2025-10-07 12:03:50,342 - INFO -marigold_trainer.py - train >> iter 17041 (epoch  8): loss=0.05142
 2025-10-07 12:04:04,993 - INFO -marigold_trainer.py - train >> iter 17042 (epoch  8): loss=0.05914
 2025-10-07 12:04:20,299 - INFO -marigold_trainer.py - train >> iter 17043 (epoch  8): loss=0.06224
 2025-10-07 12:04:35,629 - INFO -marigold_trainer.py - train >> iter 17044 (epoch  8): loss=0.06167
 2025-10-07 12:04:51,612 - INFO -marigold_trainer.py - train >> iter 17045 (epoch  8): loss=0.05300
 2025-10-07 12:05:06,929 - INFO -marigold_trainer.py - train >> iter 17046 (epoch  8): loss=0.06223
 2025-10-07 12:05:21,591 - INFO -marigold_trainer.py - train >> iter 17047 (epoch  8): loss=0.05957
 2025-10-07 12:05:38,002 - INFO -marigold_trainer.py - train >> iter 17048 (epoch  8): loss=0.05992
 2025-10-07 12:05:52,867 - INFO -marigold_trainer.py - train >> iter 17049 (epoch  8): loss=0.05441
 2025-10-07 12:06:08,831 - INFO -marigold_trainer.py - train >> iter 17050 (epoch  8): loss=0.05832
 2025-10-07 12:06:24,153 - INFO -marigold_trainer.py - train >> iter 17051 (epoch  8): loss=0.06626
 2025-10-07 12:06:40,140 - INFO -marigold_trainer.py - train >> iter 17052 (epoch  8): loss=0.05502
 2025-10-07 12:06:54,814 - INFO -marigold_trainer.py - train >> iter 17053 (epoch  8): loss=0.06370
 2025-10-07 12:07:10,767 - INFO -marigold_trainer.py - train >> iter 17054 (epoch  8): loss=0.06555
 2025-10-07 12:07:26,743 - INFO -marigold_trainer.py - train >> iter 17055 (epoch  8): loss=0.05614
 2025-10-07 12:07:42,717 - INFO -marigold_trainer.py - train >> iter 17056 (epoch  8): loss=0.05039
 2025-10-07 12:07:58,042 - INFO -marigold_trainer.py - train >> iter 17057 (epoch  8): loss=0.06206
 2025-10-07 12:08:14,021 - INFO -marigold_trainer.py - train >> iter 17058 (epoch  8): loss=0.05201
 2025-10-07 12:08:29,346 - INFO -marigold_trainer.py - train >> iter 17059 (epoch  8): loss=0.06451
 2025-10-07 12:08:46,621 - INFO -marigold_trainer.py - train >> iter 17060 (epoch  8): loss=0.06104
 2025-10-07 12:09:01,942 - INFO -marigold_trainer.py - train >> iter 17061 (epoch  8): loss=0.06156
 2025-10-07 12:09:17,269 - INFO -marigold_trainer.py - train >> iter 17062 (epoch  8): loss=0.05964
 2025-10-07 12:09:32,597 - INFO -marigold_trainer.py - train >> iter 17063 (epoch  8): loss=0.06770
 2025-10-07 12:09:47,920 - INFO -marigold_trainer.py - train >> iter 17064 (epoch  8): loss=0.06264
 2025-10-07 12:10:04,560 - INFO -marigold_trainer.py - train >> iter 17065 (epoch  8): loss=0.05406
 2025-10-07 12:10:19,875 - INFO -marigold_trainer.py - train >> iter 17066 (epoch  8): loss=0.05711
 2025-10-07 12:10:37,617 - INFO -marigold_trainer.py - train >> iter 17067 (epoch  8): loss=0.05988
 2025-10-07 12:10:53,143 - INFO -marigold_trainer.py - train >> iter 17068 (epoch  8): loss=0.06290
 2025-10-07 12:11:09,125 - INFO -marigold_trainer.py - train >> iter 17069 (epoch  8): loss=0.05682
 2025-10-07 12:11:25,099 - INFO -marigold_trainer.py - train >> iter 17070 (epoch  8): loss=0.05870
 2025-10-07 12:11:40,880 - INFO -marigold_trainer.py - train >> iter 17071 (epoch  8): loss=0.06703
 2025-10-07 12:11:57,058 - INFO -marigold_trainer.py - train >> iter 17072 (epoch  8): loss=0.05395
 2025-10-07 12:12:13,026 - INFO -marigold_trainer.py - train >> iter 17073 (epoch  8): loss=0.05666
 2025-10-07 12:12:28,349 - INFO -marigold_trainer.py - train >> iter 17074 (epoch  8): loss=0.06813
 2025-10-07 12:12:43,674 - INFO -marigold_trainer.py - train >> iter 17075 (epoch  8): loss=0.06256
 2025-10-07 12:13:02,267 - INFO -marigold_trainer.py - train >> iter 17076 (epoch  8): loss=0.05949
 2025-10-07 12:13:19,557 - INFO -marigold_trainer.py - train >> iter 17077 (epoch  8): loss=0.06124
 2025-10-07 12:13:37,502 - INFO -marigold_trainer.py - train >> iter 17078 (epoch  8): loss=0.06018
 2025-10-07 12:13:52,180 - INFO -marigold_trainer.py - train >> iter 17079 (epoch  8): loss=0.06430
 2025-10-07 12:14:06,826 - INFO -marigold_trainer.py - train >> iter 17080 (epoch  8): loss=0.06369
 2025-10-07 12:14:21,482 - INFO -marigold_trainer.py - train >> iter 17081 (epoch  8): loss=0.05799
 2025-10-07 12:14:36,791 - INFO -marigold_trainer.py - train >> iter 17082 (epoch  8): loss=0.05829
 2025-10-07 12:14:52,765 - INFO -marigold_trainer.py - train >> iter 17083 (epoch  8): loss=0.05454
 2025-10-07 12:15:08,096 - INFO -marigold_trainer.py - train >> iter 17084 (epoch  8): loss=0.05808
 2025-10-07 12:15:24,074 - INFO -marigold_trainer.py - train >> iter 17085 (epoch  8): loss=0.05682
 2025-10-07 12:15:39,387 - INFO -marigold_trainer.py - train >> iter 17086 (epoch  8): loss=0.05765
 2025-10-07 12:15:54,048 - INFO -marigold_trainer.py - train >> iter 17087 (epoch  8): loss=0.05466
 2025-10-07 12:16:08,701 - INFO -marigold_trainer.py - train >> iter 17088 (epoch  8): loss=0.06490
 2025-10-07 12:16:24,000 - INFO -marigold_trainer.py - train >> iter 17089 (epoch  8): loss=0.06389
 2025-10-07 12:16:38,672 - INFO -marigold_trainer.py - train >> iter 17090 (epoch  8): loss=0.06037
 2025-10-07 12:16:55,282 - INFO -marigold_trainer.py - train >> iter 17091 (epoch  8): loss=0.06124
 2025-10-07 12:17:09,959 - INFO -marigold_trainer.py - train >> iter 17092 (epoch  8): loss=0.05251
 2025-10-07 12:17:24,608 - INFO -marigold_trainer.py - train >> iter 17093 (epoch  8): loss=0.05420
 2025-10-07 12:17:39,914 - INFO -marigold_trainer.py - train >> iter 17094 (epoch  8): loss=0.06173
 2025-10-07 12:17:54,580 - INFO -marigold_trainer.py - train >> iter 17095 (epoch  8): loss=0.05723
 2025-10-07 12:18:13,147 - INFO -marigold_trainer.py - train >> iter 17096 (epoch  8): loss=0.05944
 2025-10-07 12:18:29,575 - INFO -marigold_trainer.py - train >> iter 17097 (epoch  8): loss=0.05627
 2025-10-07 12:18:45,742 - INFO -marigold_trainer.py - train >> iter 17098 (epoch  8): loss=0.06501
 2025-10-07 12:19:00,413 - INFO -marigold_trainer.py - train >> iter 17099 (epoch  8): loss=0.06142
 2025-10-07 12:19:15,060 - INFO -marigold_trainer.py - train >> iter 17100 (epoch  8): loss=0.05736
 2025-10-07 12:19:31,027 - INFO -marigold_trainer.py - train >> iter 17101 (epoch  8): loss=0.05603
 2025-10-07 12:19:46,348 - INFO -marigold_trainer.py - train >> iter 17102 (epoch  8): loss=0.06007
 2025-10-07 12:20:01,667 - INFO -marigold_trainer.py - train >> iter 17103 (epoch  8): loss=0.06347
 2025-10-07 12:20:17,655 - INFO -marigold_trainer.py - train >> iter 17104 (epoch  8): loss=0.06004
 2025-10-07 12:20:34,083 - INFO -marigold_trainer.py - train >> iter 17105 (epoch  8): loss=0.05670
 2025-10-07 12:20:50,054 - INFO -marigold_trainer.py - train >> iter 17106 (epoch  8): loss=0.04896
 2025-10-07 12:21:05,576 - INFO -marigold_trainer.py - train >> iter 17107 (epoch  8): loss=0.06716
 2025-10-07 12:21:20,897 - INFO -marigold_trainer.py - train >> iter 17108 (epoch  8): loss=0.06362
 2025-10-07 12:21:35,570 - INFO -marigold_trainer.py - train >> iter 17109 (epoch  8): loss=0.05563
 2025-10-07 12:21:50,871 - INFO -marigold_trainer.py - train >> iter 17110 (epoch  8): loss=0.05918
 2025-10-07 12:22:06,203 - INFO -marigold_trainer.py - train >> iter 17111 (epoch  8): loss=0.04923
 2025-10-07 12:22:22,631 - INFO -marigold_trainer.py - train >> iter 17112 (epoch  8): loss=0.05898
 2025-10-07 12:22:38,813 - INFO -marigold_trainer.py - train >> iter 17113 (epoch  8): loss=0.05198
 2025-10-07 12:22:55,444 - INFO -marigold_trainer.py - train >> iter 17114 (epoch  8): loss=0.06013
 2025-10-07 12:23:14,034 - INFO -marigold_trainer.py - train >> iter 17115 (epoch  8): loss=0.06741
 2025-10-07 12:23:30,015 - INFO -marigold_trainer.py - train >> iter 17116 (epoch  8): loss=0.06202
 2025-10-07 12:23:44,689 - INFO -marigold_trainer.py - train >> iter 17117 (epoch  8): loss=0.05472
 2025-10-07 12:24:00,000 - INFO -marigold_trainer.py - train >> iter 17118 (epoch  8): loss=0.05963
 2025-10-07 12:24:15,973 - INFO -marigold_trainer.py - train >> iter 17119 (epoch  8): loss=0.05623
 2025-10-07 12:24:31,291 - INFO -marigold_trainer.py - train >> iter 17120 (epoch  8): loss=0.06260
 2025-10-07 12:24:47,915 - INFO -marigold_trainer.py - train >> iter 17121 (epoch  8): loss=0.05622
 2025-10-07 12:25:03,888 - INFO -marigold_trainer.py - train >> iter 17122 (epoch  8): loss=0.05264
 2025-10-07 12:25:19,863 - INFO -marigold_trainer.py - train >> iter 17123 (epoch  8): loss=0.06074
 2025-10-07 12:25:36,494 - INFO -marigold_trainer.py - train >> iter 17124 (epoch  8): loss=0.05244
 2025-10-07 12:25:53,776 - INFO -marigold_trainer.py - train >> iter 17125 (epoch  8): loss=0.06290
 2025-10-07 12:26:09,753 - INFO -marigold_trainer.py - train >> iter 17126 (epoch  8): loss=0.05274
 2025-10-07 12:26:25,078 - INFO -marigold_trainer.py - train >> iter 17127 (epoch  8): loss=0.05126
 2025-10-07 12:26:42,160 - INFO -marigold_trainer.py - train >> iter 17128 (epoch  8): loss=0.05101
 2025-10-07 12:26:58,330 - INFO -marigold_trainer.py - train >> iter 17129 (epoch  8): loss=0.05496
 2025-10-07 12:27:13,658 - INFO -marigold_trainer.py - train >> iter 17130 (epoch  8): loss=0.05393
 2025-10-07 12:27:28,331 - INFO -marigold_trainer.py - train >> iter 17131 (epoch  8): loss=0.06014
 2025-10-07 12:27:43,727 - INFO -marigold_trainer.py - train >> iter 17132 (epoch  8): loss=0.05991
 2025-10-07 12:27:58,392 - INFO -marigold_trainer.py - train >> iter 17133 (epoch  8): loss=0.05901
 2025-10-07 12:28:13,701 - INFO -marigold_trainer.py - train >> iter 17134 (epoch  8): loss=0.06027
 2025-10-07 12:28:30,334 - INFO -marigold_trainer.py - train >> iter 17135 (epoch  8): loss=0.06192
 2025-10-07 12:28:45,654 - INFO -marigold_trainer.py - train >> iter 17136 (epoch  8): loss=0.05836
 2025-10-07 12:29:02,281 - INFO -marigold_trainer.py - train >> iter 17137 (epoch  8): loss=0.06777
 2025-10-07 12:29:18,253 - INFO -marigold_trainer.py - train >> iter 17138 (epoch  8): loss=0.05154
 2025-10-07 12:29:34,882 - INFO -marigold_trainer.py - train >> iter 17139 (epoch  8): loss=0.06397
 2025-10-07 12:29:50,204 - INFO -marigold_trainer.py - train >> iter 17140 (epoch  8): loss=0.05833
 2025-10-07 12:30:06,835 - INFO -marigold_trainer.py - train >> iter 17141 (epoch  8): loss=0.07384
 2025-10-07 12:30:22,162 - INFO -marigold_trainer.py - train >> iter 17142 (epoch  8): loss=0.05850
 2025-10-07 12:30:37,475 - INFO -marigold_trainer.py - train >> iter 17143 (epoch  8): loss=0.06295
 2025-10-07 12:30:52,132 - INFO -marigold_trainer.py - train >> iter 17144 (epoch  8): loss=0.05950
 2025-10-07 12:31:08,740 - INFO -marigold_trainer.py - train >> iter 17145 (epoch  8): loss=0.05792
 2025-10-07 12:31:23,407 - INFO -marigold_trainer.py - train >> iter 17146 (epoch  8): loss=0.06651
 2025-10-07 12:31:39,366 - INFO -marigold_trainer.py - train >> iter 17147 (epoch  8): loss=0.06508
 2025-10-07 12:31:54,024 - INFO -marigold_trainer.py - train >> iter 17148 (epoch  8): loss=0.06534
 2025-10-07 12:32:09,320 - INFO -marigold_trainer.py - train >> iter 17149 (epoch  8): loss=0.06145
 2025-10-07 12:32:24,442 - INFO -marigold_trainer.py - train >> iter 17150 (epoch  8): loss=0.06093
 2025-10-07 12:32:39,957 - INFO -marigold_trainer.py - train >> iter 17151 (epoch  8): loss=0.05273
 2025-10-07 12:32:55,275 - INFO -marigold_trainer.py - train >> iter 17152 (epoch  8): loss=0.06382
 2025-10-07 12:33:11,046 - INFO -marigold_trainer.py - train >> iter 17153 (epoch  8): loss=0.06253
 2025-10-07 12:33:27,238 - INFO -marigold_trainer.py - train >> iter 17154 (epoch  8): loss=0.05779
 2025-10-07 12:33:42,555 - INFO -marigold_trainer.py - train >> iter 17155 (epoch  8): loss=0.06176
 2025-10-07 12:33:58,511 - INFO -marigold_trainer.py - train >> iter 17156 (epoch  8): loss=0.06477
 2025-10-07 12:34:13,178 - INFO -marigold_trainer.py - train >> iter 17157 (epoch  8): loss=0.05885
 2025-10-07 12:34:27,827 - INFO -marigold_trainer.py - train >> iter 17158 (epoch  8): loss=0.05363
 2025-10-07 12:34:43,788 - INFO -marigold_trainer.py - train >> iter 17159 (epoch  8): loss=0.06350
 2025-10-07 12:34:59,769 - INFO -marigold_trainer.py - train >> iter 17160 (epoch  8): loss=0.05660
 2025-10-07 12:35:15,087 - INFO -marigold_trainer.py - train >> iter 17161 (epoch  8): loss=0.05656
 2025-10-07 12:35:31,504 - INFO -marigold_trainer.py - train >> iter 17162 (epoch  8): loss=0.06034
 2025-10-07 12:35:46,377 - INFO -marigold_trainer.py - train >> iter 17163 (epoch  8): loss=0.06636
 2025-10-07 12:36:02,340 - INFO -marigold_trainer.py - train >> iter 17164 (epoch  8): loss=0.06222
 2025-10-07 12:36:18,770 - INFO -marigold_trainer.py - train >> iter 17165 (epoch  8): loss=0.05667
 2025-10-07 12:36:34,293 - INFO -marigold_trainer.py - train >> iter 17166 (epoch  8): loss=0.06424
 2025-10-07 12:36:51,564 - INFO -marigold_trainer.py - train >> iter 17167 (epoch  8): loss=0.06442
 2025-10-07 12:37:07,529 - INFO -marigold_trainer.py - train >> iter 17168 (epoch  8): loss=0.05865
 2025-10-07 12:37:24,807 - INFO -marigold_trainer.py - train >> iter 17169 (epoch  8): loss=0.06573
 2025-10-07 12:37:40,127 - INFO -marigold_trainer.py - train >> iter 17170 (epoch  8): loss=0.06104
 2025-10-07 12:37:56,752 - INFO -marigold_trainer.py - train >> iter 17171 (epoch  8): loss=0.05406
 2025-10-07 12:38:12,735 - INFO -marigold_trainer.py - train >> iter 17172 (epoch  8): loss=0.05515
 2025-10-07 12:38:28,703 - INFO -marigold_trainer.py - train >> iter 17173 (epoch  8): loss=0.06023
 2025-10-07 12:38:45,787 - INFO -marigold_trainer.py - train >> iter 17174 (epoch  8): loss=0.06015
 2025-10-07 12:39:02,624 - INFO -marigold_trainer.py - train >> iter 17175 (epoch  8): loss=0.06253
 2025-10-07 12:39:18,605 - INFO -marigold_trainer.py - train >> iter 17176 (epoch  8): loss=0.06003
 2025-10-07 12:39:33,275 - INFO -marigold_trainer.py - train >> iter 17177 (epoch  8): loss=0.06097
 2025-10-07 12:39:47,920 - INFO -marigold_trainer.py - train >> iter 17178 (epoch  8): loss=0.06214
 2025-10-07 12:40:03,881 - INFO -marigold_trainer.py - train >> iter 17179 (epoch  8): loss=0.06423
 2025-10-07 12:40:20,962 - INFO -marigold_trainer.py - train >> iter 17180 (epoch  8): loss=0.06110
 2025-10-07 12:40:37,138 - INFO -marigold_trainer.py - train >> iter 17181 (epoch  8): loss=0.06172
 2025-10-07 12:40:53,117 - INFO -marigold_trainer.py - train >> iter 17182 (epoch  8): loss=0.06942
 2025-10-07 12:41:07,778 - INFO -marigold_trainer.py - train >> iter 17183 (epoch  8): loss=0.05842
 2025-10-07 12:41:25,045 - INFO -marigold_trainer.py - train >> iter 17184 (epoch  8): loss=0.06562
 2025-10-07 12:41:40,371 - INFO -marigold_trainer.py - train >> iter 17185 (epoch  8): loss=0.05535
 2025-10-07 12:41:56,348 - INFO -marigold_trainer.py - train >> iter 17186 (epoch  8): loss=0.05678
 2025-10-07 12:42:11,008 - INFO -marigold_trainer.py - train >> iter 17187 (epoch  8): loss=0.06336
 2025-10-07 12:42:26,309 - INFO -marigold_trainer.py - train >> iter 17188 (epoch  8): loss=0.05930
 2025-10-07 12:42:41,639 - INFO -marigold_trainer.py - train >> iter 17189 (epoch  8): loss=0.06107
 2025-10-07 12:42:56,308 - INFO -marigold_trainer.py - train >> iter 17190 (epoch  8): loss=0.06019
 2025-10-07 12:43:12,925 - INFO -marigold_trainer.py - train >> iter 17191 (epoch  8): loss=0.05698
 2025-10-07 12:43:28,903 - INFO -marigold_trainer.py - train >> iter 17192 (epoch  8): loss=0.05891
 2025-10-07 12:43:44,225 - INFO -marigold_trainer.py - train >> iter 17193 (epoch  8): loss=0.06184
 2025-10-07 12:44:00,860 - INFO -marigold_trainer.py - train >> iter 17194 (epoch  8): loss=0.05915
 2025-10-07 12:44:17,484 - INFO -marigold_trainer.py - train >> iter 17195 (epoch  8): loss=0.06084
 2025-10-07 12:44:32,814 - INFO -marigold_trainer.py - train >> iter 17196 (epoch  8): loss=0.05990
 2025-10-07 12:44:47,464 - INFO -marigold_trainer.py - train >> iter 17197 (epoch  8): loss=0.06674
 2025-10-07 12:45:02,115 - INFO -marigold_trainer.py - train >> iter 17198 (epoch  8): loss=0.06226
 2025-10-07 12:45:19,379 - INFO -marigold_trainer.py - train >> iter 17199 (epoch  8): loss=0.06437
 2025-10-07 12:45:35,355 - INFO -marigold_trainer.py - train >> iter 17200 (epoch  8): loss=0.06561
 2025-10-07 12:45:50,677 - INFO -marigold_trainer.py - train >> iter 17201 (epoch  8): loss=0.06286
 2025-10-07 12:46:07,318 - INFO -marigold_trainer.py - train >> iter 17202 (epoch  8): loss=0.06583
 2025-10-07 12:46:21,983 - INFO -marigold_trainer.py - train >> iter 17203 (epoch  8): loss=0.05804
 2025-10-07 12:46:36,632 - INFO -marigold_trainer.py - train >> iter 17204 (epoch  8): loss=0.06445
 2025-10-07 12:46:53,040 - INFO -marigold_trainer.py - train >> iter 17205 (epoch  8): loss=0.06931
 2025-10-07 12:47:08,561 - INFO -marigold_trainer.py - train >> iter 17206 (epoch  8): loss=0.04766
 2025-10-07 12:47:24,540 - INFO -marigold_trainer.py - train >> iter 17207 (epoch  8): loss=0.06613
 2025-10-07 12:47:41,166 - INFO -marigold_trainer.py - train >> iter 17208 (epoch  8): loss=0.06021
 2025-10-07 12:47:57,145 - INFO -marigold_trainer.py - train >> iter 17209 (epoch  8): loss=0.05400
 2025-10-07 12:48:11,810 - INFO -marigold_trainer.py - train >> iter 17210 (epoch  8): loss=0.05496
 2025-10-07 12:48:27,771 - INFO -marigold_trainer.py - train >> iter 17211 (epoch  8): loss=0.05746
 2025-10-07 12:48:43,089 - INFO -marigold_trainer.py - train >> iter 17212 (epoch  8): loss=0.05392
 2025-10-07 12:48:58,418 - INFO -marigold_trainer.py - train >> iter 17213 (epoch  8): loss=0.06335
 2025-10-07 12:49:15,707 - INFO -marigold_trainer.py - train >> iter 17214 (epoch  8): loss=0.06384
 2025-10-07 12:49:31,676 - INFO -marigold_trainer.py - train >> iter 17215 (epoch  8): loss=0.05915
 2025-10-07 12:49:46,991 - INFO -marigold_trainer.py - train >> iter 17216 (epoch  8): loss=0.06252
 2025-10-07 12:50:01,664 - INFO -marigold_trainer.py - train >> iter 17217 (epoch  8): loss=0.05186
 2025-10-07 12:50:17,620 - INFO -marigold_trainer.py - train >> iter 17218 (epoch  8): loss=0.06040
 2025-10-07 12:50:33,588 - INFO -marigold_trainer.py - train >> iter 17219 (epoch  8): loss=0.06189
 2025-10-07 12:50:48,916 - INFO -marigold_trainer.py - train >> iter 17220 (epoch  8): loss=0.06196
 2025-10-07 12:51:04,696 - INFO -marigold_trainer.py - train >> iter 17221 (epoch  8): loss=0.06268
 2025-10-07 12:51:21,528 - INFO -marigold_trainer.py - train >> iter 17222 (epoch  8): loss=0.06005
 2025-10-07 12:51:36,187 - INFO -marigold_trainer.py - train >> iter 17223 (epoch  8): loss=0.05023
 2025-10-07 12:51:51,487 - INFO -marigold_trainer.py - train >> iter 17224 (epoch  8): loss=0.05885
 2025-10-07 12:52:07,465 - INFO -marigold_trainer.py - train >> iter 17225 (epoch  8): loss=0.06369
 2025-10-07 12:52:22,130 - INFO -marigold_trainer.py - train >> iter 17226 (epoch  8): loss=0.04968
 2025-10-07 12:52:38,085 - INFO -marigold_trainer.py - train >> iter 17227 (epoch  8): loss=0.05348
 2025-10-07 12:52:55,369 - INFO -marigold_trainer.py - train >> iter 17228 (epoch  8): loss=0.05781
 2025-10-07 12:53:10,047 - INFO -marigold_trainer.py - train >> iter 17229 (epoch  8): loss=0.06499
 2025-10-07 12:53:26,653 - INFO -marigold_trainer.py - train >> iter 17230 (epoch  8): loss=0.06001
 2025-10-07 12:53:42,070 - INFO -marigold_trainer.py - train >> iter 17231 (epoch  8): loss=0.06343
 2025-10-07 12:53:57,371 - INFO -marigold_trainer.py - train >> iter 17232 (epoch  8): loss=0.05994
 2025-10-07 12:54:12,691 - INFO -marigold_trainer.py - train >> iter 17233 (epoch  8): loss=0.05421
 2025-10-07 12:54:27,364 - INFO -marigold_trainer.py - train >> iter 17234 (epoch  8): loss=0.05789
 2025-10-07 12:54:43,318 - INFO -marigold_trainer.py - train >> iter 17235 (epoch  8): loss=0.06774
 2025-10-07 12:54:57,995 - INFO -marigold_trainer.py - train >> iter 17236 (epoch  8): loss=0.07031
 2025-10-07 12:55:14,408 - INFO -marigold_trainer.py - train >> iter 17237 (epoch  8): loss=0.05766
 2025-10-07 12:55:30,585 - INFO -marigold_trainer.py - train >> iter 17238 (epoch  8): loss=0.06382
 2025-10-07 12:55:47,215 - INFO -marigold_trainer.py - train >> iter 17239 (epoch  8): loss=0.07015
 2025-10-07 12:56:01,885 - INFO -marigold_trainer.py - train >> iter 17240 (epoch  8): loss=0.05319
 2025-10-07 12:56:17,841 - INFO -marigold_trainer.py - train >> iter 17241 (epoch  8): loss=0.06349
 2025-10-07 12:56:32,519 - INFO -marigold_trainer.py - train >> iter 17242 (epoch  8): loss=0.06331
 2025-10-07 12:56:48,481 - INFO -marigold_trainer.py - train >> iter 17243 (epoch  8): loss=0.06319
 2025-10-07 12:57:03,155 - INFO -marigold_trainer.py - train >> iter 17244 (epoch  8): loss=0.05524
 2025-10-07 12:57:18,461 - INFO -marigold_trainer.py - train >> iter 17245 (epoch  8): loss=0.06150
 2025-10-07 12:57:33,787 - INFO -marigold_trainer.py - train >> iter 17246 (epoch  8): loss=0.05618
 2025-10-07 12:57:51,067 - INFO -marigold_trainer.py - train >> iter 17247 (epoch  8): loss=0.06392
 2025-10-07 12:58:06,832 - INFO -marigold_trainer.py - train >> iter 17248 (epoch  8): loss=0.05541
 2025-10-07 12:58:23,665 - INFO -marigold_trainer.py - train >> iter 17249 (epoch  8): loss=0.05960
 2025-10-07 12:58:39,641 - INFO -marigold_trainer.py - train >> iter 17250 (epoch  8): loss=0.06328
 2025-10-07 12:58:39,642 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: output/train_marigold/checkpoint/latest
 2025-10-07 12:58:39,642 - DEBUG -marigold_trainer.py - save_checkpoint >> Old checkpoint is backed up at: output/train_marigold/checkpoint/_old_latest
 2025-10-07 12:58:42,985 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: output/train_marigold/checkpoint/latest/unet
 2025-10-07 12:58:49,246 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: output/train_marigold/checkpoint/latest/trainer.ckpt
 2025-10-07 12:58:49,889 - DEBUG -marigold_trainer.py - save_checkpoint >> Old checkpoint backup is removed.
 2025-10-07 12:59:06,024 - INFO -marigold_trainer.py - train >> iter 17251 (epoch  8): loss=0.05572
 2025-10-07 12:59:21,551 - INFO -marigold_trainer.py - train >> iter 17252 (epoch  8): loss=0.05359
 2025-10-07 12:59:36,855 - INFO -marigold_trainer.py - train >> iter 17253 (epoch  8): loss=0.05536
 2025-10-07 12:59:54,153 - INFO -marigold_trainer.py - train >> iter 17254 (epoch  8): loss=0.05078
 2025-10-07 13:00:10,138 - INFO -marigold_trainer.py - train >> iter 17255 (epoch  8): loss=0.06500
 2025-10-07 13:00:26,778 - INFO -marigold_trainer.py - train >> iter 17256 (epoch  8): loss=0.06420
 2025-10-07 13:00:42,109 - INFO -marigold_trainer.py - train >> iter 17257 (epoch  8): loss=0.05250
 2025-10-07 13:00:57,439 - INFO -marigold_trainer.py - train >> iter 17258 (epoch  8): loss=0.06439
 2025-10-07 13:01:14,085 - INFO -marigold_trainer.py - train >> iter 17259 (epoch  8): loss=0.06760
 2025-10-07 13:01:30,706 - INFO -marigold_trainer.py - train >> iter 17260 (epoch  8): loss=0.05850
 2025-10-07 13:01:46,028 - INFO -marigold_trainer.py - train >> iter 17261 (epoch  8): loss=0.06011
 2025-10-07 13:02:02,012 - INFO -marigold_trainer.py - train >> iter 17262 (epoch  8): loss=0.07144
 2025-10-07 13:02:17,315 - INFO -marigold_trainer.py - train >> iter 17263 (epoch  8): loss=0.06026
 2025-10-07 13:02:33,936 - INFO -marigold_trainer.py - train >> iter 17264 (epoch  8): loss=0.06708
 2025-10-07 13:02:48,607 - INFO -marigold_trainer.py - train >> iter 17265 (epoch  8): loss=0.05895
 2025-10-07 13:03:05,880 - INFO -marigold_trainer.py - train >> iter 17266 (epoch  8): loss=0.06154
 2025-10-07 13:03:21,200 - INFO -marigold_trainer.py - train >> iter 17267 (epoch  8): loss=0.05006
 2025-10-07 13:03:36,520 - INFO -marigold_trainer.py - train >> iter 17268 (epoch  8): loss=0.05475
 2025-10-07 13:03:54,454 - INFO -marigold_trainer.py - train >> iter 17269 (epoch  8): loss=0.05845
 2025-10-07 13:04:09,763 - INFO -marigold_trainer.py - train >> iter 17270 (epoch  8): loss=0.05555
 2025-10-07 13:04:25,728 - INFO -marigold_trainer.py - train >> iter 17271 (epoch  8): loss=0.06527
 2025-10-07 13:04:41,052 - INFO -marigold_trainer.py - train >> iter 17272 (epoch  8): loss=0.05776
 2025-10-07 13:04:57,008 - INFO -marigold_trainer.py - train >> iter 17273 (epoch  8): loss=0.06041
 2025-10-07 13:05:13,639 - INFO -marigold_trainer.py - train >> iter 17274 (epoch  8): loss=0.06717
 2025-10-07 13:05:28,313 - INFO -marigold_trainer.py - train >> iter 17275 (epoch  8): loss=0.06199
 2025-10-07 13:05:44,922 - INFO -marigold_trainer.py - train >> iter 17276 (epoch  8): loss=0.06552
 2025-10-07 13:06:00,904 - INFO -marigold_trainer.py - train >> iter 17277 (epoch  8): loss=0.06567
 2025-10-07 13:06:16,875 - INFO -marigold_trainer.py - train >> iter 17278 (epoch  8): loss=0.05213
 2025-10-07 13:06:32,861 - INFO -marigold_trainer.py - train >> iter 17279 (epoch  8): loss=0.05447
 2025-10-07 13:06:48,840 - INFO -marigold_trainer.py - train >> iter 17280 (epoch  8): loss=0.06016
 2025-10-07 13:07:03,507 - INFO -marigold_trainer.py - train >> iter 17281 (epoch  8): loss=0.05410
 2025-10-07 13:07:20,112 - INFO -marigold_trainer.py - train >> iter 17282 (epoch  8): loss=0.05855
 2025-10-07 13:07:35,429 - INFO -marigold_trainer.py - train >> iter 17283 (epoch  8): loss=0.05532
 2025-10-07 13:07:50,751 - INFO -marigold_trainer.py - train >> iter 17284 (epoch  8): loss=0.06590
 2025-10-07 13:08:05,407 - INFO -marigold_trainer.py - train >> iter 17285 (epoch  8): loss=0.05531
 2025-10-07 13:08:20,710 - INFO -marigold_trainer.py - train >> iter 17286 (epoch  8): loss=0.05673
 2025-10-07 13:08:36,690 - INFO -marigold_trainer.py - train >> iter 17287 (epoch  8): loss=0.05535
 2025-10-07 13:08:52,011 - INFO -marigold_trainer.py - train >> iter 17288 (epoch  8): loss=0.06037
 2025-10-07 13:09:07,982 - INFO -marigold_trainer.py - train >> iter 17289 (epoch  8): loss=0.06031
 2025-10-07 13:09:22,648 - INFO -marigold_trainer.py - train >> iter 17290 (epoch  8): loss=0.06072
 2025-10-07 13:09:37,950 - INFO -marigold_trainer.py - train >> iter 17291 (epoch  8): loss=0.05987
 2025-10-07 13:09:54,364 - INFO -marigold_trainer.py - train >> iter 17292 (epoch  8): loss=0.06447
 2025-10-07 13:10:11,837 - INFO -marigold_trainer.py - train >> iter 17293 (epoch  8): loss=0.05730
 2025-10-07 13:10:27,153 - INFO -marigold_trainer.py - train >> iter 17294 (epoch  8): loss=0.06539
 2025-10-07 13:10:43,127 - INFO -marigold_trainer.py - train >> iter 17295 (epoch  8): loss=0.05565
 2025-10-07 13:10:57,788 - INFO -marigold_trainer.py - train >> iter 17296 (epoch  8): loss=0.07100
 2025-10-07 13:11:14,402 - INFO -marigold_trainer.py - train >> iter 17297 (epoch  8): loss=0.06219
 2025-10-07 13:11:29,726 - INFO -marigold_trainer.py - train >> iter 17298 (epoch  8): loss=0.06000
 2025-10-07 13:11:46,356 - INFO -marigold_trainer.py - train >> iter 17299 (epoch  8): loss=0.05414
 2025-10-07 13:12:01,680 - INFO -marigold_trainer.py - train >> iter 17300 (epoch  8): loss=0.05654
 2025-10-07 13:12:17,653 - INFO -marigold_trainer.py - train >> iter 17301 (epoch  8): loss=0.06108
 2025-10-07 13:12:32,309 - INFO -marigold_trainer.py - train >> iter 17302 (epoch  8): loss=0.05270
 2025-10-07 13:12:47,406 - INFO -marigold_trainer.py - train >> iter 17303 (epoch  8): loss=0.06320
 2025-10-07 13:13:02,928 - INFO -marigold_trainer.py - train >> iter 17304 (epoch  8): loss=0.05532
 2025-10-07 13:13:18,702 - INFO -marigold_trainer.py - train >> iter 17305 (epoch  8): loss=0.06275
 2025-10-07 13:13:34,879 - INFO -marigold_trainer.py - train >> iter 17306 (epoch  8): loss=0.05567
 2025-10-07 13:13:49,551 - INFO -marigold_trainer.py - train >> iter 17307 (epoch  8): loss=0.05637
 2025-10-07 13:14:04,855 - INFO -marigold_trainer.py - train >> iter 17308 (epoch  8): loss=0.05427
 2025-10-07 13:14:20,184 - INFO -marigold_trainer.py - train >> iter 17309 (epoch  8): loss=0.06037
 2025-10-07 13:14:35,495 - INFO -marigold_trainer.py - train >> iter 17310 (epoch  8): loss=0.05839
 2025-10-07 13:14:50,823 - INFO -marigold_trainer.py - train >> iter 17311 (epoch  8): loss=0.05409
 2025-10-07 13:15:06,143 - INFO -marigold_trainer.py - train >> iter 17312 (epoch  8): loss=0.06219
 2025-10-07 13:15:21,460 - INFO -marigold_trainer.py - train >> iter 17313 (epoch  8): loss=0.05946
 2025-10-07 13:15:36,789 - INFO -marigold_trainer.py - train >> iter 17314 (epoch  8): loss=0.05542
 2025-10-07 13:15:53,414 - INFO -marigold_trainer.py - train >> iter 17315 (epoch  8): loss=0.05617
 2025-10-07 13:16:10,033 - INFO -marigold_trainer.py - train >> iter 17316 (epoch  8): loss=0.06019
 2025-10-07 13:16:26,005 - INFO -marigold_trainer.py - train >> iter 17317 (epoch  8): loss=0.06661
 2025-10-07 13:16:41,323 - INFO -marigold_trainer.py - train >> iter 17318 (epoch  8): loss=0.06173
 2025-10-07 13:16:57,945 - INFO -marigold_trainer.py - train >> iter 17319 (epoch  8): loss=0.06876
 2025-10-07 13:17:13,934 - INFO -marigold_trainer.py - train >> iter 17320 (epoch  8): loss=0.05801
 2025-10-07 13:17:30,572 - INFO -marigold_trainer.py - train >> iter 17321 (epoch  8): loss=0.06291
 2025-10-07 13:17:45,893 - INFO -marigold_trainer.py - train >> iter 17322 (epoch  8): loss=0.05808
 2025-10-07 13:18:01,213 - INFO -marigold_trainer.py - train >> iter 17323 (epoch  8): loss=0.05456
 2025-10-07 13:18:15,962 - INFO -marigold_trainer.py - train >> iter 17324 (epoch  8): loss=0.05985
 2025-10-07 13:18:30,614 - INFO -marigold_trainer.py - train >> iter 17325 (epoch  8): loss=0.05481
 2025-10-07 13:18:47,222 - INFO -marigold_trainer.py - train >> iter 17326 (epoch  8): loss=0.06475
 2025-10-07 13:19:02,545 - INFO -marigold_trainer.py - train >> iter 17327 (epoch  8): loss=0.05563
 2025-10-07 13:19:17,871 - INFO -marigold_trainer.py - train >> iter 17328 (epoch  8): loss=0.05677
 2025-10-07 13:19:33,191 - INFO -marigold_trainer.py - train >> iter 17329 (epoch  8): loss=0.05112
 2025-10-07 13:19:49,805 - INFO -marigold_trainer.py - train >> iter 17330 (epoch  8): loss=0.05617
 2025-10-07 13:20:04,477 - INFO -marigold_trainer.py - train >> iter 17331 (epoch  8): loss=0.06161
 2025-10-07 13:20:21,093 - INFO -marigold_trainer.py - train >> iter 17332 (epoch  8): loss=0.05486
 2025-10-07 13:20:36,419 - INFO -marigold_trainer.py - train >> iter 17333 (epoch  8): loss=0.06964
 2025-10-07 13:20:52,403 - INFO -marigold_trainer.py - train >> iter 17334 (epoch  8): loss=0.05565
 2025-10-07 13:21:08,389 - INFO -marigold_trainer.py - train >> iter 17335 (epoch  8): loss=0.06117
 2025-10-07 13:21:23,722 - INFO -marigold_trainer.py - train >> iter 17336 (epoch  8): loss=0.05827
 2025-10-07 13:21:40,349 - INFO -marigold_trainer.py - train >> iter 17337 (epoch  8): loss=0.06321
 2025-10-07 13:21:58,091 - INFO -marigold_trainer.py - train >> iter 17338 (epoch  8): loss=0.06047
 2025-10-07 13:22:15,571 - INFO -marigold_trainer.py - train >> iter 17339 (epoch  8): loss=0.05348
 2025-10-07 13:22:32,196 - INFO -marigold_trainer.py - train >> iter 17340 (epoch  8): loss=0.06482
 2025-10-07 13:22:49,477 - INFO -marigold_trainer.py - train >> iter 17341 (epoch  8): loss=0.05540
 2025-10-07 13:23:06,108 - INFO -marigold_trainer.py - train >> iter 17342 (epoch  8): loss=0.05644
 2025-10-07 13:23:22,088 - INFO -marigold_trainer.py - train >> iter 17343 (epoch  8): loss=0.06059
 2025-10-07 13:23:37,412 - INFO -marigold_trainer.py - train >> iter 17344 (epoch  8): loss=0.05786
 2025-10-07 13:23:53,393 - INFO -marigold_trainer.py - train >> iter 17345 (epoch  8): loss=0.05341
 2025-10-07 13:24:08,710 - INFO -marigold_trainer.py - train >> iter 17346 (epoch  8): loss=0.05439
 2025-10-07 13:24:24,032 - INFO -marigold_trainer.py - train >> iter 17347 (epoch  8): loss=0.06108
 2025-10-07 13:24:40,654 - INFO -marigold_trainer.py - train >> iter 17348 (epoch  8): loss=0.05530
 2025-10-07 13:24:56,639 - INFO -marigold_trainer.py - train >> iter 17349 (epoch  8): loss=0.06392
 2025-10-07 13:25:11,972 - INFO -marigold_trainer.py - train >> iter 17350 (epoch  8): loss=0.06245
 2025-10-07 13:25:27,949 - INFO -marigold_trainer.py - train >> iter 17351 (epoch  8): loss=0.06681
 2025-10-07 13:25:42,616 - INFO -marigold_trainer.py - train >> iter 17352 (epoch  8): loss=0.06009
 2025-10-07 13:25:57,267 - INFO -marigold_trainer.py - train >> iter 17353 (epoch  8): loss=0.05690
 2025-10-07 13:26:13,223 - INFO -marigold_trainer.py - train >> iter 17354 (epoch  8): loss=0.05703
 2025-10-07 13:26:28,538 - INFO -marigold_trainer.py - train >> iter 17355 (epoch  8): loss=0.05996
 2025-10-07 13:26:43,858 - INFO -marigold_trainer.py - train >> iter 17356 (epoch  8): loss=0.05394
 2025-10-07 13:27:00,480 - INFO -marigold_trainer.py - train >> iter 17357 (epoch  8): loss=0.06167
 2025-10-07 13:27:16,251 - INFO -marigold_trainer.py - train >> iter 17358 (epoch  8): loss=0.05809
 2025-10-07 13:27:32,444 - INFO -marigold_trainer.py - train >> iter 17359 (epoch  8): loss=0.05651
 2025-10-07 13:27:49,080 - INFO -marigold_trainer.py - train >> iter 17360 (epoch  8): loss=0.07636
 2025-10-07 13:28:05,706 - INFO -marigold_trainer.py - train >> iter 17361 (epoch  8): loss=0.06170
 2025-10-07 13:28:21,666 - INFO -marigold_trainer.py - train >> iter 17362 (epoch  8): loss=0.06066
 2025-10-07 13:28:37,649 - INFO -marigold_trainer.py - train >> iter 17363 (epoch  8): loss=0.06539
 2025-10-07 13:28:52,967 - INFO -marigold_trainer.py - train >> iter 17364 (epoch  8): loss=0.06039
 2025-10-07 13:29:08,283 - INFO -marigold_trainer.py - train >> iter 17365 (epoch  8): loss=0.05244
 2025-10-07 13:29:24,256 - INFO -marigold_trainer.py - train >> iter 17366 (epoch  8): loss=0.05819
 2025-10-07 13:29:40,242 - INFO -marigold_trainer.py - train >> iter 17367 (epoch  8): loss=0.06263
 2025-10-07 13:29:56,220 - INFO -marigold_trainer.py - train >> iter 17368 (epoch  8): loss=0.05563
 2025-10-07 13:30:12,653 - INFO -marigold_trainer.py - train >> iter 17369 (epoch  8): loss=0.06862
 2025-10-07 13:30:29,490 - INFO -marigold_trainer.py - train >> iter 17370 (epoch  8): loss=0.05587
 2025-10-07 13:30:44,164 - INFO -marigold_trainer.py - train >> iter 17371 (epoch  8): loss=0.05264
 2025-10-07 13:31:00,115 - INFO -marigold_trainer.py - train >> iter 17372 (epoch  8): loss=0.06245
 2025-10-07 13:31:15,438 - INFO -marigold_trainer.py - train >> iter 17373 (epoch  8): loss=0.06210
 2025-10-07 13:31:31,415 - INFO -marigold_trainer.py - train >> iter 17374 (epoch  8): loss=0.05973
 2025-10-07 13:31:46,741 - INFO -marigold_trainer.py - train >> iter 17375 (epoch  8): loss=0.05651
 2025-10-07 13:32:01,412 - INFO -marigold_trainer.py - train >> iter 17376 (epoch  8): loss=0.04709
 2025-10-07 13:32:17,373 - INFO -marigold_trainer.py - train >> iter 17377 (epoch  8): loss=0.05468
 2025-10-07 13:32:33,801 - INFO -marigold_trainer.py - train >> iter 17378 (epoch  8): loss=0.05582
 2025-10-07 13:32:48,676 - INFO -marigold_trainer.py - train >> iter 17379 (epoch  8): loss=0.04949
 2025-10-07 13:33:03,325 - INFO -marigold_trainer.py - train >> iter 17380 (epoch  8): loss=0.05365
 2025-10-07 13:33:17,977 - INFO -marigold_trainer.py - train >> iter 17381 (epoch  8): loss=0.05051
 2025-10-07 13:33:34,592 - INFO -marigold_trainer.py - train >> iter 17382 (epoch  8): loss=0.05862
 2025-10-07 13:33:51,883 - INFO -marigold_trainer.py - train >> iter 17383 (epoch  8): loss=0.05869
 2025-10-07 13:34:07,212 - INFO -marigold_trainer.py - train >> iter 17384 (epoch  8): loss=0.05879
 2025-10-07 13:34:23,193 - INFO -marigold_trainer.py - train >> iter 17385 (epoch  8): loss=0.05829
 2025-10-07 13:34:37,862 - INFO -marigold_trainer.py - train >> iter 17386 (epoch  8): loss=0.05473
 2025-10-07 13:34:52,509 - INFO -marigold_trainer.py - train >> iter 17387 (epoch  8): loss=0.05099
 2025-10-07 13:35:07,154 - INFO -marigold_trainer.py - train >> iter 17388 (epoch  8): loss=0.05222
 2025-10-07 13:35:22,453 - INFO -marigold_trainer.py - train >> iter 17389 (epoch  8): loss=0.05938
 2025-10-07 13:35:38,422 - INFO -marigold_trainer.py - train >> iter 17390 (epoch  8): loss=0.05589
 2025-10-07 13:35:53,095 - INFO -marigold_trainer.py - train >> iter 17391 (epoch  8): loss=0.05499
 2025-10-07 13:36:08,398 - INFO -marigold_trainer.py - train >> iter 17392 (epoch  8): loss=0.06066
 2025-10-07 13:36:23,067 - INFO -marigold_trainer.py - train >> iter 17393 (epoch  8): loss=0.06175
 2025-10-07 13:36:38,367 - INFO -marigold_trainer.py - train >> iter 17394 (epoch  8): loss=0.05628
 2025-10-07 13:36:54,345 - INFO -marigold_trainer.py - train >> iter 17395 (epoch  8): loss=0.06492
 2025-10-07 13:37:09,677 - INFO -marigold_trainer.py - train >> iter 17396 (epoch  8): loss=0.06219
 2025-10-07 13:37:25,662 - INFO -marigold_trainer.py - train >> iter 17397 (epoch  8): loss=0.06246
 2025-10-07 13:37:40,980 - INFO -marigold_trainer.py - train >> iter 17398 (epoch  8): loss=0.06549
 2025-10-07 13:37:56,308 - INFO -marigold_trainer.py - train >> iter 17399 (epoch  8): loss=0.06186
 2025-10-07 13:38:11,613 - INFO -marigold_trainer.py - train >> iter 17400 (epoch  8): loss=0.05848
 2025-10-07 13:38:27,380 - INFO -marigold_trainer.py - train >> iter 17401 (epoch  8): loss=0.05937
 2025-10-07 13:38:44,214 - INFO -marigold_trainer.py - train >> iter 17402 (epoch  8): loss=0.05690
 2025-10-07 13:39:02,155 - INFO -marigold_trainer.py - train >> iter 17403 (epoch  8): loss=0.06228
 2025-10-07 13:39:18,127 - INFO -marigold_trainer.py - train >> iter 17404 (epoch  8): loss=0.05905
 2025-10-07 13:39:34,765 - INFO -marigold_trainer.py - train >> iter 17405 (epoch  8): loss=0.06189
 2025-10-07 13:39:49,421 - INFO -marigold_trainer.py - train >> iter 17406 (epoch  8): loss=0.05405
 2025-10-07 13:40:04,722 - INFO -marigold_trainer.py - train >> iter 17407 (epoch  8): loss=0.05887
 2025-10-07 13:40:21,352 - INFO -marigold_trainer.py - train >> iter 17408 (epoch  8): loss=0.05548
 2025-10-07 13:40:37,990 - INFO -marigold_trainer.py - train >> iter 17409 (epoch  8): loss=0.06214
 2025-10-07 13:40:53,965 - INFO -marigold_trainer.py - train >> iter 17410 (epoch  8): loss=0.06221
 2025-10-07 13:41:09,285 - INFO -marigold_trainer.py - train >> iter 17411 (epoch  8): loss=0.05701
 2025-10-07 13:41:23,945 - INFO -marigold_trainer.py - train >> iter 17412 (epoch  8): loss=0.05739
 2025-10-07 13:41:39,906 - INFO -marigold_trainer.py - train >> iter 17413 (epoch  8): loss=0.05763
 2025-10-07 13:41:56,538 - INFO -marigold_trainer.py - train >> iter 17414 (epoch  8): loss=0.05422
 2025-10-07 13:42:11,855 - INFO -marigold_trainer.py - train >> iter 17415 (epoch  8): loss=0.06162
 2025-10-07 13:42:28,489 - INFO -marigold_trainer.py - train >> iter 17416 (epoch  8): loss=0.06369
 2025-10-07 13:42:43,799 - INFO -marigold_trainer.py - train >> iter 17417 (epoch  8): loss=0.06745
 2025-10-07 13:43:00,436 - INFO -marigold_trainer.py - train >> iter 17418 (epoch  8): loss=0.06389
 2025-10-07 13:43:15,763 - INFO -marigold_trainer.py - train >> iter 17419 (epoch  8): loss=0.07074
 2025-10-07 13:43:31,739 - INFO -marigold_trainer.py - train >> iter 17420 (epoch  8): loss=0.06832
 2025-10-07 13:43:47,714 - INFO -marigold_trainer.py - train >> iter 17421 (epoch  8): loss=0.05582
 2025-10-07 13:44:03,043 - INFO -marigold_trainer.py - train >> iter 17422 (epoch  8): loss=0.06204
 2025-10-07 13:44:19,110 - INFO -marigold_trainer.py - train >> iter 17423 (epoch  8): loss=0.05968
 2025-10-07 13:44:33,779 - INFO -marigold_trainer.py - train >> iter 17424 (epoch  8): loss=0.05542
 2025-10-07 13:44:50,384 - INFO -marigold_trainer.py - train >> iter 17425 (epoch  8): loss=0.05482
 2025-10-07 13:45:05,717 - INFO -marigold_trainer.py - train >> iter 17426 (epoch  8): loss=0.05886
 2025-10-07 13:45:21,675 - INFO -marigold_trainer.py - train >> iter 17427 (epoch  8): loss=0.06227
 2025-10-07 13:45:36,996 - INFO -marigold_trainer.py - train >> iter 17428 (epoch  8): loss=0.06249
 2025-10-07 13:45:51,664 - INFO -marigold_trainer.py - train >> iter 17429 (epoch  8): loss=0.07158
 2025-10-07 13:46:06,315 - INFO -marigold_trainer.py - train >> iter 17430 (epoch  8): loss=0.05988
 2025-10-07 13:46:22,268 - INFO -marigold_trainer.py - train >> iter 17431 (epoch  8): loss=0.05635
 2025-10-07 13:46:37,583 - INFO -marigold_trainer.py - train >> iter 17432 (epoch  8): loss=0.06399
 2025-10-07 13:46:54,214 - INFO -marigold_trainer.py - train >> iter 17433 (epoch  8): loss=0.07056
 2025-10-07 13:47:10,197 - INFO -marigold_trainer.py - train >> iter 17434 (epoch  8): loss=0.04497
 2025-10-07 13:47:26,178 - INFO -marigold_trainer.py - train >> iter 17435 (epoch  8): loss=0.05348
 2025-10-07 13:47:42,159 - INFO -marigold_trainer.py - train >> iter 17436 (epoch  8): loss=0.05971
 2025-10-07 13:47:57,475 - INFO -marigold_trainer.py - train >> iter 17437 (epoch  8): loss=0.06028
 2025-10-07 13:48:12,797 - INFO -marigold_trainer.py - train >> iter 17438 (epoch  8): loss=0.05851
 2025-10-07 13:48:27,472 - INFO -marigold_trainer.py - train >> iter 17439 (epoch  8): loss=0.06161
 2025-10-07 13:48:43,427 - INFO -marigold_trainer.py - train >> iter 17440 (epoch  8): loss=0.07403
 2025-10-07 13:48:58,091 - INFO -marigold_trainer.py - train >> iter 17441 (epoch  8): loss=0.05771
 2025-10-07 13:49:13,396 - INFO -marigold_trainer.py - train >> iter 17442 (epoch  8): loss=0.05792
 2025-10-07 13:49:30,023 - INFO -marigold_trainer.py - train >> iter 17443 (epoch  8): loss=0.06167
 2025-10-07 13:49:45,353 - INFO -marigold_trainer.py - train >> iter 17444 (epoch  8): loss=0.05760
 2025-10-07 13:50:01,326 - INFO -marigold_trainer.py - train >> iter 17445 (epoch  8): loss=0.06156
 2025-10-07 13:50:16,648 - INFO -marigold_trainer.py - train >> iter 17446 (epoch  8): loss=0.06031
 2025-10-07 13:50:31,978 - INFO -marigold_trainer.py - train >> iter 17447 (epoch  8): loss=0.06027
 2025-10-07 13:50:49,270 - INFO -marigold_trainer.py - train >> iter 17448 (epoch  8): loss=0.05163
 2025-10-07 13:51:06,567 - INFO -marigold_trainer.py - train >> iter 17449 (epoch  8): loss=0.06521
 2025-10-07 13:51:22,994 - INFO -marigold_trainer.py - train >> iter 17450 (epoch  8): loss=0.05540
 2025-10-07 13:51:38,516 - INFO -marigold_trainer.py - train >> iter 17451 (epoch  8): loss=0.06515
 2025-10-07 13:51:54,481 - INFO -marigold_trainer.py - train >> iter 17452 (epoch  8): loss=0.06107
 2025-10-07 13:52:09,158 - INFO -marigold_trainer.py - train >> iter 17453 (epoch  8): loss=0.06354
 2025-10-07 13:52:24,468 - INFO -marigold_trainer.py - train >> iter 17454 (epoch  8): loss=0.06098
 2025-10-07 13:52:40,452 - INFO -marigold_trainer.py - train >> iter 17455 (epoch  8): loss=0.05619
 2025-10-07 13:52:55,776 - INFO -marigold_trainer.py - train >> iter 17456 (epoch  8): loss=0.05693
 2025-10-07 13:53:11,751 - INFO -marigold_trainer.py - train >> iter 17457 (epoch  8): loss=0.05732
 2025-10-07 13:53:26,434 - INFO -marigold_trainer.py - train >> iter 17458 (epoch  8): loss=0.06033
 2025-10-07 13:53:43,044 - INFO -marigold_trainer.py - train >> iter 17459 (epoch  8): loss=0.06133
 2025-10-07 13:53:58,370 - INFO -marigold_trainer.py - train >> iter 17460 (epoch  8): loss=0.05839
 2025-10-07 13:54:15,006 - INFO -marigold_trainer.py - train >> iter 17461 (epoch  8): loss=0.06330
 2025-10-07 13:54:30,790 - INFO -marigold_trainer.py - train >> iter 17462 (epoch  8): loss=0.05671
 2025-10-07 13:54:46,312 - INFO -marigold_trainer.py - train >> iter 17463 (epoch  8): loss=0.06059
 2025-10-07 13:55:02,297 - INFO -marigold_trainer.py - train >> iter 17464 (epoch  8): loss=0.06087
 2025-10-07 13:55:16,963 - INFO -marigold_trainer.py - train >> iter 17465 (epoch  8): loss=0.05947
 2025-10-07 13:55:32,263 - INFO -marigold_trainer.py - train >> iter 17466 (epoch  8): loss=0.06602
 2025-10-07 13:55:48,886 - INFO -marigold_trainer.py - train >> iter 17467 (epoch  8): loss=0.05382
 2025-10-07 13:56:03,559 - INFO -marigold_trainer.py - train >> iter 17468 (epoch  8): loss=0.05105
 2025-10-07 13:56:18,865 - INFO -marigold_trainer.py - train >> iter 17469 (epoch  8): loss=0.05748
 2025-10-07 13:56:35,506 - INFO -marigold_trainer.py - train >> iter 17470 (epoch  8): loss=0.05639
 2025-10-07 13:56:51,493 - INFO -marigold_trainer.py - train >> iter 17471 (epoch  8): loss=0.05234
 2025-10-07 13:57:06,167 - INFO -marigold_trainer.py - train >> iter 17472 (epoch  8): loss=0.05250
 2025-10-07 13:57:20,815 - INFO -marigold_trainer.py - train >> iter 17473 (epoch  8): loss=0.05481
 2025-10-07 13:57:35,466 - INFO -marigold_trainer.py - train >> iter 17474 (epoch  8): loss=0.06208
 2025-10-07 13:57:51,427 - INFO -marigold_trainer.py - train >> iter 17475 (epoch  8): loss=0.06346
 2025-10-07 13:58:06,752 - INFO -marigold_trainer.py - train >> iter 17476 (epoch  8): loss=0.06647
 2025-10-07 13:58:23,380 - INFO -marigold_trainer.py - train >> iter 17477 (epoch  8): loss=0.05174
 2025-10-07 13:58:39,365 - INFO -marigold_trainer.py - train >> iter 17478 (epoch  8): loss=0.06331
 2025-10-07 13:58:54,684 - INFO -marigold_trainer.py - train >> iter 17479 (epoch  8): loss=0.06156
 2025-10-07 13:59:09,989 - INFO -marigold_trainer.py - train >> iter 17480 (epoch  8): loss=0.05861
 2025-10-07 13:59:25,958 - INFO -marigold_trainer.py - train >> iter 17481 (epoch  8): loss=0.05346
 2025-10-07 13:59:42,586 - INFO -marigold_trainer.py - train >> iter 17482 (epoch  8): loss=0.06835
 2025-10-07 13:59:57,911 - INFO -marigold_trainer.py - train >> iter 17483 (epoch  8): loss=0.06171
 2025-10-07 14:00:15,182 - INFO -marigold_trainer.py - train >> iter 17484 (epoch  8): loss=0.06550
 2025-10-07 14:00:31,802 - INFO -marigold_trainer.py - train >> iter 17485 (epoch  8): loss=0.06049
 2025-10-07 14:00:47,774 - INFO -marigold_trainer.py - train >> iter 17486 (epoch  8): loss=0.06239
 2025-10-07 14:01:03,549 - INFO -marigold_trainer.py - train >> iter 17487 (epoch  8): loss=0.06161
 2025-10-07 14:01:19,071 - INFO -marigold_trainer.py - train >> iter 17488 (epoch  8): loss=0.05398
 2025-10-07 14:01:35,708 - INFO -marigold_trainer.py - train >> iter 17489 (epoch  8): loss=0.05228
 2025-10-07 14:01:51,681 - INFO -marigold_trainer.py - train >> iter 17490 (epoch  8): loss=0.06359
 2025-10-07 14:02:08,313 - INFO -marigold_trainer.py - train >> iter 17491 (epoch  8): loss=0.05909
 2025-10-07 14:02:22,977 - INFO -marigold_trainer.py - train >> iter 17492 (epoch  8): loss=0.05834
 2025-10-07 14:02:38,276 - INFO -marigold_trainer.py - train >> iter 17493 (epoch  8): loss=0.05243
 2025-10-07 14:02:54,045 - INFO -marigold_trainer.py - train >> iter 17494 (epoch  8): loss=0.06135
 2025-10-07 14:03:11,544 - INFO -marigold_trainer.py - train >> iter 17495 (epoch  8): loss=0.05696
 2025-10-07 14:03:26,874 - INFO -marigold_trainer.py - train >> iter 17496 (epoch  8): loss=0.06382
 2025-10-07 14:03:44,160 - INFO -marigold_trainer.py - train >> iter 17497 (epoch  8): loss=0.06345
 2025-10-07 14:03:59,473 - INFO -marigold_trainer.py - train >> iter 17498 (epoch  8): loss=0.06093
 2025-10-07 14:04:14,137 - INFO -marigold_trainer.py - train >> iter 17499 (epoch  8): loss=0.05148
 2025-10-07 14:04:30,100 - INFO -marigold_trainer.py - train >> iter 17500 (epoch  8): loss=0.05886
 2025-10-07 14:04:30,101 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: output/train_marigold/checkpoint/latest
 2025-10-07 14:04:30,101 - DEBUG -marigold_trainer.py - save_checkpoint >> Old checkpoint is backed up at: output/train_marigold/checkpoint/_old_latest
 2025-10-07 14:04:33,451 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: output/train_marigold/checkpoint/latest/unet
 2025-10-07 14:04:39,798 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: output/train_marigold/checkpoint/latest/trainer.ckpt
 2025-10-07 14:04:40,390 - DEBUG -marigold_trainer.py - save_checkpoint >> Old checkpoint backup is removed.
 2025-10-07 14:04:56,076 - INFO -marigold_trainer.py - train >> iter 17501 (epoch  8): loss=0.06235
 2025-10-07 14:05:12,061 - INFO -marigold_trainer.py - train >> iter 17502 (epoch  8): loss=0.05938
 2025-10-07 14:05:26,736 - INFO -marigold_trainer.py - train >> iter 17503 (epoch  8): loss=0.07417
 2025-10-07 14:05:42,495 - INFO -marigold_trainer.py - train >> iter 17504 (epoch  8): loss=0.06795
 2025-10-07 14:06:00,445 - INFO -marigold_trainer.py - train >> iter 17505 (epoch  8): loss=0.06291
 2025-10-07 14:06:15,314 - INFO -marigold_trainer.py - train >> iter 17506 (epoch  8): loss=0.05989
 2025-10-07 14:06:31,924 - INFO -marigold_trainer.py - train >> iter 17507 (epoch  8): loss=0.05303
 2025-10-07 14:06:48,354 - INFO -marigold_trainer.py - train >> iter 17508 (epoch  8): loss=0.06165
 2025-10-07 14:07:03,883 - INFO -marigold_trainer.py - train >> iter 17509 (epoch  8): loss=0.05012
 2025-10-07 14:07:18,553 - INFO -marigold_trainer.py - train >> iter 17510 (epoch  8): loss=0.05738
 2025-10-07 14:07:35,159 - INFO -marigold_trainer.py - train >> iter 17511 (epoch  8): loss=0.06442
 2025-10-07 14:07:50,480 - INFO -marigold_trainer.py - train >> iter 17512 (epoch  8): loss=0.06043
 2025-10-07 14:08:05,147 - INFO -marigold_trainer.py - train >> iter 17513 (epoch  8): loss=0.05716
 2025-10-07 14:08:21,099 - INFO -marigold_trainer.py - train >> iter 17514 (epoch  8): loss=0.05834
 2025-10-07 14:08:36,500 - INFO -marigold_trainer.py - train >> iter 17515 (epoch  8): loss=0.06915
 2025-10-07 14:08:51,806 - INFO -marigold_trainer.py - train >> iter 17516 (epoch  8): loss=0.05645
 2025-10-07 14:09:06,479 - INFO -marigold_trainer.py - train >> iter 17517 (epoch  8): loss=0.06423
 2025-10-07 14:09:21,133 - INFO -marigold_trainer.py - train >> iter 17518 (epoch  8): loss=0.06004
 2025-10-07 14:09:37,750 - INFO -marigold_trainer.py - train >> iter 17519 (epoch  8): loss=0.05635
 2025-10-07 14:09:53,077 - INFO -marigold_trainer.py - train >> iter 17520 (epoch  8): loss=0.05649
 2025-10-07 14:10:07,758 - INFO -marigold_trainer.py - train >> iter 17521 (epoch  8): loss=0.05556
 2025-10-07 14:10:23,061 - INFO -marigold_trainer.py - train >> iter 17522 (epoch  8): loss=0.06172
 2025-10-07 14:10:39,033 - INFO -marigold_trainer.py - train >> iter 17523 (epoch  8): loss=0.06806
 2025-10-07 14:10:55,659 - INFO -marigold_trainer.py - train >> iter 17524 (epoch  8): loss=0.06222
 2025-10-07 14:11:12,300 - INFO -marigold_trainer.py - train >> iter 17525 (epoch  8): loss=0.05074
 2025-10-07 14:11:27,621 - INFO -marigold_trainer.py - train >> iter 17526 (epoch  8): loss=0.05502
 2025-10-07 14:11:43,604 - INFO -marigold_trainer.py - train >> iter 17527 (epoch  8): loss=0.05218
 2025-10-07 14:11:58,925 - INFO -marigold_trainer.py - train >> iter 17528 (epoch  8): loss=0.06057
 2025-10-07 14:12:13,592 - INFO -marigold_trainer.py - train >> iter 17529 (epoch  8): loss=0.06067
 2025-10-07 14:12:29,549 - INFO -marigold_trainer.py - train >> iter 17530 (epoch  8): loss=0.06330
 2025-10-07 14:12:45,329 - INFO -marigold_trainer.py - train >> iter 17531 (epoch  8): loss=0.04775
 2025-10-07 14:13:00,860 - INFO -marigold_trainer.py - train >> iter 17532 (epoch  8): loss=0.06519
 2025-10-07 14:13:16,835 - INFO -marigold_trainer.py - train >> iter 17533 (epoch  8): loss=0.06643
 2025-10-07 14:13:33,463 - INFO -marigold_trainer.py - train >> iter 17534 (epoch  8): loss=0.06221
 2025-10-07 14:13:48,591 - INFO -marigold_trainer.py - train >> iter 17535 (epoch  8): loss=0.05450
 2025-10-07 14:14:05,427 - INFO -marigold_trainer.py - train >> iter 17536 (epoch  8): loss=0.06133
 2025-10-07 14:14:20,756 - INFO -marigold_trainer.py - train >> iter 17537 (epoch  8): loss=0.06746
 2025-10-07 14:14:35,423 - INFO -marigold_trainer.py - train >> iter 17538 (epoch  8): loss=0.06362
 2025-10-07 14:14:51,375 - INFO -marigold_trainer.py - train >> iter 17539 (epoch  8): loss=0.05406
 2025-10-07 14:15:08,004 - INFO -marigold_trainer.py - train >> iter 17540 (epoch  8): loss=0.06800
 2025-10-07 14:15:24,627 - INFO -marigold_trainer.py - train >> iter 17541 (epoch  8): loss=0.05346
 2025-10-07 14:15:40,614 - INFO -marigold_trainer.py - train >> iter 17542 (epoch  8): loss=0.06258
 2025-10-07 14:15:56,593 - INFO -marigold_trainer.py - train >> iter 17543 (epoch  8): loss=0.05119
 2025-10-07 14:16:11,907 - INFO -marigold_trainer.py - train >> iter 17544 (epoch  8): loss=0.05608
 2025-10-07 14:16:27,224 - INFO -marigold_trainer.py - train >> iter 17545 (epoch  8): loss=0.06727
 2025-10-07 14:16:41,897 - INFO -marigold_trainer.py - train >> iter 17546 (epoch  8): loss=0.06472
 2025-10-07 14:16:56,545 - INFO -marigold_trainer.py - train >> iter 17547 (epoch  8): loss=0.05357
 2025-10-07 14:17:12,504 - INFO -marigold_trainer.py - train >> iter 17548 (epoch  8): loss=0.05803
 2025-10-07 14:17:27,172 - INFO -marigold_trainer.py - train >> iter 17549 (epoch  8): loss=0.05581
 2025-10-07 14:17:43,124 - INFO -marigold_trainer.py - train >> iter 17550 (epoch  8): loss=0.05929
 2025-10-07 14:17:58,445 - INFO -marigold_trainer.py - train >> iter 17551 (epoch  8): loss=0.05967
 2025-10-07 14:18:13,772 - INFO -marigold_trainer.py - train >> iter 17552 (epoch  8): loss=0.05372
 2025-10-07 14:18:29,100 - INFO -marigold_trainer.py - train >> iter 17553 (epoch  8): loss=0.05388
 2025-10-07 14:18:44,218 - INFO -marigold_trainer.py - train >> iter 17554 (epoch  8): loss=0.05976
 2025-10-07 14:18:59,093 - INFO -marigold_trainer.py - train >> iter 17555 (epoch  8): loss=0.05921
 2025-10-07 14:19:15,046 - INFO -marigold_trainer.py - train >> iter 17556 (epoch  8): loss=0.05577
 2025-10-07 14:19:30,367 - INFO -marigold_trainer.py - train >> iter 17557 (epoch  8): loss=0.05576
 2025-10-07 14:19:45,488 - INFO -marigold_trainer.py - train >> iter 17558 (epoch  8): loss=0.05560
 2025-10-07 14:20:01,672 - INFO -marigold_trainer.py - train >> iter 17559 (epoch  8): loss=0.06140
 2025-10-07 14:20:16,993 - INFO -marigold_trainer.py - train >> iter 17560 (epoch  8): loss=0.06244
 2025-10-07 14:20:32,317 - INFO -marigold_trainer.py - train >> iter 17561 (epoch  8): loss=0.05763
 2025-10-07 14:20:47,628 - INFO -marigold_trainer.py - train >> iter 17562 (epoch  8): loss=0.05987
 2025-10-07 14:21:03,599 - INFO -marigold_trainer.py - train >> iter 17563 (epoch  8): loss=0.06127
 2025-10-07 14:21:19,578 - INFO -marigold_trainer.py - train >> iter 17564 (epoch  8): loss=0.06522
 2025-10-07 14:21:34,253 - INFO -marigold_trainer.py - train >> iter 17565 (epoch  8): loss=0.06463
 2025-10-07 14:21:51,512 - INFO -marigold_trainer.py - train >> iter 17566 (epoch  8): loss=0.06204
 2025-10-07 14:22:06,180 - INFO -marigold_trainer.py - train >> iter 17567 (epoch  8): loss=0.05324
 2025-10-07 14:22:21,489 - INFO -marigold_trainer.py - train >> iter 17568 (epoch  8): loss=0.05134
 2025-10-07 14:22:36,148 - INFO -marigold_trainer.py - train >> iter 17569 (epoch  8): loss=0.06457
 2025-10-07 14:22:50,798 - INFO -marigold_trainer.py - train >> iter 17570 (epoch  8): loss=0.05460
 2025-10-07 14:23:06,107 - INFO -marigold_trainer.py - train >> iter 17571 (epoch  8): loss=0.05302
 2025-10-07 14:23:23,389 - INFO -marigold_trainer.py - train >> iter 17572 (epoch  8): loss=0.05890
 2025-10-07 14:23:39,358 - INFO -marigold_trainer.py - train >> iter 17573 (epoch  8): loss=0.06576
 2025-10-07 14:23:55,984 - INFO -marigold_trainer.py - train >> iter 17574 (epoch  8): loss=0.06270
 2025-10-07 14:24:11,759 - INFO -marigold_trainer.py - train >> iter 17575 (epoch  8): loss=0.06306
 2025-10-07 14:24:27,268 - INFO -marigold_trainer.py - train >> iter 17576 (epoch  8): loss=0.05795
 2025-10-07 14:24:43,899 - INFO -marigold_trainer.py - train >> iter 17577 (epoch  8): loss=0.06016
 2025-10-07 14:24:59,217 - INFO -marigold_trainer.py - train >> iter 17578 (epoch  8): loss=0.05835
 2025-10-07 14:25:13,882 - INFO -marigold_trainer.py - train >> iter 17579 (epoch  8): loss=0.05601
 2025-10-07 14:25:29,838 - INFO -marigold_trainer.py - train >> iter 17580 (epoch  8): loss=0.05423
 2025-10-07 14:25:44,507 - INFO -marigold_trainer.py - train >> iter 17581 (epoch  8): loss=0.06300
 2025-10-07 14:25:59,156 - INFO -marigold_trainer.py - train >> iter 17582 (epoch  8): loss=0.05498
 2025-10-07 14:26:13,808 - INFO -marigold_trainer.py - train >> iter 17583 (epoch  8): loss=0.06274
 2025-10-07 14:26:30,418 - INFO -marigold_trainer.py - train >> iter 17584 (epoch  8): loss=0.06066
 2025-10-07 14:26:45,087 - INFO -marigold_trainer.py - train >> iter 17585 (epoch  8): loss=0.06548
 2025-10-07 14:27:01,696 - INFO -marigold_trainer.py - train >> iter 17586 (epoch  8): loss=0.06212
 2025-10-07 14:27:17,009 - INFO -marigold_trainer.py - train >> iter 17587 (epoch  8): loss=0.05986
 2025-10-07 14:27:33,638 - INFO -marigold_trainer.py - train >> iter 17588 (epoch  8): loss=0.05484
 2025-10-07 14:27:48,957 - INFO -marigold_trainer.py - train >> iter 17589 (epoch  8): loss=0.05768
 2025-10-07 14:28:05,592 - INFO -marigold_trainer.py - train >> iter 17590 (epoch  8): loss=0.05708
 2025-10-07 14:28:22,224 - INFO -marigold_trainer.py - train >> iter 17591 (epoch  8): loss=0.05621
 2025-10-07 14:28:36,890 - INFO -marigold_trainer.py - train >> iter 17592 (epoch  8): loss=0.05256
 2025-10-07 14:28:54,158 - INFO -marigold_trainer.py - train >> iter 17593 (epoch  8): loss=0.06521
 2025-10-07 14:29:09,939 - INFO -marigold_trainer.py - train >> iter 17594 (epoch  8): loss=0.05741
 2025-10-07 14:29:26,118 - INFO -marigold_trainer.py - train >> iter 17595 (epoch  8): loss=0.06089
 2025-10-07 14:29:42,101 - INFO -marigold_trainer.py - train >> iter 17596 (epoch  8): loss=0.06981
 2025-10-07 14:29:58,730 - INFO -marigold_trainer.py - train >> iter 17597 (epoch  8): loss=0.06501
 2025-10-07 14:30:16,466 - INFO -marigold_trainer.py - train >> iter 17598 (epoch  8): loss=0.06134
 2025-10-07 14:30:31,786 - INFO -marigold_trainer.py - train >> iter 17599 (epoch  8): loss=0.05794
 2025-10-07 14:30:47,765 - INFO -marigold_trainer.py - train >> iter 17600 (epoch  8): loss=0.05674
 2025-10-07 14:31:05,252 - INFO -marigold_trainer.py - train >> iter 17601 (epoch  8): loss=0.05935
 2025-10-07 14:31:19,917 - INFO -marigold_trainer.py - train >> iter 17602 (epoch  8): loss=0.05371
 2025-10-07 14:31:37,189 - INFO -marigold_trainer.py - train >> iter 17603 (epoch  8): loss=0.05700
 2025-10-07 14:31:54,267 - INFO -marigold_trainer.py - train >> iter 17604 (epoch  8): loss=0.05558
 2025-10-07 14:32:09,137 - INFO -marigold_trainer.py - train >> iter 17605 (epoch  8): loss=0.06366
 2025-10-07 14:32:25,109 - INFO -marigold_trainer.py - train >> iter 17606 (epoch  8): loss=0.05047
 2025-10-07 14:32:41,079 - INFO -marigold_trainer.py - train >> iter 17607 (epoch  8): loss=0.06280
 2025-10-07 14:32:56,419 - INFO -marigold_trainer.py - train >> iter 17608 (epoch  8): loss=0.05474
 2025-10-07 14:33:12,398 - INFO -marigold_trainer.py - train >> iter 17609 (epoch  8): loss=0.05556
 2025-10-07 14:33:28,376 - INFO -marigold_trainer.py - train >> iter 17610 (epoch  8): loss=0.06402
 2025-10-07 14:33:45,670 - INFO -marigold_trainer.py - train >> iter 17611 (epoch  8): loss=0.06169
 2025-10-07 14:34:00,992 - INFO -marigold_trainer.py - train >> iter 17612 (epoch  8): loss=0.06879
 2025-10-07 14:34:15,667 - INFO -marigold_trainer.py - train >> iter 17613 (epoch  8): loss=0.05952
 2025-10-07 14:34:31,710 - INFO -marigold_trainer.py - train >> iter 17614 (epoch  8): loss=0.04812
 2025-10-07 14:34:47,020 - INFO -marigold_trainer.py - train >> iter 17615 (epoch  8): loss=0.06061
 2025-10-07 14:35:01,680 - INFO -marigold_trainer.py - train >> iter 17616 (epoch  8): loss=0.04844
 2025-10-07 14:35:16,330 - INFO -marigold_trainer.py - train >> iter 17617 (epoch  8): loss=0.06158
 2025-10-07 14:35:31,637 - INFO -marigold_trainer.py - train >> iter 17618 (epoch  8): loss=0.05883
 2025-10-07 14:35:48,269 - INFO -marigold_trainer.py - train >> iter 17619 (epoch  8): loss=0.06254
 2025-10-07 14:36:04,040 - INFO -marigold_trainer.py - train >> iter 17620 (epoch  8): loss=0.06429
 2025-10-07 14:36:20,019 - INFO -marigold_trainer.py - train >> iter 17621 (epoch  8): loss=0.06422
 2025-10-07 14:36:36,197 - INFO -marigold_trainer.py - train >> iter 17622 (epoch  8): loss=0.06016
 2025-10-07 14:36:50,863 - INFO -marigold_trainer.py - train >> iter 17623 (epoch  8): loss=0.05575
 2025-10-07 14:37:06,166 - INFO -marigold_trainer.py - train >> iter 17624 (epoch  8): loss=0.05162
 2025-10-07 14:37:22,144 - INFO -marigold_trainer.py - train >> iter 17625 (epoch  8): loss=0.06895
 2025-10-07 14:37:37,466 - INFO -marigold_trainer.py - train >> iter 17626 (epoch  8): loss=0.05718
 2025-10-07 14:37:52,118 - INFO -marigold_trainer.py - train >> iter 17627 (epoch  8): loss=0.05787
 2025-10-07 14:38:09,378 - INFO -marigold_trainer.py - train >> iter 17628 (epoch  8): loss=0.06220
 2025-10-07 14:38:24,043 - INFO -marigold_trainer.py - train >> iter 17629 (epoch  8): loss=0.05732
 2025-10-07 14:38:40,001 - INFO -marigold_trainer.py - train >> iter 17630 (epoch  8): loss=0.05430
 2025-10-07 14:38:55,328 - INFO -marigold_trainer.py - train >> iter 17631 (epoch  8): loss=0.05548
 2025-10-07 14:39:11,110 - INFO -marigold_trainer.py - train >> iter 17632 (epoch  8): loss=0.05958
 2025-10-07 14:39:27,290 - INFO -marigold_trainer.py - train >> iter 17633 (epoch  8): loss=0.05713
 2025-10-07 14:39:42,612 - INFO -marigold_trainer.py - train >> iter 17634 (epoch  8): loss=0.05180
 2025-10-07 14:39:59,687 - INFO -marigold_trainer.py - train >> iter 17635 (epoch  8): loss=0.05448
 2025-10-07 14:40:14,561 - INFO -marigold_trainer.py - train >> iter 17636 (epoch  8): loss=0.04667
 2025-10-07 14:40:29,662 - INFO -marigold_trainer.py - train >> iter 17637 (epoch  8): loss=0.05784
 2025-10-07 14:40:44,522 - INFO -marigold_trainer.py - train >> iter 17638 (epoch  8): loss=0.06200
 2025-10-07 14:40:59,820 - INFO -marigold_trainer.py - train >> iter 17639 (epoch  8): loss=0.05526
 2025-10-07 14:41:15,788 - INFO -marigold_trainer.py - train >> iter 17640 (epoch  8): loss=0.06369
 2025-10-07 14:41:30,461 - INFO -marigold_trainer.py - train >> iter 17641 (epoch  8): loss=0.06220
 2025-10-07 14:41:47,070 - INFO -marigold_trainer.py - train >> iter 17642 (epoch  8): loss=0.05636
 2025-10-07 14:42:02,391 - INFO -marigold_trainer.py - train >> iter 17643 (epoch  8): loss=0.06532
 2025-10-07 14:42:17,051 - INFO -marigold_trainer.py - train >> iter 17644 (epoch  8): loss=0.05477
 2025-10-07 14:42:33,663 - INFO -marigold_trainer.py - train >> iter 17645 (epoch  8): loss=0.05630
 2025-10-07 14:42:48,984 - INFO -marigold_trainer.py - train >> iter 17646 (epoch  8): loss=0.05826
 2025-10-07 14:43:04,960 - INFO -marigold_trainer.py - train >> iter 17647 (epoch  8): loss=0.05944
 2025-10-07 14:43:20,290 - INFO -marigold_trainer.py - train >> iter 17648 (epoch  8): loss=0.05437
 2025-10-07 14:43:34,960 - INFO -marigold_trainer.py - train >> iter 17649 (epoch  8): loss=0.05388
 2025-10-07 14:43:50,257 - INFO -marigold_trainer.py - train >> iter 17650 (epoch  8): loss=0.05540
 2025-10-07 14:44:06,234 - INFO -marigold_trainer.py - train >> iter 17651 (epoch  8): loss=0.06841
 2025-10-07 14:44:21,997 - INFO -marigold_trainer.py - train >> iter 17652 (epoch  8): loss=0.06401
 2025-10-07 14:44:37,511 - INFO -marigold_trainer.py - train >> iter 17653 (epoch  8): loss=0.05749
 2025-10-07 14:44:53,494 - INFO -marigold_trainer.py - train >> iter 17654 (epoch  8): loss=0.05873
 2025-10-07 14:45:09,474 - INFO -marigold_trainer.py - train >> iter 17655 (epoch  8): loss=0.06209
 2025-10-07 14:45:26,755 - INFO -marigold_trainer.py - train >> iter 17656 (epoch  8): loss=0.05363
 2025-10-07 14:45:42,078 - INFO -marigold_trainer.py - train >> iter 17657 (epoch  8): loss=0.05155
 2025-10-07 14:45:57,407 - INFO -marigold_trainer.py - train >> iter 17658 (epoch  8): loss=0.05539
 2025-10-07 14:46:15,335 - INFO -marigold_trainer.py - train >> iter 17659 (epoch  8): loss=0.06256
 2025-10-07 14:46:29,993 - INFO -marigold_trainer.py - train >> iter 17660 (epoch  8): loss=0.06388
 2025-10-07 14:46:46,605 - INFO -marigold_trainer.py - train >> iter 17661 (epoch  8): loss=0.05636
 2025-10-07 14:47:02,574 - INFO -marigold_trainer.py - train >> iter 17662 (epoch  8): loss=0.06391
 2025-10-07 14:47:18,551 - INFO -marigold_trainer.py - train >> iter 17663 (epoch  8): loss=0.05936
 2025-10-07 14:47:33,881 - INFO -marigold_trainer.py - train >> iter 17664 (epoch  8): loss=0.05520
 2025-10-07 14:47:49,201 - INFO -marigold_trainer.py - train >> iter 17665 (epoch  8): loss=0.05969
 2025-10-07 14:48:04,523 - INFO -marigold_trainer.py - train >> iter 17666 (epoch  8): loss=0.05231
 2025-10-07 14:48:19,192 - INFO -marigold_trainer.py - train >> iter 17667 (epoch  8): loss=0.05227
 2025-10-07 14:48:34,496 - INFO -marigold_trainer.py - train >> iter 17668 (epoch  8): loss=0.05163
 2025-10-07 14:48:50,476 - INFO -marigold_trainer.py - train >> iter 17669 (epoch  8): loss=0.05867
 2025-10-07 14:49:05,793 - INFO -marigold_trainer.py - train >> iter 17670 (epoch  8): loss=0.05453
 2025-10-07 14:49:21,118 - INFO -marigold_trainer.py - train >> iter 17671 (epoch  8): loss=0.06429
 2025-10-07 14:49:35,783 - INFO -marigold_trainer.py - train >> iter 17672 (epoch  8): loss=0.04993
 2025-10-07 14:49:51,081 - INFO -marigold_trainer.py - train >> iter 17673 (epoch  8): loss=0.05574
 2025-10-07 14:50:06,393 - INFO -marigold_trainer.py - train >> iter 17674 (epoch  8): loss=0.06765
 2025-10-07 14:50:21,518 - INFO -marigold_trainer.py - train >> iter 17675 (epoch  8): loss=0.06283
 2025-10-07 14:50:37,692 - INFO -marigold_trainer.py - train >> iter 17676 (epoch  8): loss=0.05041
 2025-10-07 14:50:53,676 - INFO -marigold_trainer.py - train >> iter 17677 (epoch  8): loss=0.05523
 2025-10-07 14:51:08,998 - INFO -marigold_trainer.py - train >> iter 17678 (epoch  8): loss=0.05908
 2025-10-07 14:51:26,730 - INFO -marigold_trainer.py - train >> iter 17679 (epoch  8): loss=0.06353
 2025-10-07 14:51:42,913 - INFO -marigold_trainer.py - train >> iter 17680 (epoch  8): loss=0.05953
 2025-10-07 14:51:58,894 - INFO -marigold_trainer.py - train >> iter 17681 (epoch  8): loss=0.05818
 2025-10-07 14:52:15,316 - INFO -marigold_trainer.py - train >> iter 17682 (epoch  8): loss=0.05838
 2025-10-07 14:52:30,857 - INFO -marigold_trainer.py - train >> iter 17683 (epoch  8): loss=0.06141
 2025-10-07 14:52:46,613 - INFO -marigold_trainer.py - train >> iter 17684 (epoch  8): loss=0.05264
 2025-10-07 14:53:02,138 - INFO -marigold_trainer.py - train >> iter 17685 (epoch  8): loss=0.05802
 2025-10-07 14:53:17,457 - INFO -marigold_trainer.py - train >> iter 17686 (epoch  8): loss=0.05392
 2025-10-07 14:53:35,406 - INFO -marigold_trainer.py - train >> iter 17687 (epoch  8): loss=0.05786
 2025-10-07 14:53:50,069 - INFO -marigold_trainer.py - train >> iter 17688 (epoch  8): loss=0.05680
 2025-10-07 14:54:06,028 - INFO -marigold_trainer.py - train >> iter 17689 (epoch  8): loss=0.06275
 2025-10-07 14:54:20,698 - INFO -marigold_trainer.py - train >> iter 17690 (epoch  8): loss=0.05896
 2025-10-07 14:54:36,001 - INFO -marigold_trainer.py - train >> iter 17691 (epoch  8): loss=0.05369
 2025-10-07 14:54:52,643 - INFO -marigold_trainer.py - train >> iter 17692 (epoch  8): loss=0.05289
 2025-10-07 14:55:07,975 - INFO -marigold_trainer.py - train >> iter 17693 (epoch  8): loss=0.06108
 2025-10-07 14:55:24,060 - INFO -marigold_trainer.py - train >> iter 17694 (epoch  8): loss=0.05202
 2025-10-07 14:55:39,380 - INFO -marigold_trainer.py - train >> iter 17695 (epoch  8): loss=0.06054
 2025-10-07 14:55:55,348 - INFO -marigold_trainer.py - train >> iter 17696 (epoch  8): loss=0.05759
 2025-10-07 14:56:10,019 - INFO -marigold_trainer.py - train >> iter 17697 (epoch  8): loss=0.05486
 2025-10-07 14:56:25,325 - INFO -marigold_trainer.py - train >> iter 17698 (epoch  8): loss=0.04814
 2025-10-07 14:56:39,995 - INFO -marigold_trainer.py - train >> iter 17699 (epoch  8): loss=0.05097
 2025-10-07 14:56:55,949 - INFO -marigold_trainer.py - train >> iter 17700 (epoch  8): loss=0.05825
 2025-10-07 14:57:10,623 - INFO -marigold_trainer.py - train >> iter 17701 (epoch  8): loss=0.05592
 2025-10-07 14:57:27,879 - INFO -marigold_trainer.py - train >> iter 17702 (epoch  8): loss=0.05999
 2025-10-07 14:57:43,202 - INFO -marigold_trainer.py - train >> iter 17703 (epoch  8): loss=0.05042
 2025-10-07 14:58:00,486 - INFO -marigold_trainer.py - train >> iter 17704 (epoch  8): loss=0.05973
 2025-10-07 14:58:17,111 - INFO -marigold_trainer.py - train >> iter 17705 (epoch  8): loss=0.06470
 2025-10-07 14:58:31,782 - INFO -marigold_trainer.py - train >> iter 17706 (epoch  8): loss=0.06537
 2025-10-07 14:58:47,738 - INFO -marigold_trainer.py - train >> iter 17707 (epoch  8): loss=0.06042
 2025-10-07 14:59:03,069 - INFO -marigold_trainer.py - train >> iter 17708 (epoch  8): loss=0.05383
 2025-10-07 14:59:19,709 - INFO -marigold_trainer.py - train >> iter 17709 (epoch  8): loss=0.06098
 2025-10-07 14:59:36,347 - INFO -marigold_trainer.py - train >> iter 17710 (epoch  8): loss=0.05439
 2025-10-07 14:59:51,681 - INFO -marigold_trainer.py - train >> iter 17711 (epoch  8): loss=0.06470
 2025-10-07 15:00:07,004 - INFO -marigold_trainer.py - train >> iter 17712 (epoch  8): loss=0.05564
 2025-10-07 15:00:22,325 - INFO -marigold_trainer.py - train >> iter 17713 (epoch  8): loss=0.06061
 2025-10-07 15:00:36,986 - INFO -marigold_trainer.py - train >> iter 17714 (epoch  8): loss=0.05168
 2025-10-07 15:00:52,287 - INFO -marigold_trainer.py - train >> iter 17715 (epoch  8): loss=0.06297
 2025-10-07 15:01:07,603 - INFO -marigold_trainer.py - train >> iter 17716 (epoch  8): loss=0.05475
 2025-10-07 15:01:22,922 - INFO -marigold_trainer.py - train >> iter 17717 (epoch  8): loss=0.06406
 2025-10-07 15:01:38,045 - INFO -marigold_trainer.py - train >> iter 17718 (epoch  8): loss=0.06041
 2025-10-07 15:01:54,018 - INFO -marigold_trainer.py - train >> iter 17719 (epoch  8): loss=0.04981
 2025-10-07 15:02:09,996 - INFO -marigold_trainer.py - train >> iter 17720 (epoch  8): loss=0.06033
 2025-10-07 15:02:26,622 - INFO -marigold_trainer.py - train >> iter 17721 (epoch  8): loss=0.05982
 2025-10-07 15:02:42,594 - INFO -marigold_trainer.py - train >> iter 17722 (epoch  8): loss=0.05492
 2025-10-07 15:02:58,107 - INFO -marigold_trainer.py - train >> iter 17723 (epoch  8): loss=0.06865
 2025-10-07 15:03:13,430 - INFO -marigold_trainer.py - train >> iter 17724 (epoch  8): loss=0.04797
 2025-10-07 15:03:28,760 - INFO -marigold_trainer.py - train >> iter 17725 (epoch  8): loss=0.05966
 2025-10-07 15:03:45,395 - INFO -marigold_trainer.py - train >> iter 17726 (epoch  8): loss=0.05935
 2025-10-07 15:04:01,383 - INFO -marigold_trainer.py - train >> iter 17727 (epoch  8): loss=0.05814
 2025-10-07 15:04:16,701 - INFO -marigold_trainer.py - train >> iter 17728 (epoch  8): loss=0.05958
 2025-10-07 15:04:32,660 - INFO -marigold_trainer.py - train >> iter 17729 (epoch  8): loss=0.06302
 2025-10-07 15:04:47,982 - INFO -marigold_trainer.py - train >> iter 17730 (epoch  8): loss=0.05948
 2025-10-07 15:05:03,938 - INFO -marigold_trainer.py - train >> iter 17731 (epoch  8): loss=0.05687
 2025-10-07 15:05:23,189 - INFO -marigold_trainer.py - train >> iter 17732 (epoch  8): loss=0.05400
 2025-10-07 15:05:41,788 - INFO -marigold_trainer.py - train >> iter 17733 (epoch  8): loss=0.05019
 2025-10-07 15:06:00,379 - INFO -marigold_trainer.py - train >> iter 17734 (epoch  8): loss=0.06736
 2025-10-07 15:06:15,711 - INFO -marigold_trainer.py - train >> iter 17735 (epoch  8): loss=0.06092
 2025-10-07 15:06:31,670 - INFO -marigold_trainer.py - train >> iter 17736 (epoch  8): loss=0.06105
 2025-10-07 15:06:47,003 - INFO -marigold_trainer.py - train >> iter 17737 (epoch  8): loss=0.05716
 2025-10-07 15:07:02,986 - INFO -marigold_trainer.py - train >> iter 17738 (epoch  8): loss=0.05848
 2025-10-07 15:07:18,956 - INFO -marigold_trainer.py - train >> iter 17739 (epoch  8): loss=0.05459
 2025-10-07 15:07:34,277 - INFO -marigold_trainer.py - train >> iter 17740 (epoch  8): loss=0.05105
 2025-10-07 15:07:49,594 - INFO -marigold_trainer.py - train >> iter 17741 (epoch  8): loss=0.05538
 2025-10-07 15:08:06,677 - INFO -marigold_trainer.py - train >> iter 17742 (epoch  8): loss=0.05806
 2025-10-07 15:08:21,550 - INFO -marigold_trainer.py - train >> iter 17743 (epoch  8): loss=0.06654
 2025-10-07 15:08:38,822 - INFO -marigold_trainer.py - train >> iter 17744 (epoch  8): loss=0.05553
 2025-10-07 15:08:54,142 - INFO -marigold_trainer.py - train >> iter 17745 (epoch  8): loss=0.05981
 2025-10-07 15:09:09,464 - INFO -marigold_trainer.py - train >> iter 17746 (epoch  8): loss=0.06135
 2025-10-07 15:09:24,131 - INFO -marigold_trainer.py - train >> iter 17747 (epoch  8): loss=0.05591
 2025-10-07 15:09:39,889 - INFO -marigold_trainer.py - train >> iter 17748 (epoch  8): loss=0.05731
 2025-10-07 15:09:56,714 - INFO -marigold_trainer.py - train >> iter 17749 (epoch  8): loss=0.06126
 2025-10-07 15:10:12,047 - INFO -marigold_trainer.py - train >> iter 17750 (epoch  8): loss=0.06135
 2025-10-07 15:10:12,048 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: output/train_marigold/checkpoint/latest
 2025-10-07 15:10:12,048 - DEBUG -marigold_trainer.py - save_checkpoint >> Old checkpoint is backed up at: output/train_marigold/checkpoint/_old_latest
 2025-10-07 15:10:15,346 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: output/train_marigold/checkpoint/latest/unet
 2025-10-07 15:10:21,543 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: output/train_marigold/checkpoint/latest/trainer.ckpt
 2025-10-07 15:10:22,247 - DEBUG -marigold_trainer.py - save_checkpoint >> Old checkpoint backup is removed.
 2025-10-07 15:10:37,927 - INFO -marigold_trainer.py - train >> iter 17751 (epoch  8): loss=0.05674
 2025-10-07 15:10:52,597 - INFO -marigold_trainer.py - train >> iter 17752 (epoch  8): loss=0.06342
 2025-10-07 15:11:07,908 - INFO -marigold_trainer.py - train >> iter 17753 (epoch  8): loss=0.06121
 2025-10-07 15:11:22,593 - INFO -marigold_trainer.py - train >> iter 17754 (epoch  8): loss=0.05288
 2025-10-07 15:11:37,244 - INFO -marigold_trainer.py - train >> iter 17755 (epoch  8): loss=0.04908
 2025-10-07 15:11:53,210 - INFO -marigold_trainer.py - train >> iter 17756 (epoch  8): loss=0.06462
 2025-10-07 15:12:07,891 - INFO -marigold_trainer.py - train >> iter 17757 (epoch  8): loss=0.06094
 2025-10-07 15:12:22,543 - INFO -marigold_trainer.py - train >> iter 17758 (epoch  8): loss=0.05664
 2025-10-07 15:12:40,266 - INFO -marigold_trainer.py - train >> iter 17759 (epoch  8): loss=0.06671
 2025-10-07 15:12:57,559 - INFO -marigold_trainer.py - train >> iter 17760 (epoch  8): loss=0.06320
 2025-10-07 15:13:13,536 - INFO -marigold_trainer.py - train >> iter 17761 (epoch  8): loss=0.05510
 2025-10-07 15:13:29,725 - INFO -marigold_trainer.py - train >> iter 17762 (epoch  8): loss=0.05946
 2025-10-07 15:13:45,695 - INFO -marigold_trainer.py - train >> iter 17763 (epoch  8): loss=0.05442
 2025-10-07 15:14:01,672 - INFO -marigold_trainer.py - train >> iter 17764 (epoch  8): loss=0.05880
 2025-10-07 15:14:18,296 - INFO -marigold_trainer.py - train >> iter 17765 (epoch  8): loss=0.05981
 2025-10-07 15:14:32,967 - INFO -marigold_trainer.py - train >> iter 17766 (epoch  8): loss=0.05582
 2025-10-07 15:14:49,373 - INFO -marigold_trainer.py - train >> iter 17767 (epoch  8): loss=0.06032
 2025-10-07 15:15:05,557 - INFO -marigold_trainer.py - train >> iter 17768 (epoch  8): loss=0.05862
 2025-10-07 15:15:21,339 - INFO -marigold_trainer.py - train >> iter 17769 (epoch  8): loss=0.05693
 2025-10-07 15:15:36,863 - INFO -marigold_trainer.py - train >> iter 17770 (epoch  8): loss=0.05905
 2025-10-07 15:15:52,182 - INFO -marigold_trainer.py - train >> iter 17771 (epoch  8): loss=0.06121
 2025-10-07 15:16:07,510 - INFO -marigold_trainer.py - train >> iter 17772 (epoch  8): loss=0.05090
 2025-10-07 15:16:22,837 - INFO -marigold_trainer.py - train >> iter 17773 (epoch  8): loss=0.05467
 2025-10-07 15:16:38,164 - INFO -marigold_trainer.py - train >> iter 17774 (epoch  8): loss=0.05382
 2025-10-07 15:16:52,831 - INFO -marigold_trainer.py - train >> iter 17775 (epoch  8): loss=0.05575
 2025-10-07 15:17:08,131 - INFO -marigold_trainer.py - train >> iter 17776 (epoch  8): loss=0.06141
 2025-10-07 15:17:22,801 - INFO -marigold_trainer.py - train >> iter 17777 (epoch  8): loss=0.06150
 2025-10-07 15:17:38,757 - INFO -marigold_trainer.py - train >> iter 17778 (epoch  8): loss=0.05158
 2025-10-07 15:17:54,733 - INFO -marigold_trainer.py - train >> iter 17779 (epoch  8): loss=0.06129
 2025-10-07 15:18:09,864 - INFO -marigold_trainer.py - train >> iter 17780 (epoch  8): loss=0.06030
 2025-10-07 15:18:26,486 - INFO -marigold_trainer.py - train >> iter 17781 (epoch  8): loss=0.05936
 2025-10-07 15:18:41,363 - INFO -marigold_trainer.py - train >> iter 17782 (epoch  8): loss=0.05162
 2025-10-07 15:18:57,328 - INFO -marigold_trainer.py - train >> iter 17783 (epoch  8): loss=0.06342
 2025-10-07 15:19:11,995 - INFO -marigold_trainer.py - train >> iter 17784 (epoch  8): loss=0.05887
 2025-10-07 15:19:26,647 - INFO -marigold_trainer.py - train >> iter 17785 (epoch  8): loss=0.05765
 2025-10-07 15:19:42,610 - INFO -marigold_trainer.py - train >> iter 17786 (epoch  8): loss=0.05612
 2025-10-07 15:19:58,585 - INFO -marigold_trainer.py - train >> iter 17787 (epoch  8): loss=0.05643
 2025-10-07 15:20:14,357 - INFO -marigold_trainer.py - train >> iter 17788 (epoch  8): loss=0.05543
 2025-10-07 15:20:29,330 - INFO -marigold_trainer.py - train >> iter 17789 (epoch  8): loss=0.05860
 2025-10-07 15:20:45,939 - INFO -marigold_trainer.py - train >> iter 17790 (epoch  8): loss=0.05716
 2025-10-07 15:21:01,916 - INFO -marigold_trainer.py - train >> iter 17791 (epoch  8): loss=0.05890
 2025-10-07 15:21:17,242 - INFO -marigold_trainer.py - train >> iter 17792 (epoch  8): loss=0.05945
 2025-10-07 15:21:33,677 - INFO -marigold_trainer.py - train >> iter 17793 (epoch  8): loss=0.06438
 2025-10-07 15:21:49,865 - INFO -marigold_trainer.py - train >> iter 17794 (epoch  8): loss=0.06819
 2025-10-07 15:22:04,537 - INFO -marigold_trainer.py - train >> iter 17795 (epoch  8): loss=0.05844
 2025-10-07 15:22:19,184 - INFO -marigold_trainer.py - train >> iter 17796 (epoch  8): loss=0.06569
 2025-10-07 15:22:34,490 - INFO -marigold_trainer.py - train >> iter 17797 (epoch  8): loss=0.05843
 2025-10-07 15:22:50,462 - INFO -marigold_trainer.py - train >> iter 17798 (epoch  8): loss=0.05165
 2025-10-07 15:23:05,784 - INFO -marigold_trainer.py - train >> iter 17799 (epoch  8): loss=0.05781
 2025-10-07 15:23:20,451 - INFO -marigold_trainer.py - train >> iter 17800 (epoch  8): loss=0.05733
 2025-10-07 15:23:36,413 - INFO -marigold_trainer.py - train >> iter 17801 (epoch  8): loss=0.05343
 2025-10-07 15:23:52,387 - INFO -marigold_trainer.py - train >> iter 17802 (epoch  8): loss=0.05881
 2025-10-07 15:24:07,060 - INFO -marigold_trainer.py - train >> iter 17803 (epoch  8): loss=0.05461
 2025-10-07 15:24:23,012 - INFO -marigold_trainer.py - train >> iter 17804 (epoch  8): loss=0.05970
 2025-10-07 15:24:38,982 - INFO -marigold_trainer.py - train >> iter 17805 (epoch  8): loss=0.05469
 2025-10-07 15:24:54,961 - INFO -marigold_trainer.py - train >> iter 17806 (epoch  8): loss=0.05532
 2025-10-07 15:25:11,592 - INFO -marigold_trainer.py - train >> iter 17807 (epoch  8): loss=0.05968
 2025-10-07 15:25:28,220 - INFO -marigold_trainer.py - train >> iter 17808 (epoch  8): loss=0.06448
 2025-10-07 15:25:43,548 - INFO -marigold_trainer.py - train >> iter 17809 (epoch  8): loss=0.06248
 2025-10-07 15:25:58,843 - INFO -marigold_trainer.py - train >> iter 17810 (epoch  8): loss=0.05049
 2025-10-07 15:26:13,521 - INFO -marigold_trainer.py - train >> iter 17811 (epoch  8): loss=0.05475
 2025-10-07 15:26:29,472 - INFO -marigold_trainer.py - train >> iter 17812 (epoch  8): loss=0.06192
 2025-10-07 15:26:44,798 - INFO -marigold_trainer.py - train >> iter 17813 (epoch  8): loss=0.05762
 2025-10-07 15:27:00,775 - INFO -marigold_trainer.py - train >> iter 17814 (epoch  8): loss=0.05394
 2025-10-07 15:27:16,095 - INFO -marigold_trainer.py - train >> iter 17815 (epoch  8): loss=0.05995
 2025-10-07 15:27:32,051 - INFO -marigold_trainer.py - train >> iter 17816 (epoch  8): loss=0.05357
 2025-10-07 15:27:47,370 - INFO -marigold_trainer.py - train >> iter 17817 (epoch  8): loss=0.05225
 2025-10-07 15:28:03,350 - INFO -marigold_trainer.py - train >> iter 17818 (epoch  8): loss=0.06122
 2025-10-07 15:28:19,985 - INFO -marigold_trainer.py - train >> iter 17819 (epoch  8): loss=0.05510
 2025-10-07 15:28:35,972 - INFO -marigold_trainer.py - train >> iter 17820 (epoch  8): loss=0.05862
 2025-10-07 15:28:52,612 - INFO -marigold_trainer.py - train >> iter 17821 (epoch  8): loss=0.04914
 2025-10-07 15:29:07,924 - INFO -marigold_trainer.py - train >> iter 17822 (epoch  8): loss=0.06375
 2025-10-07 15:29:23,889 - INFO -marigold_trainer.py - train >> iter 17823 (epoch  8): loss=0.05970
 2025-10-07 15:29:38,551 - INFO -marigold_trainer.py - train >> iter 17824 (epoch  8): loss=0.05130
 2025-10-07 15:29:53,196 - INFO -marigold_trainer.py - train >> iter 17825 (epoch  8): loss=0.05886
 2025-10-07 15:30:07,843 - INFO -marigold_trainer.py - train >> iter 17826 (epoch  8): loss=0.06614
 2025-10-07 15:30:23,149 - INFO -marigold_trainer.py - train >> iter 17827 (epoch  8): loss=0.05741
 2025-10-07 15:30:37,820 - INFO -marigold_trainer.py - train >> iter 17828 (epoch  8): loss=0.05773
 2025-10-07 15:30:53,122 - INFO -marigold_trainer.py - train >> iter 17829 (epoch  8): loss=0.06150
 2025-10-07 15:31:08,450 - INFO -marigold_trainer.py - train >> iter 17830 (epoch  8): loss=0.05591
 2025-10-07 15:31:24,415 - INFO -marigold_trainer.py - train >> iter 17831 (epoch  8): loss=0.05953
 2025-10-07 15:31:40,399 - INFO -marigold_trainer.py - train >> iter 17832 (epoch  8): loss=0.05567
 2025-10-07 15:31:57,678 - INFO -marigold_trainer.py - train >> iter 17833 (epoch  8): loss=0.06012
 2025-10-07 15:32:12,345 - INFO -marigold_trainer.py - train >> iter 17834 (epoch  8): loss=0.05395
 2025-10-07 15:32:27,646 - INFO -marigold_trainer.py - train >> iter 17835 (epoch  8): loss=0.05066
 2025-10-07 15:32:43,614 - INFO -marigold_trainer.py - train >> iter 17836 (epoch  8): loss=0.06230
 2025-10-07 15:32:58,947 - INFO -marigold_trainer.py - train >> iter 17837 (epoch  8): loss=0.05489
 2025-10-07 15:33:14,901 - INFO -marigold_trainer.py - train >> iter 17838 (epoch  8): loss=0.05705
 2025-10-07 15:33:30,222 - INFO -marigold_trainer.py - train >> iter 17839 (epoch  8): loss=0.05637
 2025-10-07 15:33:46,192 - INFO -marigold_trainer.py - train >> iter 17840 (epoch  8): loss=0.06318
 2025-10-07 15:34:00,851 - INFO -marigold_trainer.py - train >> iter 17841 (epoch  8): loss=0.05091
 2025-10-07 15:34:16,154 - INFO -marigold_trainer.py - train >> iter 17842 (epoch  8): loss=0.05844
 2025-10-07 15:34:31,473 - INFO -marigold_trainer.py - train >> iter 17843 (epoch  8): loss=0.04833
 2025-10-07 15:34:46,132 - INFO -marigold_trainer.py - train >> iter 17844 (epoch  8): loss=0.06264
 2025-10-07 15:35:01,437 - INFO -marigold_trainer.py - train >> iter 17845 (epoch  8): loss=0.06284
 2025-10-07 15:35:16,101 - INFO -marigold_trainer.py - train >> iter 17846 (epoch  8): loss=0.06125
 2025-10-07 15:35:32,056 - INFO -marigold_trainer.py - train >> iter 17847 (epoch  8): loss=0.06235
 2025-10-07 15:35:46,724 - INFO -marigold_trainer.py - train >> iter 17848 (epoch  8): loss=0.05676
 2025-10-07 15:36:01,373 - INFO -marigold_trainer.py - train >> iter 17849 (epoch  8): loss=0.05914
 2025-10-07 15:36:17,331 - INFO -marigold_trainer.py - train >> iter 17850 (epoch  8): loss=0.05599
 2025-10-07 15:36:33,769 - INFO -marigold_trainer.py - train >> iter 17851 (epoch  8): loss=0.06066
 2025-10-07 15:36:49,951 - INFO -marigold_trainer.py - train >> iter 17852 (epoch  8): loss=0.06236
 2025-10-07 15:37:05,930 - INFO -marigold_trainer.py - train >> iter 17853 (epoch  8): loss=0.05651
 2025-10-07 15:37:21,257 - INFO -marigold_trainer.py - train >> iter 17854 (epoch  8): loss=0.05589
 2025-10-07 15:37:37,031 - INFO -marigold_trainer.py - train >> iter 17855 (epoch  8): loss=0.06767
 2025-10-07 15:37:53,206 - INFO -marigold_trainer.py - train >> iter 17856 (epoch  8): loss=0.05595
 2025-10-07 15:38:09,192 - INFO -marigold_trainer.py - train >> iter 17857 (epoch  8): loss=0.05837
 2025-10-07 15:38:23,863 - INFO -marigold_trainer.py - train >> iter 17858 (epoch  8): loss=0.06151
 2025-10-07 15:38:41,781 - INFO -marigold_trainer.py - train >> iter 17859 (epoch  8): loss=0.04934
 2025-10-07 15:38:57,751 - INFO -marigold_trainer.py - train >> iter 17860 (epoch  8): loss=0.05746
 2025-10-07 15:39:13,726 - INFO -marigold_trainer.py - train >> iter 17861 (epoch  8): loss=0.06268
 2025-10-07 15:39:29,049 - INFO -marigold_trainer.py - train >> iter 17862 (epoch  8): loss=0.05331
 2025-10-07 15:39:45,030 - INFO -marigold_trainer.py - train >> iter 17863 (epoch  8): loss=0.06141
 2025-10-07 15:40:00,143 - INFO -marigold_trainer.py - train >> iter 17864 (epoch  8): loss=0.05461
 2025-10-07 15:40:15,001 - INFO -marigold_trainer.py - train >> iter 17865 (epoch  8): loss=0.04628
 2025-10-07 15:40:30,957 - INFO -marigold_trainer.py - train >> iter 17866 (epoch  8): loss=0.05314
 2025-10-07 15:40:45,620 - INFO -marigold_trainer.py - train >> iter 17867 (epoch  8): loss=0.05772
 2025-10-07 15:41:01,569 - INFO -marigold_trainer.py - train >> iter 17868 (epoch  8): loss=0.05190
 2025-10-07 15:41:19,487 - INFO -marigold_trainer.py - train >> iter 17869 (epoch  8): loss=0.06737
 2025-10-07 15:41:34,152 - INFO -marigold_trainer.py - train >> iter 17870 (epoch  8): loss=0.05519
 2025-10-07 15:41:48,800 - INFO -marigold_trainer.py - train >> iter 17871 (epoch  8): loss=0.05473
 2025-10-07 15:42:04,751 - INFO -marigold_trainer.py - train >> iter 17872 (epoch  8): loss=0.05152
 2025-10-07 15:42:19,423 - INFO -marigold_trainer.py - train >> iter 17873 (epoch  8): loss=0.06273
 2025-10-07 15:42:35,385 - INFO -marigold_trainer.py - train >> iter 17874 (epoch  8): loss=0.06420
 2025-10-07 15:42:50,057 - INFO -marigold_trainer.py - train >> iter 17875 (epoch  8): loss=0.05679
 2025-10-07 15:43:06,014 - INFO -marigold_trainer.py - train >> iter 17876 (epoch  8): loss=0.05708
 2025-10-07 15:43:21,983 - INFO -marigold_trainer.py - train >> iter 17877 (epoch  8): loss=0.06050
 2025-10-07 15:43:38,610 - INFO -marigold_trainer.py - train >> iter 17878 (epoch  8): loss=0.06748
 2025-10-07 15:43:53,928 - INFO -marigold_trainer.py - train >> iter 17879 (epoch  8): loss=0.06080
 2025-10-07 15:44:09,241 - INFO -marigold_trainer.py - train >> iter 17880 (epoch  8): loss=0.06407
 2025-10-07 15:44:25,215 - INFO -marigold_trainer.py - train >> iter 17881 (epoch  8): loss=0.05824
 2025-10-07 15:44:40,539 - INFO -marigold_trainer.py - train >> iter 17882 (epoch  8): loss=0.05513
 2025-10-07 15:44:55,870 - INFO -marigold_trainer.py - train >> iter 17883 (epoch  8): loss=0.05815
 2025-10-07 15:45:11,197 - INFO -marigold_trainer.py - train >> iter 17884 (epoch  8): loss=0.05988
 2025-10-07 15:45:27,822 - INFO -marigold_trainer.py - train >> iter 17885 (epoch  8): loss=0.05359
 2025-10-07 15:45:43,143 - INFO -marigold_trainer.py - train >> iter 17886 (epoch  8): loss=0.05724
 2025-10-07 15:46:00,425 - INFO -marigold_trainer.py - train >> iter 17887 (epoch  8): loss=0.05480
 2025-10-07 15:46:15,747 - INFO -marigold_trainer.py - train >> iter 17888 (epoch  8): loss=0.05916
 2025-10-07 15:46:30,414 - INFO -marigold_trainer.py - train >> iter 17889 (epoch  8): loss=0.05519
 2025-10-07 15:46:46,373 - INFO -marigold_trainer.py - train >> iter 17890 (epoch  8): loss=0.06230
 2025-10-07 15:47:02,443 - INFO -marigold_trainer.py - train >> iter 17891 (epoch  8): loss=0.05229
 2025-10-07 15:47:19,072 - INFO -marigold_trainer.py - train >> iter 17892 (epoch  8): loss=0.06346
 2025-10-07 15:47:35,713 - INFO -marigold_trainer.py - train >> iter 17893 (epoch  8): loss=0.06398
 2025-10-07 15:47:51,041 - INFO -marigold_trainer.py - train >> iter 17894 (epoch  8): loss=0.05355
 2025-10-07 15:48:06,353 - INFO -marigold_trainer.py - train >> iter 17895 (epoch  8): loss=0.05214
 2025-10-07 15:48:22,110 - INFO -marigold_trainer.py - train >> iter 17896 (epoch  8): loss=0.06454
 2025-10-07 15:48:40,256 - INFO -marigold_trainer.py - train >> iter 17897 (epoch  8): loss=0.05687
 2025-10-07 15:48:56,244 - INFO -marigold_trainer.py - train >> iter 17898 (epoch  8): loss=0.05809
 2025-10-07 15:49:11,366 - INFO -marigold_trainer.py - train >> iter 17899 (epoch  8): loss=0.06181
 2025-10-07 15:49:28,189 - INFO -marigold_trainer.py - train >> iter 17900 (epoch  8): loss=0.06061
 2025-10-07 15:49:43,503 - INFO -marigold_trainer.py - train >> iter 17901 (epoch  8): loss=0.05473
 2025-10-07 15:49:58,151 - INFO -marigold_trainer.py - train >> iter 17902 (epoch  8): loss=0.05488
 2025-10-07 15:50:13,457 - INFO -marigold_trainer.py - train >> iter 17903 (epoch  8): loss=0.04889
 2025-10-07 15:50:28,774 - INFO -marigold_trainer.py - train >> iter 17904 (epoch  8): loss=0.07156
 2025-10-07 15:50:44,087 - INFO -marigold_trainer.py - train >> iter 17905 (epoch  8): loss=0.05496
 2025-10-07 15:51:00,059 - INFO -marigold_trainer.py - train >> iter 17906 (epoch  8): loss=0.05686
 2025-10-07 15:51:15,373 - INFO -marigold_trainer.py - train >> iter 17907 (epoch  8): loss=0.05814
 2025-10-07 15:51:30,490 - INFO -marigold_trainer.py - train >> iter 17908 (epoch  8): loss=0.05896
 2025-10-07 15:51:45,999 - INFO -marigold_trainer.py - train >> iter 17909 (epoch  8): loss=0.05734
 2025-10-07 15:52:01,320 - INFO -marigold_trainer.py - train >> iter 17910 (epoch  8): loss=0.05468
 2025-10-07 15:52:17,947 - INFO -marigold_trainer.py - train >> iter 17911 (epoch  8): loss=0.05640
 2025-10-07 15:52:33,271 - INFO -marigold_trainer.py - train >> iter 17912 (epoch  8): loss=0.05701
 2025-10-07 15:52:49,242 - INFO -marigold_trainer.py - train >> iter 17913 (epoch  8): loss=0.05276
 2025-10-07 15:53:03,913 - INFO -marigold_trainer.py - train >> iter 17914 (epoch  8): loss=0.05743
 2025-10-07 15:53:19,213 - INFO -marigold_trainer.py - train >> iter 17915 (epoch  8): loss=0.06105
 2025-10-07 15:53:35,188 - INFO -marigold_trainer.py - train >> iter 17916 (epoch  8): loss=0.05978
 2025-10-07 15:53:50,504 - INFO -marigold_trainer.py - train >> iter 17917 (epoch  8): loss=0.06202
 2025-10-07 15:54:06,475 - INFO -marigold_trainer.py - train >> iter 17918 (epoch  8): loss=0.06351
 2025-10-07 15:54:22,461 - INFO -marigold_trainer.py - train >> iter 17919 (epoch  8): loss=0.05623
 2025-10-07 15:54:38,432 - INFO -marigold_trainer.py - train >> iter 17920 (epoch  8): loss=0.06369
 2025-10-07 15:54:53,101 - INFO -marigold_trainer.py - train >> iter 17921 (epoch  8): loss=0.05742
 2025-10-07 15:55:09,054 - INFO -marigold_trainer.py - train >> iter 17922 (epoch  8): loss=0.06187
 2025-10-07 15:55:25,030 - INFO -marigold_trainer.py - train >> iter 17923 (epoch  8): loss=0.06718
 2025-10-07 15:55:39,704 - INFO -marigold_trainer.py - train >> iter 17924 (epoch  8): loss=0.06465
 2025-10-07 15:55:55,007 - INFO -marigold_trainer.py - train >> iter 17925 (epoch  8): loss=0.06111
 2025-10-07 15:56:11,634 - INFO -marigold_trainer.py - train >> iter 17926 (epoch  8): loss=0.06171
 2025-10-07 15:56:29,567 - INFO -marigold_trainer.py - train >> iter 17927 (epoch  8): loss=0.06395
 2025-10-07 15:56:44,889 - INFO -marigold_trainer.py - train >> iter 17928 (epoch  8): loss=0.05258
 2025-10-07 15:57:00,212 - INFO -marigold_trainer.py - train >> iter 17929 (epoch  8): loss=0.05775
 2025-10-07 15:57:15,536 - INFO -marigold_trainer.py - train >> iter 17930 (epoch  8): loss=0.05610
 2025-10-07 15:57:30,184 - INFO -marigold_trainer.py - train >> iter 17931 (epoch  8): loss=0.05806
 2025-10-07 15:57:45,286 - INFO -marigold_trainer.py - train >> iter 17932 (epoch  8): loss=0.05934
 2025-10-07 15:58:00,161 - INFO -marigold_trainer.py - train >> iter 17933 (epoch  8): loss=0.05589
 2025-10-07 15:58:16,114 - INFO -marigold_trainer.py - train >> iter 17934 (epoch  8): loss=0.05529
 2025-10-07 15:58:32,739 - INFO -marigold_trainer.py - train >> iter 17935 (epoch  8): loss=0.05873
 2025-10-07 15:58:48,062 - INFO -marigold_trainer.py - train >> iter 17936 (epoch  8): loss=0.05745
 2025-10-07 15:59:03,388 - INFO -marigold_trainer.py - train >> iter 17937 (epoch  8): loss=0.05702
 2025-10-07 15:59:20,446 - INFO -marigold_trainer.py - train >> iter 17938 (epoch  8): loss=0.06474
 2025-10-07 15:59:35,318 - INFO -marigold_trainer.py - train >> iter 17939 (epoch  8): loss=0.04973
 2025-10-07 15:59:51,274 - INFO -marigold_trainer.py - train >> iter 17940 (epoch  8): loss=0.05627
 2025-10-07 16:00:05,946 - INFO -marigold_trainer.py - train >> iter 17941 (epoch  8): loss=0.05485
 2025-10-07 16:00:21,247 - INFO -marigold_trainer.py - train >> iter 17942 (epoch  8): loss=0.05675
 2025-10-07 16:00:37,224 - INFO -marigold_trainer.py - train >> iter 17943 (epoch  8): loss=0.05452
 2025-10-07 16:00:53,213 - INFO -marigold_trainer.py - train >> iter 17944 (epoch  8): loss=0.05270
 2025-10-07 16:01:07,883 - INFO -marigold_trainer.py - train >> iter 17945 (epoch  8): loss=0.04890
 2025-10-07 16:01:24,496 - INFO -marigold_trainer.py - train >> iter 17946 (epoch  8): loss=0.06094
 2025-10-07 16:01:39,814 - INFO -marigold_trainer.py - train >> iter 17947 (epoch  8): loss=0.06130
 2025-10-07 16:01:55,791 - INFO -marigold_trainer.py - train >> iter 17948 (epoch  8): loss=0.05990
 2025-10-07 16:02:11,104 - INFO -marigold_trainer.py - train >> iter 17949 (epoch  8): loss=0.05541
 2025-10-07 16:02:27,085 - INFO -marigold_trainer.py - train >> iter 17950 (epoch  8): loss=0.06545
 2025-10-07 16:02:41,743 - INFO -marigold_trainer.py - train >> iter 17951 (epoch  8): loss=0.05704
 2025-10-07 16:02:57,045 - INFO -marigold_trainer.py - train >> iter 17952 (epoch  8): loss=0.05500
 2025-10-07 16:03:12,362 - INFO -marigold_trainer.py - train >> iter 17953 (epoch  8): loss=0.05719
 2025-10-07 16:03:28,340 - INFO -marigold_trainer.py - train >> iter 17954 (epoch  8): loss=0.05868
 2025-10-07 16:03:43,663 - INFO -marigold_trainer.py - train >> iter 17955 (epoch  8): loss=0.06236
 2025-10-07 16:03:58,982 - INFO -marigold_trainer.py - train >> iter 17956 (epoch  8): loss=0.05865
 2025-10-07 16:04:13,660 - INFO -marigold_trainer.py - train >> iter 17957 (epoch  8): loss=0.04668
 2025-10-07 16:04:30,068 - INFO -marigold_trainer.py - train >> iter 17958 (epoch  8): loss=0.05693
 2025-10-07 16:04:45,599 - INFO -marigold_trainer.py - train >> iter 17959 (epoch  8): loss=0.05158
 2025-10-07 16:05:02,232 - INFO -marigold_trainer.py - train >> iter 17960 (epoch  8): loss=0.05428
 2025-10-07 16:05:18,205 - INFO -marigold_trainer.py - train >> iter 17961 (epoch  8): loss=0.05618
 2025-10-07 16:05:34,178 - INFO -marigold_trainer.py - train >> iter 17962 (epoch  8): loss=0.05679
 2025-10-07 16:05:48,849 - INFO -marigold_trainer.py - train >> iter 17963 (epoch  8): loss=0.05023
 2025-10-07 16:06:03,503 - INFO -marigold_trainer.py - train >> iter 17964 (epoch  8): loss=0.05454
 2025-10-07 16:06:18,149 - INFO -marigold_trainer.py - train >> iter 17965 (epoch  8): loss=0.06004
 2025-10-07 16:06:32,795 - INFO -marigold_trainer.py - train >> iter 17966 (epoch  8): loss=0.05560
 2025-10-07 16:06:50,056 - INFO -marigold_trainer.py - train >> iter 17967 (epoch  8): loss=0.05754
 2025-10-07 16:07:05,385 - INFO -marigold_trainer.py - train >> iter 17968 (epoch  8): loss=0.05451
 2025-10-07 16:07:21,355 - INFO -marigold_trainer.py - train >> iter 17969 (epoch  8): loss=0.05783
 2025-10-07 16:07:37,331 - INFO -marigold_trainer.py - train >> iter 17970 (epoch  8): loss=0.05431
 2025-10-07 16:07:53,300 - INFO -marigold_trainer.py - train >> iter 17971 (epoch  8): loss=0.05281
 2025-10-07 16:08:09,945 - INFO -marigold_trainer.py - train >> iter 17972 (epoch  8): loss=0.05566
 2025-10-07 16:08:25,258 - INFO -marigold_trainer.py - train >> iter 17973 (epoch  8): loss=0.05845
 2025-10-07 16:08:39,912 - INFO -marigold_trainer.py - train >> iter 17974 (epoch  8): loss=0.05973
 2025-10-07 16:08:55,214 - INFO -marigold_trainer.py - train >> iter 17975 (epoch  8): loss=0.06328
 2025-10-07 16:09:11,187 - INFO -marigold_trainer.py - train >> iter 17976 (epoch  8): loss=0.06610
 2025-10-07 16:09:26,511 - INFO -marigold_trainer.py - train >> iter 17977 (epoch  8): loss=0.05411
 2025-10-07 16:09:43,140 - INFO -marigold_trainer.py - train >> iter 17978 (epoch  8): loss=0.05476
 2025-10-07 16:09:59,773 - INFO -marigold_trainer.py - train >> iter 17979 (epoch  8): loss=0.05943
 2025-10-07 16:10:15,101 - INFO -marigold_trainer.py - train >> iter 17980 (epoch  8): loss=0.05751
 2025-10-07 16:10:29,768 - INFO -marigold_trainer.py - train >> iter 17981 (epoch  8): loss=0.05790
 2025-10-07 16:10:45,068 - INFO -marigold_trainer.py - train >> iter 17982 (epoch  8): loss=0.05336
 2025-10-07 16:11:01,042 - INFO -marigold_trainer.py - train >> iter 17983 (epoch  8): loss=0.06393
 2025-10-07 16:11:16,361 - INFO -marigold_trainer.py - train >> iter 17984 (epoch  8): loss=0.05326
 2025-10-07 16:11:32,337 - INFO -marigold_trainer.py - train >> iter 17985 (epoch  8): loss=0.05283
 2025-10-07 16:11:48,316 - INFO -marigold_trainer.py - train >> iter 17986 (epoch  8): loss=0.05442
 2025-10-07 16:12:03,643 - INFO -marigold_trainer.py - train >> iter 17987 (epoch  8): loss=0.05626
 2025-10-07 16:12:20,287 - INFO -marigold_trainer.py - train >> iter 17988 (epoch  8): loss=0.06014
 2025-10-07 16:12:36,273 - INFO -marigold_trainer.py - train >> iter 17989 (epoch  8): loss=0.05252
 2025-10-07 16:12:51,588 - INFO -marigold_trainer.py - train >> iter 17990 (epoch  8): loss=0.06237
 2025-10-07 16:13:08,234 - INFO -marigold_trainer.py - train >> iter 17991 (epoch  8): loss=0.05438
 2025-10-07 16:13:22,897 - INFO -marigold_trainer.py - train >> iter 17992 (epoch  8): loss=0.05099
 2025-10-07 16:13:37,545 - INFO -marigold_trainer.py - train >> iter 17993 (epoch  8): loss=0.05401
 2025-10-07 16:13:52,287 - INFO -marigold_trainer.py - train >> iter 17994 (epoch  8): loss=0.05194
 2025-10-07 16:14:08,912 - INFO -marigold_trainer.py - train >> iter 17995 (epoch  8): loss=0.05881
 2025-10-07 16:14:24,244 - INFO -marigold_trainer.py - train >> iter 17996 (epoch  8): loss=0.05526
 2025-10-07 16:14:39,576 - INFO -marigold_trainer.py - train >> iter 17997 (epoch  8): loss=0.05712
 2025-10-07 16:14:56,210 - INFO -marigold_trainer.py - train >> iter 17998 (epoch  8): loss=0.06121
 2025-10-07 16:15:10,876 - INFO -marigold_trainer.py - train >> iter 17999 (epoch  8): loss=0.05984
 2025-10-07 16:15:25,527 - INFO -marigold_trainer.py - train >> iter 18000 (epoch  8): loss=0.05297
 2025-10-07 16:15:25,527 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: output/train_marigold/checkpoint/iter_018000
 2025-10-07 16:15:28,858 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: output/train_marigold/checkpoint/iter_018000/unet
 2025-10-07 16:15:28,866 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: output/train_marigold/checkpoint/latest
 2025-10-07 16:15:28,867 - DEBUG -marigold_trainer.py - save_checkpoint >> Old checkpoint is backed up at: output/train_marigold/checkpoint/_old_latest
 2025-10-07 16:15:32,051 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: output/train_marigold/checkpoint/latest/unet
 2025-10-07 16:15:38,227 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: output/train_marigold/checkpoint/latest/trainer.ckpt
 2025-10-07 16:15:38,732 - DEBUG -marigold_trainer.py - save_checkpoint >> Old checkpoint backup is removed.
 2025-10-07 16:15:53,085 - INFO -marigold_trainer.py - train >> iter 18001 (epoch  8): loss=0.05610
 2025-10-07 16:16:08,386 - INFO -marigold_trainer.py - train >> iter 18002 (epoch  8): loss=0.05782
 2025-10-07 16:16:24,171 - INFO -marigold_trainer.py - train >> iter 18003 (epoch  8): loss=0.06139
 2025-10-07 16:16:39,047 - INFO -marigold_trainer.py - train >> iter 18004 (epoch  8): loss=0.05947
 2025-10-07 16:16:54,999 - INFO -marigold_trainer.py - train >> iter 18005 (epoch  8): loss=0.05062
 2025-10-07 16:17:10,965 - INFO -marigold_trainer.py - train >> iter 18006 (epoch  8): loss=0.06073
 2025-10-07 16:17:27,578 - INFO -marigold_trainer.py - train >> iter 18007 (epoch  8): loss=0.05618
 2025-10-07 16:17:43,552 - INFO -marigold_trainer.py - train >> iter 18008 (epoch  8): loss=0.05837
 2025-10-07 16:17:58,225 - INFO -marigold_trainer.py - train >> iter 18009 (epoch  8): loss=0.05792
 2025-10-07 16:18:14,184 - INFO -marigold_trainer.py - train >> iter 18010 (epoch  8): loss=0.05860
 2025-10-07 16:18:28,846 - INFO -marigold_trainer.py - train >> iter 18011 (epoch  8): loss=0.04989
 2025-10-07 16:18:44,603 - INFO -marigold_trainer.py - train >> iter 18012 (epoch  8): loss=0.06135
 2025-10-07 16:19:00,132 - INFO -marigold_trainer.py - train >> iter 18013 (epoch  8): loss=0.05794
 2025-10-07 16:19:16,084 - INFO -marigold_trainer.py - train >> iter 18014 (epoch  8): loss=0.04469
 2025-10-07 16:19:31,404 - INFO -marigold_trainer.py - train >> iter 18015 (epoch  8): loss=0.05830
 2025-10-07 16:19:46,726 - INFO -marigold_trainer.py - train >> iter 18016 (epoch  8): loss=0.05681
 2025-10-07 16:20:02,054 - INFO -marigold_trainer.py - train >> iter 18017 (epoch  8): loss=0.06084
 2025-10-07 16:20:18,032 - INFO -marigold_trainer.py - train >> iter 18018 (epoch  8): loss=0.06121
 2025-10-07 16:20:34,668 - INFO -marigold_trainer.py - train >> iter 18019 (epoch  8): loss=0.06792
 2025-10-07 16:20:49,989 - INFO -marigold_trainer.py - train >> iter 18020 (epoch  8): loss=0.05397
 2025-10-07 16:21:05,756 - INFO -marigold_trainer.py - train >> iter 18021 (epoch  8): loss=0.05428
 2025-10-07 16:21:21,928 - INFO -marigold_trainer.py - train >> iter 18022 (epoch  8): loss=0.05040
 2025-10-07 16:21:37,893 - INFO -marigold_trainer.py - train >> iter 18023 (epoch  8): loss=0.06015
 2025-10-07 16:21:53,230 - INFO -marigold_trainer.py - train >> iter 18024 (epoch  8): loss=0.05208
 2025-10-07 16:22:08,558 - INFO -marigold_trainer.py - train >> iter 18025 (epoch  8): loss=0.05849
 2025-10-07 16:22:25,180 - INFO -marigold_trainer.py - train >> iter 18026 (epoch  8): loss=0.06972
 2025-10-07 16:22:40,499 - INFO -marigold_trainer.py - train >> iter 18027 (epoch  8): loss=0.05878
 2025-10-07 16:22:55,824 - INFO -marigold_trainer.py - train >> iter 18028 (epoch  8): loss=0.06127
 2025-10-07 16:23:11,804 - INFO -marigold_trainer.py - train >> iter 18029 (epoch  8): loss=0.06498
 2025-10-07 16:23:27,112 - INFO -marigold_trainer.py - train >> iter 18030 (epoch  8): loss=0.06128
 2025-10-07 16:23:43,540 - INFO -marigold_trainer.py - train >> iter 18031 (epoch  8): loss=0.06179
 2025-10-07 16:23:59,066 - INFO -marigold_trainer.py - train >> iter 18032 (epoch  8): loss=0.05578
 2025-10-07 16:24:15,042 - INFO -marigold_trainer.py - train >> iter 18033 (epoch  8): loss=0.05857
 2025-10-07 16:24:29,715 - INFO -marigold_trainer.py - train >> iter 18034 (epoch  8): loss=0.06272
 2025-10-07 16:24:45,017 - INFO -marigold_trainer.py - train >> iter 18035 (epoch  8): loss=0.05820
 2025-10-07 16:25:00,992 - INFO -marigold_trainer.py - train >> iter 18036 (epoch  8): loss=0.06607
 2025-10-07 16:25:16,964 - INFO -marigold_trainer.py - train >> iter 18037 (epoch  8): loss=0.05669
 2025-10-07 16:25:31,632 - INFO -marigold_trainer.py - train >> iter 18038 (epoch  8): loss=0.05698
 2025-10-07 16:25:47,587 - INFO -marigold_trainer.py - train >> iter 18039 (epoch  8): loss=0.06553
 2025-10-07 16:26:03,563 - INFO -marigold_trainer.py - train >> iter 18040 (epoch  8): loss=0.05371
 2025-10-07 16:26:20,847 - INFO -marigold_trainer.py - train >> iter 18041 (epoch  8): loss=0.05740
 2025-10-07 16:26:39,440 - INFO -marigold_trainer.py - train >> iter 18042 (epoch  8): loss=0.05890
 2025-10-07 16:26:55,421 - INFO -marigold_trainer.py - train >> iter 18043 (epoch  8): loss=0.06342
 2025-10-07 16:27:10,740 - INFO -marigold_trainer.py - train >> iter 18044 (epoch  8): loss=0.05663
 2025-10-07 16:27:27,369 - INFO -marigold_trainer.py - train >> iter 18045 (epoch  8): loss=0.06035
 2025-10-07 16:27:43,347 - INFO -marigold_trainer.py - train >> iter 18046 (epoch  8): loss=0.05978
 2025-10-07 16:27:59,322 - INFO -marigold_trainer.py - train >> iter 18047 (epoch  8): loss=0.05858
 2025-10-07 16:28:14,643 - INFO -marigold_trainer.py - train >> iter 18048 (epoch  8): loss=0.05840
 2025-10-07 16:28:30,600 - INFO -marigold_trainer.py - train >> iter 18049 (epoch  8): loss=0.05343
 2025-10-07 16:28:46,566 - INFO -marigold_trainer.py - train >> iter 18050 (epoch  8): loss=0.05671
 2025-10-07 16:29:02,535 - INFO -marigold_trainer.py - train >> iter 18051 (epoch  8): loss=0.05805
 2025-10-07 16:29:17,850 - INFO -marigold_trainer.py - train >> iter 18052 (epoch  8): loss=0.05187
 2025-10-07 16:29:32,512 - INFO -marigold_trainer.py - train >> iter 18053 (epoch  8): loss=0.06133
 2025-10-07 16:29:49,120 - INFO -marigold_trainer.py - train >> iter 18054 (epoch  8): loss=0.05132
 2025-10-07 16:30:04,891 - INFO -marigold_trainer.py - train >> iter 18055 (epoch  8): loss=0.05259
 2025-10-07 16:30:19,751 - INFO -marigold_trainer.py - train >> iter 18056 (epoch  8): loss=0.05678
 2025-10-07 16:30:36,155 - INFO -marigold_trainer.py - train >> iter 18057 (epoch  8): loss=0.05391
 2025-10-07 16:30:51,671 - INFO -marigold_trainer.py - train >> iter 18058 (epoch  8): loss=0.05376
 2025-10-07 16:31:06,998 - INFO -marigold_trainer.py - train >> iter 18059 (epoch  8): loss=0.05541
 2025-10-07 16:31:22,320 - INFO -marigold_trainer.py - train >> iter 18060 (epoch  8): loss=0.06953
 2025-10-07 16:31:37,646 - INFO -marigold_trainer.py - train >> iter 18061 (epoch  8): loss=0.06182
 2025-10-07 16:31:55,384 - INFO -marigold_trainer.py - train >> iter 18062 (epoch  8): loss=0.05750
 2025-10-07 16:32:11,563 - INFO -marigold_trainer.py - train >> iter 18063 (epoch  8): loss=0.05523
 2025-10-07 16:32:27,541 - INFO -marigold_trainer.py - train >> iter 18064 (epoch  8): loss=0.05709
 2025-10-07 16:32:43,517 - INFO -marigold_trainer.py - train >> iter 18065 (epoch  8): loss=0.05589
 2025-10-07 16:33:00,794 - INFO -marigold_trainer.py - train >> iter 18066 (epoch  8): loss=0.06092
 2025-10-07 16:33:18,083 - INFO -marigold_trainer.py - train >> iter 18067 (epoch  8): loss=0.06647
 2025-10-07 16:33:34,049 - INFO -marigold_trainer.py - train >> iter 18068 (epoch  8): loss=0.06010
 2025-10-07 16:33:49,376 - INFO -marigold_trainer.py - train >> iter 18069 (epoch  8): loss=0.05988
 2025-10-07 16:34:04,677 - INFO -marigold_trainer.py - train >> iter 18070 (epoch  8): loss=0.05595
 2025-10-07 16:34:19,351 - INFO -marigold_trainer.py - train >> iter 18071 (epoch  8): loss=0.05213
 2025-10-07 16:34:33,997 - INFO -marigold_trainer.py - train >> iter 18072 (epoch  8): loss=0.05481
 2025-10-07 16:34:48,644 - INFO -marigold_trainer.py - train >> iter 18073 (epoch  8): loss=0.06787
 2025-10-07 16:35:05,263 - INFO -marigold_trainer.py - train >> iter 18074 (epoch  8): loss=0.05950
 2025-10-07 16:35:20,582 - INFO -marigold_trainer.py - train >> iter 18075 (epoch  8): loss=0.05601
 2025-10-07 16:35:37,212 - INFO -marigold_trainer.py - train >> iter 18076 (epoch  8): loss=0.06078
 2025-10-07 16:35:52,526 - INFO -marigold_trainer.py - train >> iter 18077 (epoch  8): loss=0.06064
 2025-10-07 16:36:07,849 - INFO -marigold_trainer.py - train >> iter 18078 (epoch  8): loss=0.05855
 2025-10-07 16:36:23,173 - INFO -marigold_trainer.py - train >> iter 18079 (epoch  8): loss=0.05808
 2025-10-07 16:36:38,494 - INFO -marigold_trainer.py - train >> iter 18080 (epoch  8): loss=0.05453
 2025-10-07 16:36:53,610 - INFO -marigold_trainer.py - train >> iter 18081 (epoch  8): loss=0.04884
 2025-10-07 16:37:09,788 - INFO -marigold_trainer.py - train >> iter 18082 (epoch  8): loss=0.05492
 2025-10-07 16:37:25,777 - INFO -marigold_trainer.py - train >> iter 18083 (epoch  8): loss=0.04585
 2025-10-07 16:37:41,752 - INFO -marigold_trainer.py - train >> iter 18084 (epoch  8): loss=0.06149
 2025-10-07 16:37:57,528 - INFO -marigold_trainer.py - train >> iter 18085 (epoch  8): loss=0.05256
 2025-10-07 16:38:13,701 - INFO -marigold_trainer.py - train >> iter 18086 (epoch  8): loss=0.06152
 2025-10-07 16:38:28,456 - INFO -marigold_trainer.py - train >> iter 18087 (epoch  8): loss=0.05735
 2025-10-07 16:38:45,715 - INFO -marigold_trainer.py - train >> iter 18088 (epoch  8): loss=0.06883
 2025-10-07 16:39:01,697 - INFO -marigold_trainer.py - train >> iter 18089 (epoch  8): loss=0.05508
 2025-10-07 16:39:17,669 - INFO -marigold_trainer.py - train >> iter 18090 (epoch  8): loss=0.06073
 2025-10-07 16:39:33,645 - INFO -marigold_trainer.py - train >> iter 18091 (epoch  8): loss=0.06055
 2025-10-07 16:39:50,272 - INFO -marigold_trainer.py - train >> iter 18092 (epoch  8): loss=0.04669
 2025-10-07 16:40:04,940 - INFO -marigold_trainer.py - train >> iter 18093 (epoch  8): loss=0.06110
 2025-10-07 16:40:20,894 - INFO -marigold_trainer.py - train >> iter 18094 (epoch  8): loss=0.05780
 2025-10-07 16:40:35,563 - INFO -marigold_trainer.py - train >> iter 18095 (epoch  8): loss=0.05411
 2025-10-07 16:40:52,827 - INFO -marigold_trainer.py - train >> iter 18096 (epoch  8): loss=0.05176
 2025-10-07 16:41:08,155 - INFO -marigold_trainer.py - train >> iter 18097 (epoch  8): loss=0.05873
 2025-10-07 16:41:23,928 - INFO -marigold_trainer.py - train >> iter 18098 (epoch  8): loss=0.06042
 2025-10-07 16:41:40,097 - INFO -marigold_trainer.py - train >> iter 18099 (epoch  8): loss=0.05744
 2025-10-07 16:41:55,421 - INFO -marigold_trainer.py - train >> iter 18100 (epoch  8): loss=0.05410
 2025-10-07 16:42:12,055 - INFO -marigold_trainer.py - train >> iter 18101 (epoch  8): loss=0.05668
 2025-10-07 16:42:27,382 - INFO -marigold_trainer.py - train >> iter 18102 (epoch  8): loss=0.05825
 2025-10-07 16:42:42,703 - INFO -marigold_trainer.py - train >> iter 18103 (epoch  8): loss=0.04601
 2025-10-07 16:42:58,020 - INFO -marigold_trainer.py - train >> iter 18104 (epoch  8): loss=0.05847
 2025-10-07 16:43:14,632 - INFO -marigold_trainer.py - train >> iter 18105 (epoch  8): loss=0.06165
 2025-10-07 16:43:29,942 - INFO -marigold_trainer.py - train >> iter 18106 (epoch  8): loss=0.05819
 2025-10-07 16:43:45,912 - INFO -marigold_trainer.py - train >> iter 18107 (epoch  8): loss=0.07112
 2025-10-07 16:44:01,240 - INFO -marigold_trainer.py - train >> iter 18108 (epoch  8): loss=0.07089
 2025-10-07 16:44:17,217 - INFO -marigold_trainer.py - train >> iter 18109 (epoch  8): loss=0.06130
 2025-10-07 16:44:32,541 - INFO -marigold_trainer.py - train >> iter 18110 (epoch  8): loss=0.05338
 2025-10-07 16:44:47,855 - INFO -marigold_trainer.py - train >> iter 18111 (epoch  8): loss=0.05407
 2025-10-07 16:45:02,526 - INFO -marigold_trainer.py - train >> iter 18112 (epoch  8): loss=0.05644
 2025-10-07 16:45:17,833 - INFO -marigold_trainer.py - train >> iter 18113 (epoch  8): loss=0.05440
 2025-10-07 16:45:33,803 - INFO -marigold_trainer.py - train >> iter 18114 (epoch  8): loss=0.05792
 2025-10-07 16:45:49,784 - INFO -marigold_trainer.py - train >> iter 18115 (epoch  8): loss=0.05742
 2025-10-07 16:46:05,765 - INFO -marigold_trainer.py - train >> iter 18116 (epoch  8): loss=0.05552
 2025-10-07 16:46:21,540 - INFO -marigold_trainer.py - train >> iter 18117 (epoch  8): loss=0.06445
 2025-10-07 16:46:38,370 - INFO -marigold_trainer.py - train >> iter 18118 (epoch  8): loss=0.05741
 2025-10-07 16:46:54,355 - INFO -marigold_trainer.py - train >> iter 18119 (epoch  8): loss=0.05992
 2025-10-07 16:47:09,681 - INFO -marigold_trainer.py - train >> iter 18120 (epoch  8): loss=0.06576
 2025-10-07 16:47:24,352 - INFO -marigold_trainer.py - train >> iter 18121 (epoch  8): loss=0.05606
 2025-10-07 16:47:39,000 - INFO -marigold_trainer.py - train >> iter 18122 (epoch  8): loss=0.05514
 2025-10-07 16:47:54,954 - INFO -marigold_trainer.py - train >> iter 18123 (epoch  8): loss=0.05592
 2025-10-07 16:48:09,620 - INFO -marigold_trainer.py - train >> iter 18124 (epoch  8): loss=0.06254
 2025-10-07 16:48:26,881 - INFO -marigold_trainer.py - train >> iter 18125 (epoch  8): loss=0.05542
 2025-10-07 16:48:43,310 - INFO -marigold_trainer.py - train >> iter 18126 (epoch  8): loss=0.05088
 2025-10-07 16:49:00,796 - INFO -marigold_trainer.py - train >> iter 18127 (epoch  8): loss=0.05655
 2025-10-07 16:49:17,406 - INFO -marigold_trainer.py - train >> iter 18128 (epoch  8): loss=0.06715
 2025-10-07 16:49:34,675 - INFO -marigold_trainer.py - train >> iter 18129 (epoch  8): loss=0.05396
 2025-10-07 16:49:49,993 - INFO -marigold_trainer.py - train >> iter 18130 (epoch  8): loss=0.05721
 2025-10-07 16:50:05,978 - INFO -marigold_trainer.py - train >> iter 18131 (epoch  8): loss=0.06421
 2025-10-07 16:50:20,636 - INFO -marigold_trainer.py - train >> iter 18132 (epoch  8): loss=0.05877
 2025-10-07 16:50:35,941 - INFO -marigold_trainer.py - train >> iter 18133 (epoch  8): loss=0.06055
 2025-10-07 16:50:51,917 - INFO -marigold_trainer.py - train >> iter 18134 (epoch  8): loss=0.06188
 2025-10-07 16:51:08,551 - INFO -marigold_trainer.py - train >> iter 18135 (epoch  8): loss=0.04972
 2025-10-07 16:51:23,877 - INFO -marigold_trainer.py - train >> iter 18136 (epoch  8): loss=0.05991
 2025-10-07 16:51:39,854 - INFO -marigold_trainer.py - train >> iter 18137 (epoch  8): loss=0.05882
 2025-10-07 16:51:55,828 - INFO -marigold_trainer.py - train >> iter 18138 (epoch  8): loss=0.05500
 2025-10-07 16:52:10,483 - INFO -marigold_trainer.py - train >> iter 18139 (epoch  8): loss=0.05042
 2025-10-07 16:52:25,132 - INFO -marigold_trainer.py - train >> iter 18140 (epoch  8): loss=0.06209
 2025-10-07 16:52:42,191 - INFO -marigold_trainer.py - train >> iter 18141 (epoch  8): loss=0.04831
 2025-10-07 16:52:57,711 - INFO -marigold_trainer.py - train >> iter 18142 (epoch  8): loss=0.05977
 2025-10-07 16:53:12,376 - INFO -marigold_trainer.py - train >> iter 18143 (epoch  8): loss=0.06102
 2025-10-07 16:53:27,676 - INFO -marigold_trainer.py - train >> iter 18144 (epoch  8): loss=0.06211
 2025-10-07 16:53:43,643 - INFO -marigold_trainer.py - train >> iter 18145 (epoch  8): loss=0.05778
 2025-10-07 16:53:58,311 - INFO -marigold_trainer.py - train >> iter 18146 (epoch  8): loss=0.06034
 2025-10-07 16:54:13,607 - INFO -marigold_trainer.py - train >> iter 18147 (epoch  8): loss=0.05747
 2025-10-07 16:54:29,582 - INFO -marigold_trainer.py - train >> iter 18148 (epoch  8): loss=0.05309
 2025-10-07 16:54:46,008 - INFO -marigold_trainer.py - train >> iter 18149 (epoch  8): loss=0.06211
 2025-10-07 16:55:01,524 - INFO -marigold_trainer.py - train >> iter 18150 (epoch  8): loss=0.06203
 2025-10-07 16:55:19,265 - INFO -marigold_trainer.py - train >> iter 18151 (epoch  8): loss=0.06175
 2025-10-07 16:55:36,090 - INFO -marigold_trainer.py - train >> iter 18152 (epoch  8): loss=0.06313
 2025-10-07 16:55:52,073 - INFO -marigold_trainer.py - train >> iter 18153 (epoch  8): loss=0.05219
 2025-10-07 16:56:07,389 - INFO -marigold_trainer.py - train >> iter 18154 (epoch  8): loss=0.05863
 2025-10-07 16:56:22,052 - INFO -marigold_trainer.py - train >> iter 18155 (epoch  8): loss=0.05815
 2025-10-07 16:56:39,112 - INFO -marigold_trainer.py - train >> iter 18156 (epoch  8): loss=0.05730
 2025-10-07 16:56:53,975 - INFO -marigold_trainer.py - train >> iter 18157 (epoch  8): loss=0.05481
 2025-10-07 16:57:09,272 - INFO -marigold_trainer.py - train >> iter 18158 (epoch  8): loss=0.06686
 2025-10-07 16:57:24,595 - INFO -marigold_trainer.py - train >> iter 18159 (epoch  8): loss=0.05377
 2025-10-07 16:57:41,217 - INFO -marigold_trainer.py - train >> iter 18160 (epoch  8): loss=0.05587
 2025-10-07 16:57:56,544 - INFO -marigold_trainer.py - train >> iter 18161 (epoch  8): loss=0.05205
 2025-10-07 16:58:12,526 - INFO -marigold_trainer.py - train >> iter 18162 (epoch  8): loss=0.05229
 2025-10-07 16:58:28,512 - INFO -marigold_trainer.py - train >> iter 18163 (epoch  8): loss=0.05822
 2025-10-07 16:58:44,288 - INFO -marigold_trainer.py - train >> iter 18164 (epoch  8): loss=0.06708
 2025-10-07 16:59:00,466 - INFO -marigold_trainer.py - train >> iter 18165 (epoch  8): loss=0.05646
 2025-10-07 16:59:15,788 - INFO -marigold_trainer.py - train >> iter 18166 (epoch  8): loss=0.05149
 2025-10-07 16:59:30,462 - INFO -marigold_trainer.py - train >> iter 18167 (epoch  8): loss=0.06261
 2025-10-07 16:59:45,768 - INFO -marigold_trainer.py - train >> iter 18168 (epoch  8): loss=0.05750
 2025-10-07 17:00:00,445 - INFO -marigold_trainer.py - train >> iter 18169 (epoch  8): loss=0.06084
 2025-10-07 17:00:15,092 - INFO -marigold_trainer.py - train >> iter 18170 (epoch  8): loss=0.05237
 2025-10-07 17:00:32,351 - INFO -marigold_trainer.py - train >> iter 18171 (epoch  8): loss=0.05854
 2025-10-07 17:00:48,327 - INFO -marigold_trainer.py - train >> iter 18172 (epoch  8): loss=0.05727
 2025-10-07 17:01:04,309 - INFO -marigold_trainer.py - train >> iter 18173 (epoch  8): loss=0.05290
 2025-10-07 17:01:20,284 - INFO -marigold_trainer.py - train >> iter 18174 (epoch  8): loss=0.06354
 2025-10-07 17:01:36,254 - INFO -marigold_trainer.py - train >> iter 18175 (epoch  8): loss=0.06471
 2025-10-07 17:01:52,237 - INFO -marigold_trainer.py - train >> iter 18176 (epoch  8): loss=0.06030
 2025-10-07 17:02:07,555 - INFO -marigold_trainer.py - train >> iter 18177 (epoch  8): loss=0.06215
 2025-10-07 17:02:24,632 - INFO -marigold_trainer.py - train >> iter 18178 (epoch  8): loss=0.06343
 2025-10-07 17:02:39,504 - INFO -marigold_trainer.py - train >> iter 18179 (epoch  8): loss=0.05597
 2025-10-07 17:02:54,153 - INFO -marigold_trainer.py - train >> iter 18180 (epoch  8): loss=0.05585
 2025-10-07 17:03:10,763 - INFO -marigold_trainer.py - train >> iter 18181 (epoch  8): loss=0.06424
 2025-10-07 17:03:25,442 - INFO -marigold_trainer.py - train >> iter 18182 (epoch  8): loss=0.06338
 2025-10-07 17:03:41,394 - INFO -marigold_trainer.py - train >> iter 18183 (epoch  8): loss=0.05192
 2025-10-07 17:03:57,167 - INFO -marigold_trainer.py - train >> iter 18184 (epoch  8): loss=0.06039
 2025-10-07 17:04:12,039 - INFO -marigold_trainer.py - train >> iter 18185 (epoch  8): loss=0.05741
 2025-10-07 17:04:27,986 - INFO -marigold_trainer.py - train >> iter 18186 (epoch  8): loss=0.06145
 2025-10-07 17:04:42,657 - INFO -marigold_trainer.py - train >> iter 18187 (epoch  8): loss=0.05289
 2025-10-07 17:04:57,306 - INFO -marigold_trainer.py - train >> iter 18188 (epoch  8): loss=0.04944
 2025-10-07 17:05:13,350 - INFO -marigold_trainer.py - train >> iter 18189 (epoch  8): loss=0.06296
 2025-10-07 17:05:29,986 - INFO -marigold_trainer.py - train >> iter 18190 (epoch  8): loss=0.06068
 2025-10-07 17:05:45,305 - INFO -marigold_trainer.py - train >> iter 18191 (epoch  8): loss=0.05166
 2025-10-07 17:06:00,623 - INFO -marigold_trainer.py - train >> iter 18192 (epoch  8): loss=0.05802
 2025-10-07 17:06:17,050 - INFO -marigold_trainer.py - train >> iter 18193 (epoch  8): loss=0.05888
 2025-10-07 17:06:31,928 - INFO -marigold_trainer.py - train >> iter 18194 (epoch  8): loss=0.06636
 2025-10-07 17:06:47,883 - INFO -marigold_trainer.py - train >> iter 18195 (epoch  8): loss=0.04986
 2025-10-07 17:07:03,851 - INFO -marigold_trainer.py - train >> iter 18196 (epoch  8): loss=0.05204
 2025-10-07 17:07:19,834 - INFO -marigold_trainer.py - train >> iter 18197 (epoch  8): loss=0.05243
 2025-10-07 17:07:37,112 - INFO -marigold_trainer.py - train >> iter 18198 (epoch  8): loss=0.05560
 2025-10-07 17:07:51,784 - INFO -marigold_trainer.py - train >> iter 18199 (epoch  8): loss=0.05262
 2025-10-07 17:08:07,088 - INFO -marigold_trainer.py - train >> iter 18200 (epoch  8): loss=0.06177
 2025-10-07 17:08:23,068 - INFO -marigold_trainer.py - train >> iter 18201 (epoch  8): loss=0.05158
 2025-10-07 17:08:39,702 - INFO -marigold_trainer.py - train >> iter 18202 (epoch  8): loss=0.06289
 2025-10-07 17:08:55,471 - INFO -marigold_trainer.py - train >> iter 18203 (epoch  8): loss=0.06665
 2025-10-07 17:09:10,985 - INFO -marigold_trainer.py - train >> iter 18204 (epoch  8): loss=0.05724
 2025-10-07 17:09:25,651 - INFO -marigold_trainer.py - train >> iter 18205 (epoch  8): loss=0.05594
 2025-10-07 17:09:41,611 - INFO -marigold_trainer.py - train >> iter 18206 (epoch  8): loss=0.06311
 2025-10-07 17:09:57,592 - INFO -marigold_trainer.py - train >> iter 18207 (epoch  8): loss=0.06347
 2025-10-07 17:10:12,914 - INFO -marigold_trainer.py - train >> iter 18208 (epoch  8): loss=0.05972
 2025-10-07 17:10:28,891 - INFO -marigold_trainer.py - train >> iter 18209 (epoch  8): loss=0.05562
 2025-10-07 17:10:44,219 - INFO -marigold_trainer.py - train >> iter 18210 (epoch  8): loss=0.06032
 2025-10-07 17:10:59,540 - INFO -marigold_trainer.py - train >> iter 18211 (epoch  8): loss=0.05624
 2025-10-07 17:11:16,623 - INFO -marigold_trainer.py - train >> iter 18212 (epoch  8): loss=0.06567
 2025-10-07 17:11:32,148 - INFO -marigold_trainer.py - train >> iter 18213 (epoch  8): loss=0.06139
 2025-10-07 17:11:48,123 - INFO -marigold_trainer.py - train >> iter 18214 (epoch  8): loss=0.06176
 2025-10-07 17:12:04,109 - INFO -marigold_trainer.py - train >> iter 18215 (epoch  8): loss=0.05553
 2025-10-07 17:12:19,887 - INFO -marigold_trainer.py - train >> iter 18216 (epoch  8): loss=0.06037
 2025-10-07 17:12:36,725 - INFO -marigold_trainer.py - train >> iter 18217 (epoch  8): loss=0.06008
 2025-10-07 17:12:52,049 - INFO -marigold_trainer.py - train >> iter 18218 (epoch  8): loss=0.05275
 2025-10-07 17:13:06,701 - INFO -marigold_trainer.py - train >> iter 18219 (epoch  8): loss=0.05357
 2025-10-07 17:13:22,004 - INFO -marigold_trainer.py - train >> iter 18220 (epoch  8): loss=0.05558
 2025-10-07 17:13:37,977 - INFO -marigold_trainer.py - train >> iter 18221 (epoch  8): loss=0.05173
 2025-10-07 17:13:55,251 - INFO -marigold_trainer.py - train >> iter 18222 (epoch  8): loss=0.05702
 2025-10-07 17:14:11,231 - INFO -marigold_trainer.py - train >> iter 18223 (epoch  8): loss=0.05601
 2025-10-07 17:14:26,562 - INFO -marigold_trainer.py - train >> iter 18224 (epoch  8): loss=0.05707
 2025-10-07 17:14:43,191 - INFO -marigold_trainer.py - train >> iter 18225 (epoch  8): loss=0.05627
 2025-10-07 17:14:58,507 - INFO -marigold_trainer.py - train >> iter 18226 (epoch  8): loss=0.05071
 2025-10-07 17:15:13,825 - INFO -marigold_trainer.py - train >> iter 18227 (epoch  8): loss=0.05564
 2025-10-07 17:15:29,802 - INFO -marigold_trainer.py - train >> iter 18228 (epoch  8): loss=0.06224
 2025-10-07 17:15:45,573 - INFO -marigold_trainer.py - train >> iter 18229 (epoch  8): loss=0.05956
 2025-10-07 17:16:01,747 - INFO -marigold_trainer.py - train >> iter 18230 (epoch  8): loss=0.06198
 2025-10-07 17:16:17,060 - INFO -marigold_trainer.py - train >> iter 18231 (epoch  8): loss=0.06553
 2025-10-07 17:16:33,040 - INFO -marigold_trainer.py - train >> iter 18232 (epoch  8): loss=0.06165
 2025-10-07 17:16:48,360 - INFO -marigold_trainer.py - train >> iter 18233 (epoch  8): loss=0.05308
 2025-10-07 17:17:04,987 - INFO -marigold_trainer.py - train >> iter 18234 (epoch  8): loss=0.05608
 2025-10-07 17:17:20,303 - INFO -marigold_trainer.py - train >> iter 18235 (epoch  8): loss=0.06278
 2025-10-07 17:17:36,277 - INFO -marigold_trainer.py - train >> iter 18236 (epoch  8): loss=0.05900
 2025-10-07 17:17:50,941 - INFO -marigold_trainer.py - train >> iter 18237 (epoch  8): loss=0.05551
 2025-10-07 17:18:06,244 - INFO -marigold_trainer.py - train >> iter 18238 (epoch  8): loss=0.06220
 2025-10-07 17:18:22,220 - INFO -marigold_trainer.py - train >> iter 18239 (epoch  8): loss=0.07029
 2025-10-07 17:18:37,548 - INFO -marigold_trainer.py - train >> iter 18240 (epoch  8): loss=0.06614
 2025-10-07 17:18:53,530 - INFO -marigold_trainer.py - train >> iter 18241 (epoch  8): loss=0.05633
 2025-10-07 17:19:08,850 - INFO -marigold_trainer.py - train >> iter 18242 (epoch  8): loss=0.05446
 2025-10-07 17:19:24,167 - INFO -marigold_trainer.py - train >> iter 18243 (epoch  8): loss=0.05663
 2025-10-07 17:19:39,290 - INFO -marigold_trainer.py - train >> iter 18244 (epoch  8): loss=0.05518
 2025-10-07 17:19:54,152 - INFO -marigold_trainer.py - train >> iter 18245 (epoch  8): loss=0.06435
 2025-10-07 17:20:09,912 - INFO -marigold_trainer.py - train >> iter 18246 (epoch  8): loss=0.06140
 2025-10-07 17:20:27,397 - INFO -marigold_trainer.py - train >> iter 18247 (epoch  8): loss=0.05851
 2025-10-07 17:20:42,729 - INFO -marigold_trainer.py - train >> iter 18248 (epoch  8): loss=0.06226
 2025-10-07 17:20:58,051 - INFO -marigold_trainer.py - train >> iter 18249 (epoch  8): loss=0.06007
 2025-10-07 17:21:14,029 - INFO -marigold_trainer.py - train >> iter 18250 (epoch  8): loss=0.05082
 2025-10-07 17:21:14,030 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: output/train_marigold/checkpoint/latest
 2025-10-07 17:21:14,030 - DEBUG -marigold_trainer.py - save_checkpoint >> Old checkpoint is backed up at: output/train_marigold/checkpoint/_old_latest
 2025-10-07 17:21:17,352 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: output/train_marigold/checkpoint/latest/unet
 2025-10-07 17:21:23,437 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: output/train_marigold/checkpoint/latest/trainer.ckpt
 2025-10-07 17:21:24,142 - DEBUG -marigold_trainer.py - save_checkpoint >> Old checkpoint backup is removed.
 2025-10-07 17:21:39,186 - INFO -marigold_trainer.py - train >> iter 18251 (epoch  8): loss=0.05031
 2025-10-07 17:21:55,804 - INFO -marigold_trainer.py - train >> iter 18252 (epoch  8): loss=0.05280
 2025-10-07 17:22:11,785 - INFO -marigold_trainer.py - train >> iter 18253 (epoch  8): loss=0.06089
 2025-10-07 17:22:27,762 - INFO -marigold_trainer.py - train >> iter 18254 (epoch  8): loss=0.06021
 2025-10-07 17:22:43,101 - INFO -marigold_trainer.py - train >> iter 18255 (epoch  8): loss=0.05996
 2025-10-07 17:22:59,092 - INFO -marigold_trainer.py - train >> iter 18256 (epoch  8): loss=0.06010
 2025-10-07 17:23:14,426 - INFO -marigold_trainer.py - train >> iter 18257 (epoch  8): loss=0.06447
 2025-10-07 17:23:31,060 - INFO -marigold_trainer.py - train >> iter 18258 (epoch  8): loss=0.06077
 2025-10-07 17:23:45,726 - INFO -marigold_trainer.py - train >> iter 18259 (epoch  8): loss=0.05383
 2025-10-07 17:24:01,035 - INFO -marigold_trainer.py - train >> iter 18260 (epoch  8): loss=0.05256
 2025-10-07 17:24:16,369 - INFO -marigold_trainer.py - train >> iter 18261 (epoch  8): loss=0.05383
 2025-10-07 17:24:32,985 - INFO -marigold_trainer.py - train >> iter 18262 (epoch  8): loss=0.05841
 2025-10-07 17:24:49,609 - INFO -marigold_trainer.py - train >> iter 18263 (epoch  8): loss=0.05608
 2025-10-07 17:25:04,931 - INFO -marigold_trainer.py - train >> iter 18264 (epoch  8): loss=0.05528
 2025-10-07 17:25:22,222 - INFO -marigold_trainer.py - train >> iter 18265 (epoch  8): loss=0.05511
 2025-10-07 17:25:37,547 - INFO -marigold_trainer.py - train >> iter 18266 (epoch  8): loss=0.06742
 2025-10-07 17:25:52,216 - INFO -marigold_trainer.py - train >> iter 18267 (epoch  8): loss=0.06234
 2025-10-07 17:26:07,515 - INFO -marigold_trainer.py - train >> iter 18268 (epoch  8): loss=0.05496
 2025-10-07 17:26:23,942 - INFO -marigold_trainer.py - train >> iter 18269 (epoch  8): loss=0.05879
 2025-10-07 17:26:39,467 - INFO -marigold_trainer.py - train >> iter 18270 (epoch  8): loss=0.06350
 2025-10-07 17:26:55,445 - INFO -marigold_trainer.py - train >> iter 18271 (epoch  8): loss=0.06539
 2025-10-07 17:27:12,087 - INFO -marigold_trainer.py - train >> iter 18272 (epoch  8): loss=0.05562
 2025-10-07 17:27:26,747 - INFO -marigold_trainer.py - train >> iter 18273 (epoch  8): loss=0.05299
 2025-10-07 17:27:42,048 - INFO -marigold_trainer.py - train >> iter 18274 (epoch  8): loss=0.05968
 2025-10-07 17:27:58,019 - INFO -marigold_trainer.py - train >> iter 18275 (epoch  8): loss=0.06496
 2025-10-07 17:28:13,340 - INFO -marigold_trainer.py - train >> iter 18276 (epoch  8): loss=0.05221
 2025-10-07 17:28:28,457 - INFO -marigold_trainer.py - train >> iter 18277 (epoch  8): loss=0.06505
 2025-10-07 17:28:45,931 - INFO -marigold_trainer.py - train >> iter 18278 (epoch  8): loss=0.05894
 2025-10-07 17:29:03,215 - INFO -marigold_trainer.py - train >> iter 18279 (epoch  8): loss=0.05941
 2025-10-07 17:29:19,192 - INFO -marigold_trainer.py - train >> iter 18280 (epoch  8): loss=0.06537
 2025-10-07 17:29:35,153 - INFO -marigold_trainer.py - train >> iter 18281 (epoch  8): loss=0.05990
 2025-10-07 17:29:51,144 - INFO -marigold_trainer.py - train >> iter 18282 (epoch  8): loss=0.05533
 2025-10-07 17:30:08,425 - INFO -marigold_trainer.py - train >> iter 18283 (epoch  8): loss=0.05644
 2025-10-07 17:30:25,164 - INFO -marigold_trainer.py - train >> iter 18284 (epoch  8): loss=0.05832
 2025-10-07 17:30:41,138 - INFO -marigold_trainer.py - train >> iter 18285 (epoch  8): loss=0.06707
 2025-10-07 17:30:58,419 - INFO -marigold_trainer.py - train >> iter 18286 (epoch  8): loss=0.06177
 2025-10-07 17:31:13,728 - INFO -marigold_trainer.py - train >> iter 18287 (epoch  8): loss=0.05795
 2025-10-07 17:31:29,044 - INFO -marigold_trainer.py - train >> iter 18288 (epoch  8): loss=0.05615
 2025-10-07 17:31:45,017 - INFO -marigold_trainer.py - train >> iter 18289 (epoch  8): loss=0.05350
 2025-10-07 17:31:59,681 - INFO -marigold_trainer.py - train >> iter 18290 (epoch  8): loss=0.05556
 2025-10-07 17:32:14,977 - INFO -marigold_trainer.py - train >> iter 18291 (epoch  8): loss=0.05253
 2025-10-07 17:32:31,604 - INFO -marigold_trainer.py - train >> iter 18292 (epoch  8): loss=0.05799
 2025-10-07 17:32:46,274 - INFO -marigold_trainer.py - train >> iter 18293 (epoch  8): loss=0.06289
 2025-10-07 17:33:02,230 - INFO -marigold_trainer.py - train >> iter 18294 (epoch  8): loss=0.06415
 2025-10-07 17:33:17,563 - INFO -marigold_trainer.py - train >> iter 18295 (epoch  8): loss=0.04627
 2025-10-07 17:33:32,889 - INFO -marigold_trainer.py - train >> iter 18296 (epoch  8): loss=0.05956
 2025-10-07 17:33:48,214 - INFO -marigold_trainer.py - train >> iter 18297 (epoch  8): loss=0.05932
 2025-10-07 17:34:04,195 - INFO -marigold_trainer.py - train >> iter 18298 (epoch  8): loss=0.05251
 2025-10-07 17:34:19,515 - INFO -marigold_trainer.py - train >> iter 18299 (epoch  8): loss=0.06263
 2025-10-07 17:34:34,844 - INFO -marigold_trainer.py - train >> iter 18300 (epoch  8): loss=0.06735
 2025-10-07 17:34:51,471 - INFO -marigold_trainer.py - train >> iter 18301 (epoch  8): loss=0.05787
 2025-10-07 17:35:06,799 - INFO -marigold_trainer.py - train >> iter 18302 (epoch  8): loss=0.05980
 2025-10-07 17:35:23,217 - INFO -marigold_trainer.py - train >> iter 18303 (epoch  8): loss=0.06103
 2025-10-07 17:35:38,734 - INFO -marigold_trainer.py - train >> iter 18304 (epoch  8): loss=0.05853
 2025-10-07 17:35:54,703 - INFO -marigold_trainer.py - train >> iter 18305 (epoch  8): loss=0.05892
 2025-10-07 17:36:10,020 - INFO -marigold_trainer.py - train >> iter 18306 (epoch  8): loss=0.05983
 2025-10-07 17:36:25,990 - INFO -marigold_trainer.py - train >> iter 18307 (epoch  8): loss=0.06102
 2025-10-07 17:36:41,961 - INFO -marigold_trainer.py - train >> iter 18308 (epoch  8): loss=0.05543
 2025-10-07 17:36:57,934 - INFO -marigold_trainer.py - train >> iter 18309 (epoch  8): loss=0.06232
 2025-10-07 17:37:13,261 - INFO -marigold_trainer.py - train >> iter 18310 (epoch  8): loss=0.05185
 2025-10-07 17:37:28,581 - INFO -marigold_trainer.py - train >> iter 18311 (epoch  8): loss=0.06509
 2025-10-07 17:37:44,358 - INFO -marigold_trainer.py - train >> iter 18312 (epoch  8): loss=0.05309
 2025-10-07 17:37:59,876 - INFO -marigold_trainer.py - train >> iter 18313 (epoch  8): loss=0.05404
 2025-10-07 17:38:14,991 - INFO -marigold_trainer.py - train >> iter 18314 (epoch  8): loss=0.05740
 2025-10-07 17:38:32,471 - INFO -marigold_trainer.py - train >> iter 18315 (epoch  8): loss=0.05899
 2025-10-07 17:38:47,147 - INFO -marigold_trainer.py - train >> iter 18316 (epoch  8): loss=0.06125
 2025-10-07 17:39:03,101 - INFO -marigold_trainer.py - train >> iter 18317 (epoch  8): loss=0.07048
 2025-10-07 17:39:19,725 - INFO -marigold_trainer.py - train >> iter 18318 (epoch  8): loss=0.05679
 2025-10-07 17:39:35,053 - INFO -marigold_trainer.py - train >> iter 18319 (epoch  8): loss=0.05365
 2025-10-07 17:39:51,004 - INFO -marigold_trainer.py - train >> iter 18320 (epoch  8): loss=0.06211
 2025-10-07 17:40:06,981 - INFO -marigold_trainer.py - train >> iter 18321 (epoch  8): loss=0.05321
 2025-10-07 17:40:22,949 - INFO -marigold_trainer.py - train >> iter 18322 (epoch  8): loss=0.04681
 2025-10-07 17:40:38,276 - INFO -marigold_trainer.py - train >> iter 18323 (epoch  8): loss=0.06541
 2025-10-07 17:40:54,904 - INFO -marigold_trainer.py - train >> iter 18324 (epoch  8): loss=0.05831
 2025-10-07 17:41:10,230 - INFO -marigold_trainer.py - train >> iter 18325 (epoch  8): loss=0.06365
 2025-10-07 17:41:24,898 - INFO -marigold_trainer.py - train >> iter 18326 (epoch  8): loss=0.05754
 2025-10-07 17:41:40,647 - INFO -marigold_trainer.py - train >> iter 18327 (epoch  8): loss=0.05775
 2025-10-07 17:41:56,160 - INFO -marigold_trainer.py - train >> iter 18328 (epoch  8): loss=0.06312
 2025-10-07 17:42:11,485 - INFO -marigold_trainer.py - train >> iter 18329 (epoch  8): loss=0.05472
 2025-10-07 17:42:26,813 - INFO -marigold_trainer.py - train >> iter 18330 (epoch  8): loss=0.05652
 2025-10-07 17:42:41,486 - INFO -marigold_trainer.py - train >> iter 18331 (epoch  8): loss=0.05906
 2025-10-07 17:42:58,757 - INFO -marigold_trainer.py - train >> iter 18332 (epoch  8): loss=0.05802
 2025-10-07 17:43:15,398 - INFO -marigold_trainer.py - train >> iter 18333 (epoch  8): loss=0.05582
 2025-10-07 17:43:30,717 - INFO -marigold_trainer.py - train >> iter 18334 (epoch  8): loss=0.05588
 2025-10-07 17:43:46,027 - INFO -marigold_trainer.py - train >> iter 18335 (epoch  8): loss=0.05913
 2025-10-07 17:44:02,658 - INFO -marigold_trainer.py - train >> iter 18336 (epoch  8): loss=0.05527
 2025-10-07 17:44:17,981 - INFO -marigold_trainer.py - train >> iter 18337 (epoch  8): loss=0.05765
 2025-10-07 17:44:33,953 - INFO -marigold_trainer.py - train >> iter 18338 (epoch  8): loss=0.06169
 2025-10-07 17:44:49,925 - INFO -marigold_trainer.py - train >> iter 18339 (epoch  8): loss=0.05440
 2025-10-07 17:45:06,549 - INFO -marigold_trainer.py - train >> iter 18340 (epoch  8): loss=0.05946
 2025-10-07 17:45:21,878 - INFO -marigold_trainer.py - train >> iter 18341 (epoch  8): loss=0.05661
 2025-10-07 17:45:37,197 - INFO -marigold_trainer.py - train >> iter 18342 (epoch  8): loss=0.06004
 2025-10-07 17:45:51,863 - INFO -marigold_trainer.py - train >> iter 18343 (epoch  8): loss=0.05624
 2025-10-07 17:46:09,132 - INFO -marigold_trainer.py - train >> iter 18344 (epoch  8): loss=0.06037
 2025-10-07 17:46:25,559 - INFO -marigold_trainer.py - train >> iter 18345 (epoch  8): loss=0.06082
 2025-10-07 17:46:42,392 - INFO -marigold_trainer.py - train >> iter 18346 (epoch  8): loss=0.05842
 2025-10-07 17:46:57,715 - INFO -marigold_trainer.py - train >> iter 18347 (epoch  8): loss=0.06143
 2025-10-07 17:47:12,365 - INFO -marigold_trainer.py - train >> iter 18348 (epoch  8): loss=0.05103
 2025-10-07 17:47:28,979 - INFO -marigold_trainer.py - train >> iter 18349 (epoch  8): loss=0.05220
 2025-10-07 17:47:43,647 - INFO -marigold_trainer.py - train >> iter 18350 (epoch  8): loss=0.06609
 2025-10-07 17:47:58,950 - INFO -marigold_trainer.py - train >> iter 18351 (epoch  8): loss=0.05804
 2025-10-07 17:48:13,620 - INFO -marigold_trainer.py - train >> iter 18352 (epoch  8): loss=0.06017
 2025-10-07 17:48:28,921 - INFO -marigold_trainer.py - train >> iter 18353 (epoch  8): loss=0.05696
 2025-10-07 17:48:43,587 - INFO -marigold_trainer.py - train >> iter 18354 (epoch  8): loss=0.05922
 2025-10-07 17:48:59,344 - INFO -marigold_trainer.py - train >> iter 18355 (epoch  8): loss=0.06753
 2025-10-07 17:49:16,843 - INFO -marigold_trainer.py - train >> iter 18356 (epoch  8): loss=0.07067
 2025-10-07 17:49:32,815 - INFO -marigold_trainer.py - train >> iter 18357 (epoch  8): loss=0.06077
 2025-10-07 17:49:51,396 - INFO -marigold_trainer.py - train >> iter 18358 (epoch  8): loss=0.05443
 2025-10-07 17:50:06,709 - INFO -marigold_trainer.py - train >> iter 18359 (epoch  8): loss=0.05317
 2025-10-07 17:50:21,832 - INFO -marigold_trainer.py - train >> iter 18360 (epoch  8): loss=0.06552
 2025-10-07 17:50:38,465 - INFO -marigold_trainer.py - train >> iter 18361 (epoch  8): loss=0.05645
 2025-10-07 17:50:53,339 - INFO -marigold_trainer.py - train >> iter 18362 (epoch  8): loss=0.05878
 2025-10-07 17:51:09,288 - INFO -marigold_trainer.py - train >> iter 18363 (epoch  8): loss=0.05671
 2025-10-07 17:51:23,949 - INFO -marigold_trainer.py - train >> iter 18364 (epoch  8): loss=0.05780
 2025-10-07 17:51:38,598 - INFO -marigold_trainer.py - train >> iter 18365 (epoch  8): loss=0.05354
 2025-10-07 17:51:53,244 - INFO -marigold_trainer.py - train >> iter 18366 (epoch  8): loss=0.06480
 2025-10-07 17:52:07,897 - INFO -marigold_trainer.py - train >> iter 18367 (epoch  8): loss=0.05442
 2025-10-07 17:52:23,848 - INFO -marigold_trainer.py - train >> iter 18368 (epoch  8): loss=0.05631
 2025-10-07 17:52:39,169 - INFO -marigold_trainer.py - train >> iter 18369 (epoch  8): loss=0.05819
 2025-10-07 17:52:55,803 - INFO -marigold_trainer.py - train >> iter 18370 (epoch  8): loss=0.05160
 2025-10-07 17:53:11,123 - INFO -marigold_trainer.py - train >> iter 18371 (epoch  8): loss=0.05826
 2025-10-07 17:53:25,794 - INFO -marigold_trainer.py - train >> iter 18372 (epoch  8): loss=0.06180
 2025-10-07 17:53:40,440 - INFO -marigold_trainer.py - train >> iter 18373 (epoch  8): loss=0.05523
 2025-10-07 17:53:56,402 - INFO -marigold_trainer.py - train >> iter 18374 (epoch  8): loss=0.06413
 2025-10-07 17:54:11,735 - INFO -marigold_trainer.py - train >> iter 18375 (epoch  8): loss=0.05920
 2025-10-07 17:54:28,369 - INFO -marigold_trainer.py - train >> iter 18376 (epoch  8): loss=0.06166
 2025-10-07 17:54:44,989 - INFO -marigold_trainer.py - train >> iter 18377 (epoch  8): loss=0.05649
 2025-10-07 17:54:59,653 - INFO -marigold_trainer.py - train >> iter 18378 (epoch  8): loss=0.05664
 2025-10-07 17:55:16,267 - INFO -marigold_trainer.py - train >> iter 18379 (epoch  8): loss=0.05647
 2025-10-07 17:55:32,244 - INFO -marigold_trainer.py - train >> iter 18380 (epoch  8): loss=0.05664
 2025-10-07 17:55:46,922 - INFO -marigold_trainer.py - train >> iter 18381 (epoch  8): loss=0.06379
 2025-10-07 17:56:04,181 - INFO -marigold_trainer.py - train >> iter 18382 (epoch  8): loss=0.06084
 2025-10-07 17:56:19,504 - INFO -marigold_trainer.py - train >> iter 18383 (epoch  8): loss=0.06029
 2025-10-07 17:56:35,484 - INFO -marigold_trainer.py - train >> iter 18384 (epoch  8): loss=0.05223
 2025-10-07 17:56:50,907 - INFO -marigold_trainer.py - train >> iter 18385 (epoch  8): loss=0.05531
 2025-10-07 17:57:06,877 - INFO -marigold_trainer.py - train >> iter 18386 (epoch  8): loss=0.05687
 2025-10-07 17:57:22,852 - INFO -marigold_trainer.py - train >> iter 18387 (epoch  8): loss=0.06078
 2025-10-07 17:57:38,835 - INFO -marigold_trainer.py - train >> iter 18388 (epoch  8): loss=0.06157
 2025-10-07 17:57:54,815 - INFO -marigold_trainer.py - train >> iter 18389 (epoch  8): loss=0.06617
 2025-10-07 17:58:10,141 - INFO -marigold_trainer.py - train >> iter 18390 (epoch  8): loss=0.07517
 2025-10-07 17:58:26,119 - INFO -marigold_trainer.py - train >> iter 18391 (epoch  8): loss=0.05903
 2025-10-07 17:58:44,695 - INFO -marigold_trainer.py - train >> iter 18392 (epoch  8): loss=0.06256
 2025-10-07 17:59:00,665 - INFO -marigold_trainer.py - train >> iter 18393 (epoch  8): loss=0.05538
 2025-10-07 17:59:15,319 - INFO -marigold_trainer.py - train >> iter 18394 (epoch  8): loss=0.05959
 2025-10-07 17:59:31,276 - INFO -marigold_trainer.py - train >> iter 18395 (epoch  8): loss=0.05536
 2025-10-07 17:59:45,947 - INFO -marigold_trainer.py - train >> iter 18396 (epoch  8): loss=0.05675
 2025-10-07 18:00:01,250 - INFO -marigold_trainer.py - train >> iter 18397 (epoch  8): loss=0.06031
 2025-10-07 18:00:19,200 - INFO -marigold_trainer.py - train >> iter 18398 (epoch  8): loss=0.05944
 2025-10-07 18:00:33,864 - INFO -marigold_trainer.py - train >> iter 18399 (epoch  8): loss=0.05705
 2025-10-07 18:00:49,161 - INFO -marigold_trainer.py - train >> iter 18400 (epoch  8): loss=0.05803
 2025-10-07 18:01:04,491 - INFO -marigold_trainer.py - train >> iter 18401 (epoch  8): loss=0.06192
 2025-10-07 18:01:20,473 - INFO -marigold_trainer.py - train >> iter 18402 (epoch  8): loss=0.05610
 2025-10-07 18:01:37,098 - INFO -marigold_trainer.py - train >> iter 18403 (epoch  8): loss=0.06574
 2025-10-07 18:01:53,075 - INFO -marigold_trainer.py - train >> iter 18404 (epoch  8): loss=0.06065
 2025-10-07 18:02:07,742 - INFO -marigold_trainer.py - train >> iter 18405 (epoch  8): loss=0.05778
 2025-10-07 18:02:24,350 - INFO -marigold_trainer.py - train >> iter 18406 (epoch  8): loss=0.04919
 2025-10-07 18:02:39,023 - INFO -marigold_trainer.py - train >> iter 18407 (epoch  8): loss=0.05607
 2025-10-07 18:02:54,326 - INFO -marigold_trainer.py - train >> iter 18408 (epoch  8): loss=0.06852
 2025-10-07 18:03:09,645 - INFO -marigold_trainer.py - train >> iter 18409 (epoch  8): loss=0.06107
 2025-10-07 18:03:25,613 - INFO -marigold_trainer.py - train >> iter 18410 (epoch  8): loss=0.05401
 2025-10-07 18:03:40,933 - INFO -marigold_trainer.py - train >> iter 18411 (epoch  8): loss=0.05158
 2025-10-07 18:03:56,251 - INFO -marigold_trainer.py - train >> iter 18412 (epoch  8): loss=0.05715
 2025-10-07 18:04:11,559 - INFO -marigold_trainer.py - train >> iter 18413 (epoch  8): loss=0.05537
 2025-10-07 18:04:28,190 - INFO -marigold_trainer.py - train >> iter 18414 (epoch  8): loss=0.05339
 2025-10-07 18:04:43,530 - INFO -marigold_trainer.py - train >> iter 18415 (epoch  8): loss=0.06330
 2025-10-07 18:04:59,124 - INFO -marigold_trainer.py - train >> iter 18416 (epoch  8): loss=0.05005
 2025-10-07 18:05:16,212 - INFO -marigold_trainer.py - train >> iter 18417 (epoch  8): loss=0.06184
 2025-10-07 18:05:32,443 - INFO -marigold_trainer.py - train >> iter 18418 (epoch  8): loss=0.06706
 2025-10-07 18:05:47,399 - INFO -marigold_trainer.py - train >> iter 18419 (epoch  8): loss=0.04981
 2025-10-07 18:06:04,070 - INFO -marigold_trainer.py - train >> iter 18420 (epoch  8): loss=0.06357
 2025-10-07 18:06:18,750 - INFO -marigold_trainer.py - train >> iter 18421 (epoch  8): loss=0.05507
 2025-10-07 18:06:33,409 - INFO -marigold_trainer.py - train >> iter 18422 (epoch  8): loss=0.06448
 2025-10-07 18:06:49,374 - INFO -marigold_trainer.py - train >> iter 18423 (epoch  8): loss=0.05939
 2025-10-07 18:07:06,006 - INFO -marigold_trainer.py - train >> iter 18424 (epoch  8): loss=0.06545
 2025-10-07 18:07:21,980 - INFO -marigold_trainer.py - train >> iter 18425 (epoch  8): loss=0.05294
 2025-10-07 18:07:38,620 - INFO -marigold_trainer.py - train >> iter 18426 (epoch  8): loss=0.06817
 2025-10-07 18:07:57,230 - INFO -marigold_trainer.py - train >> iter 18427 (epoch  8): loss=0.05589
 2025-10-07 18:08:11,910 - INFO -marigold_trainer.py - train >> iter 18428 (epoch  8): loss=0.05904
 2025-10-07 18:08:27,019 - INFO -marigold_trainer.py - train >> iter 18429 (epoch  8): loss=0.06845
 2025-10-07 18:08:42,543 - INFO -marigold_trainer.py - train >> iter 18430 (epoch  8): loss=0.06066
 2025-10-07 18:08:58,520 - INFO -marigold_trainer.py - train >> iter 18431 (epoch  8): loss=0.05713
 2025-10-07 18:09:14,294 - INFO -marigold_trainer.py - train >> iter 18432 (epoch  8): loss=0.05758
 2025-10-07 18:09:31,572 - INFO -marigold_trainer.py - train >> iter 18433 (epoch  8): loss=0.07028
 2025-10-07 18:09:47,106 - INFO -marigold_trainer.py - train >> iter 18434 (epoch  8): loss=0.06047
 2025-10-07 18:10:01,782 - INFO -marigold_trainer.py - train >> iter 18435 (epoch  8): loss=0.05336
 2025-10-07 18:10:17,092 - INFO -marigold_trainer.py - train >> iter 18436 (epoch  8): loss=0.06338
 2025-10-07 18:10:33,725 - INFO -marigold_trainer.py - train >> iter 18437 (epoch  8): loss=0.05875
 2025-10-07 18:10:48,403 - INFO -marigold_trainer.py - train >> iter 18438 (epoch  8): loss=0.05715
 2025-10-07 18:11:03,710 - INFO -marigold_trainer.py - train >> iter 18439 (epoch  8): loss=0.05929
 2025-10-07 18:11:19,697 - INFO -marigold_trainer.py - train >> iter 18440 (epoch  8): loss=0.06191
 2025-10-07 18:11:35,686 - INFO -marigold_trainer.py - train >> iter 18441 (epoch  8): loss=0.05397
 2025-10-07 18:11:52,979 - INFO -marigold_trainer.py - train >> iter 18442 (epoch  8): loss=0.05360
 2025-10-07 18:12:07,652 - INFO -marigold_trainer.py - train >> iter 18443 (epoch  8): loss=0.05991
 2025-10-07 18:12:22,960 - INFO -marigold_trainer.py - train >> iter 18444 (epoch  8): loss=0.05115
 2025-10-07 18:12:38,288 - INFO -marigold_trainer.py - train >> iter 18445 (epoch  8): loss=0.05889
 2025-10-07 18:12:53,614 - INFO -marigold_trainer.py - train >> iter 18446 (epoch  8): loss=0.05369
 2025-10-07 18:13:10,249 - INFO -marigold_trainer.py - train >> iter 18447 (epoch  8): loss=0.06449
 2025-10-07 18:13:26,880 - INFO -marigold_trainer.py - train >> iter 18448 (epoch  8): loss=0.06578
 2025-10-07 18:13:44,170 - INFO -marigold_trainer.py - train >> iter 18449 (epoch  8): loss=0.05197
 2025-10-07 18:14:00,157 - INFO -marigold_trainer.py - train >> iter 18450 (epoch  8): loss=0.05478
 2025-10-07 18:14:16,144 - INFO -marigold_trainer.py - train >> iter 18451 (epoch  8): loss=0.05743
 2025-10-07 18:14:31,927 - INFO -marigold_trainer.py - train >> iter 18452 (epoch  8): loss=0.05094
 2025-10-07 18:14:48,118 - INFO -marigold_trainer.py - train >> iter 18453 (epoch  8): loss=0.06121
 2025-10-07 18:15:04,754 - INFO -marigold_trainer.py - train >> iter 18454 (epoch  8): loss=0.06365
 2025-10-07 18:15:20,085 - INFO -marigold_trainer.py - train >> iter 18455 (epoch  8): loss=0.05210
 2025-10-07 18:15:35,418 - INFO -marigold_trainer.py - train >> iter 18456 (epoch  8): loss=0.05026
 2025-10-07 18:15:50,739 - INFO -marigold_trainer.py - train >> iter 18457 (epoch  8): loss=0.05467
 2025-10-07 18:16:06,713 - INFO -marigold_trainer.py - train >> iter 18458 (epoch  8): loss=0.05851
 2025-10-07 18:16:22,504 - INFO -marigold_trainer.py - train >> iter 18459 (epoch  8): loss=0.05806
 2025-10-07 18:16:38,495 - INFO -marigold_trainer.py - train >> iter 18460 (epoch  8): loss=0.06520
 2025-10-07 18:16:55,327 - INFO -marigold_trainer.py - train >> iter 18461 (epoch  8): loss=0.06314
 2025-10-07 18:17:11,311 - INFO -marigold_trainer.py - train >> iter 18462 (epoch  8): loss=0.05309
 2025-10-07 18:17:27,938 - INFO -marigold_trainer.py - train >> iter 18463 (epoch  8): loss=0.05533
 2025-10-07 18:17:43,932 - INFO -marigold_trainer.py - train >> iter 18464 (epoch  8): loss=0.05839
 2025-10-07 18:17:59,265 - INFO -marigold_trainer.py - train >> iter 18465 (epoch  8): loss=0.05509
 2025-10-07 18:18:13,936 - INFO -marigold_trainer.py - train >> iter 18466 (epoch  8): loss=0.06648
 2025-10-07 18:18:29,245 - INFO -marigold_trainer.py - train >> iter 18467 (epoch  8): loss=0.06417
 2025-10-07 18:18:43,919 - INFO -marigold_trainer.py - train >> iter 18468 (epoch  8): loss=0.05896
 2025-10-07 18:18:58,574 - INFO -marigold_trainer.py - train >> iter 18469 (epoch  8): loss=0.05995
 2025-10-07 18:19:13,885 - INFO -marigold_trainer.py - train >> iter 18470 (epoch  8): loss=0.05281
 2025-10-07 18:19:29,198 - INFO -marigold_trainer.py - train >> iter 18471 (epoch  8): loss=0.06248
 2025-10-07 18:19:45,175 - INFO -marigold_trainer.py - train >> iter 18472 (epoch  8): loss=0.06783
 2025-10-07 18:20:01,156 - INFO -marigold_trainer.py - train >> iter 18473 (epoch  8): loss=0.05851
 2025-10-07 18:20:16,284 - INFO -marigold_trainer.py - train >> iter 18474 (epoch  8): loss=0.06241
 2025-10-07 18:20:32,470 - INFO -marigold_trainer.py - train >> iter 18475 (epoch  8): loss=0.06334
 2025-10-07 18:20:48,457 - INFO -marigold_trainer.py - train >> iter 18476 (epoch  8): loss=0.06934
 2025-10-07 18:21:03,940 - INFO -marigold_trainer.py - train >> iter 18477 (epoch  8): loss=0.05784
 2025-10-07 18:21:19,925 - INFO -marigold_trainer.py - train >> iter 18478 (epoch  8): loss=0.05417
 2025-10-07 18:21:34,597 - INFO -marigold_trainer.py - train >> iter 18479 (epoch  8): loss=0.05793
 2025-10-07 18:21:49,238 - INFO -marigold_trainer.py - train >> iter 18480 (epoch  8): loss=0.06320
 2025-10-07 18:22:05,847 - INFO -marigold_trainer.py - train >> iter 18481 (epoch  8): loss=0.06471
 2025-10-07 18:22:21,820 - INFO -marigold_trainer.py - train >> iter 18482 (epoch  8): loss=0.06016
 2025-10-07 18:22:37,149 - INFO -marigold_trainer.py - train >> iter 18483 (epoch  8): loss=0.06287
 2025-10-07 18:22:52,467 - INFO -marigold_trainer.py - train >> iter 18484 (epoch  8): loss=0.05761
 2025-10-07 18:23:08,894 - INFO -marigold_trainer.py - train >> iter 18485 (epoch  8): loss=0.05783
 2025-10-07 18:23:24,518 - INFO -marigold_trainer.py - train >> iter 18486 (epoch  8): loss=0.05819
 2025-10-07 18:23:39,819 - INFO -marigold_trainer.py - train >> iter 18487 (epoch  8): loss=0.05669
 2025-10-07 18:23:55,808 - INFO -marigold_trainer.py - train >> iter 18488 (epoch  8): loss=0.05596
 2025-10-07 18:24:10,475 - INFO -marigold_trainer.py - train >> iter 18489 (epoch  8): loss=0.05917
 2025-10-07 18:24:25,783 - INFO -marigold_trainer.py - train >> iter 18490 (epoch  8): loss=0.06358
 2025-10-07 18:24:43,076 - INFO -marigold_trainer.py - train >> iter 18491 (epoch  8): loss=0.06051
 2025-10-07 18:24:59,058 - INFO -marigold_trainer.py - train >> iter 18492 (epoch  8): loss=0.05578
 2025-10-07 18:25:13,735 - INFO -marigold_trainer.py - train >> iter 18493 (epoch  8): loss=0.05646
 2025-10-07 18:25:29,041 - INFO -marigold_trainer.py - train >> iter 18494 (epoch  8): loss=0.05387
 2025-10-07 18:25:45,673 - INFO -marigold_trainer.py - train >> iter 18495 (epoch  8): loss=0.05508
 2025-10-07 18:26:00,346 - INFO -marigold_trainer.py - train >> iter 18496 (epoch  8): loss=0.06377
 2025-10-07 18:26:16,319 - INFO -marigold_trainer.py - train >> iter 18497 (epoch  8): loss=0.05977
 2025-10-07 18:26:32,297 - INFO -marigold_trainer.py - train >> iter 18498 (epoch  8): loss=0.05659
 2025-10-07 18:26:48,924 - INFO -marigold_trainer.py - train >> iter 18499 (epoch  8): loss=0.06313
 2025-10-07 18:27:04,237 - INFO -marigold_trainer.py - train >> iter 18500 (epoch  8): loss=0.05537
 2025-10-07 18:27:04,238 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: output/train_marigold/checkpoint/latest
 2025-10-07 18:27:04,238 - DEBUG -marigold_trainer.py - save_checkpoint >> Old checkpoint is backed up at: output/train_marigold/checkpoint/_old_latest
 2025-10-07 18:27:07,575 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: output/train_marigold/checkpoint/latest/unet
 2025-10-07 18:27:13,820 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: output/train_marigold/checkpoint/latest/trainer.ckpt
 2025-10-07 18:27:14,440 - DEBUG -marigold_trainer.py - save_checkpoint >> Old checkpoint backup is removed.
 2025-10-07 18:27:31,432 - INFO -marigold_trainer.py - train >> iter 18501 (epoch  8): loss=0.05569
 2025-10-07 18:27:47,407 - INFO -marigold_trainer.py - train >> iter 18502 (epoch  8): loss=0.05684
 2025-10-07 18:28:04,050 - INFO -marigold_trainer.py - train >> iter 18503 (epoch  8): loss=0.05728
 2025-10-07 18:28:19,374 - INFO -marigold_trainer.py - train >> iter 18504 (epoch  8): loss=0.06691
 2025-10-07 18:28:34,692 - INFO -marigold_trainer.py - train >> iter 18505 (epoch  8): loss=0.05349
 2025-10-07 18:28:49,360 - INFO -marigold_trainer.py - train >> iter 18506 (epoch  8): loss=0.05452
 2025-10-07 18:29:04,008 - INFO -marigold_trainer.py - train >> iter 18507 (epoch  8): loss=0.05406
 2025-10-07 18:29:18,654 - INFO -marigold_trainer.py - train >> iter 18508 (epoch  8): loss=0.06279
 2025-10-07 18:29:19,134 - DEBUG -marigold_trainer.py - train >> epoch: 9
 2025-10-07 18:29:34,388 - INFO -marigold_trainer.py - train >> iter 18509 (epoch  9): loss=0.05907
 2025-10-07 18:29:49,714 - INFO -marigold_trainer.py - train >> iter 18510 (epoch  9): loss=0.06383
 2025-10-07 18:30:05,033 - INFO -marigold_trainer.py - train >> iter 18511 (epoch  9): loss=0.06297
 2025-10-07 18:30:21,010 - INFO -marigold_trainer.py - train >> iter 18512 (epoch  9): loss=0.05646
 2025-10-07 18:30:38,750 - INFO -marigold_trainer.py - train >> iter 18513 (epoch  9): loss=0.06528
 2025-10-07 18:30:54,932 - INFO -marigold_trainer.py - train >> iter 18514 (epoch  9): loss=0.05864
 2025-10-07 18:31:11,362 - INFO -marigold_trainer.py - train >> iter 18515 (epoch  9): loss=0.06800
 2025-10-07 18:31:26,889 - INFO -marigold_trainer.py - train >> iter 18516 (epoch  9): loss=0.05808
 2025-10-07 18:31:42,212 - INFO -marigold_trainer.py - train >> iter 18517 (epoch  9): loss=0.05610
 2025-10-07 18:31:57,532 - INFO -marigold_trainer.py - train >> iter 18518 (epoch  9): loss=0.06774
 2025-10-07 18:32:13,503 - INFO -marigold_trainer.py - train >> iter 18519 (epoch  9): loss=0.05933
 2025-10-07 18:32:28,174 - INFO -marigold_trainer.py - train >> iter 18520 (epoch  9): loss=0.06337
 2025-10-07 18:32:43,477 - INFO -marigold_trainer.py - train >> iter 18521 (epoch  9): loss=0.06125
 2025-10-07 18:33:00,111 - INFO -marigold_trainer.py - train >> iter 18522 (epoch  9): loss=0.05506
 2025-10-07 18:33:16,092 - INFO -marigold_trainer.py - train >> iter 18523 (epoch  9): loss=0.06105
 2025-10-07 18:33:32,737 - INFO -marigold_trainer.py - train >> iter 18524 (epoch  9): loss=0.05535
 2025-10-07 18:33:48,517 - INFO -marigold_trainer.py - train >> iter 18525 (epoch  9): loss=0.04725
 2025-10-07 18:34:04,044 - INFO -marigold_trainer.py - train >> iter 18526 (epoch  9): loss=0.06795
 2025-10-07 18:34:20,000 - INFO -marigold_trainer.py - train >> iter 18527 (epoch  9): loss=0.05450
 2025-10-07 18:34:35,968 - INFO -marigold_trainer.py - train >> iter 18528 (epoch  9): loss=0.05797
 2025-10-07 18:34:52,600 - INFO -marigold_trainer.py - train >> iter 18529 (epoch  9): loss=0.06498
 2025-10-07 18:35:07,912 - INFO -marigold_trainer.py - train >> iter 18530 (epoch  9): loss=0.05774
 2025-10-07 18:35:23,880 - INFO -marigold_trainer.py - train >> iter 18531 (epoch  9): loss=0.05354
 2025-10-07 18:35:39,193 - INFO -marigold_trainer.py - train >> iter 18532 (epoch  9): loss=0.05753
 2025-10-07 18:35:55,171 - INFO -marigold_trainer.py - train >> iter 18533 (epoch  9): loss=0.05785
 2025-10-07 18:36:10,496 - INFO -marigold_trainer.py - train >> iter 18534 (epoch  9): loss=0.06499
 2025-10-07 18:36:25,828 - INFO -marigold_trainer.py - train >> iter 18535 (epoch  9): loss=0.05981
 2025-10-07 18:36:41,602 - INFO -marigold_trainer.py - train >> iter 18536 (epoch  9): loss=0.06592
 2025-10-07 18:36:57,783 - INFO -marigold_trainer.py - train >> iter 18537 (epoch  9): loss=0.06416
 2025-10-07 18:37:14,418 - INFO -marigold_trainer.py - train >> iter 18538 (epoch  9): loss=0.05835
 2025-10-07 18:37:30,401 - INFO -marigold_trainer.py - train >> iter 18539 (epoch  9): loss=0.05690
 2025-10-07 18:37:45,068 - INFO -marigold_trainer.py - train >> iter 18540 (epoch  9): loss=0.05725
 2025-10-07 18:38:00,371 - INFO -marigold_trainer.py - train >> iter 18541 (epoch  9): loss=0.05341
 2025-10-07 18:38:16,979 - INFO -marigold_trainer.py - train >> iter 18542 (epoch  9): loss=0.05997
 2025-10-07 18:38:34,916 - INFO -marigold_trainer.py - train >> iter 18543 (epoch  9): loss=0.05960
 2025-10-07 18:38:50,226 - INFO -marigold_trainer.py - train >> iter 18544 (epoch  9): loss=0.05802
 2025-10-07 18:39:05,339 - INFO -marigold_trainer.py - train >> iter 18545 (epoch  9): loss=0.05258
 2025-10-07 18:39:20,857 - INFO -marigold_trainer.py - train >> iter 18546 (epoch  9): loss=0.05615
 2025-10-07 18:39:35,525 - INFO -marigold_trainer.py - train >> iter 18547 (epoch  9): loss=0.06436
 2025-10-07 18:39:51,477 - INFO -marigold_trainer.py - train >> iter 18548 (epoch  9): loss=0.05449
 2025-10-07 18:40:06,797 - INFO -marigold_trainer.py - train >> iter 18549 (epoch  9): loss=0.05915
 2025-10-07 18:40:23,421 - INFO -marigold_trainer.py - train >> iter 18550 (epoch  9): loss=0.06078
 2025-10-07 18:40:39,855 - INFO -marigold_trainer.py - train >> iter 18551 (epoch  9): loss=0.05295
 2025-10-07 18:40:55,378 - INFO -marigold_trainer.py - train >> iter 18552 (epoch  9): loss=0.05454
 2025-10-07 18:41:10,698 - INFO -marigold_trainer.py - train >> iter 18553 (epoch  9): loss=0.06044
 2025-10-07 18:41:25,350 - INFO -marigold_trainer.py - train >> iter 18554 (epoch  9): loss=0.05738
 2025-10-07 18:41:41,958 - INFO -marigold_trainer.py - train >> iter 18555 (epoch  9): loss=0.06345
 2025-10-07 18:41:57,289 - INFO -marigold_trainer.py - train >> iter 18556 (epoch  9): loss=0.05915
 2025-10-07 18:42:13,921 - INFO -marigold_trainer.py - train >> iter 18557 (epoch  9): loss=0.05794
 2025-10-07 18:42:29,897 - INFO -marigold_trainer.py - train >> iter 18558 (epoch  9): loss=0.05500
 2025-10-07 18:42:45,869 - INFO -marigold_trainer.py - train >> iter 18559 (epoch  9): loss=0.05347
 2025-10-07 18:43:01,638 - INFO -marigold_trainer.py - train >> iter 18560 (epoch  9): loss=0.06327
 2025-10-07 18:43:16,509 - INFO -marigold_trainer.py - train >> iter 18561 (epoch  9): loss=0.05049
 2025-10-07 18:43:31,809 - INFO -marigold_trainer.py - train >> iter 18562 (epoch  9): loss=0.05558
 2025-10-07 18:43:46,478 - INFO -marigold_trainer.py - train >> iter 18563 (epoch  9): loss=0.06213
 2025-10-07 18:44:01,126 - INFO -marigold_trainer.py - train >> iter 18564 (epoch  9): loss=0.04994
 2025-10-07 18:44:16,430 - INFO -marigold_trainer.py - train >> iter 18565 (epoch  9): loss=0.05039
 2025-10-07 18:44:31,757 - INFO -marigold_trainer.py - train >> iter 18566 (epoch  9): loss=0.06160
 2025-10-07 18:44:48,396 - INFO -marigold_trainer.py - train >> iter 18567 (epoch  9): loss=0.05685
 2025-10-07 18:45:03,714 - INFO -marigold_trainer.py - train >> iter 18568 (epoch  9): loss=0.06692
 2025-10-07 18:45:19,673 - INFO -marigold_trainer.py - train >> iter 18569 (epoch  9): loss=0.05335
 2025-10-07 18:45:36,307 - INFO -marigold_trainer.py - train >> iter 18570 (epoch  9): loss=0.05582
 2025-10-07 18:45:51,627 - INFO -marigold_trainer.py - train >> iter 18571 (epoch  9): loss=0.06108
 2025-10-07 18:46:06,283 - INFO -marigold_trainer.py - train >> iter 18572 (epoch  9): loss=0.06500
 2025-10-07 18:46:22,895 - INFO -marigold_trainer.py - train >> iter 18573 (epoch  9): loss=0.05995
 2025-10-07 18:46:38,220 - INFO -marigold_trainer.py - train >> iter 18574 (epoch  9): loss=0.06587
 2025-10-07 18:46:53,538 - INFO -marigold_trainer.py - train >> iter 18575 (epoch  9): loss=0.05787
 2025-10-07 18:47:08,199 - INFO -marigold_trainer.py - train >> iter 18576 (epoch  9): loss=0.05166
 2025-10-07 18:47:24,807 - INFO -marigold_trainer.py - train >> iter 18577 (epoch  9): loss=0.05983
 2025-10-07 18:47:39,473 - INFO -marigold_trainer.py - train >> iter 18578 (epoch  9): loss=0.05274
 2025-10-07 18:47:55,561 - INFO -marigold_trainer.py - train >> iter 18579 (epoch  9): loss=0.05696
 2025-10-07 18:48:10,891 - INFO -marigold_trainer.py - train >> iter 18580 (epoch  9): loss=0.05517
 2025-10-07 18:48:28,185 - INFO -marigold_trainer.py - train >> iter 18581 (epoch  9): loss=0.05362
 2025-10-07 18:48:43,310 - INFO -marigold_trainer.py - train >> iter 18582 (epoch  9): loss=0.05865
 2025-10-07 18:48:59,485 - INFO -marigold_trainer.py - train >> iter 18583 (epoch  9): loss=0.05627
 2025-10-07 18:49:16,114 - INFO -marigold_trainer.py - train >> iter 18584 (epoch  9): loss=0.06531
 2025-10-07 18:49:31,890 - INFO -marigold_trainer.py - train >> iter 18585 (epoch  9): loss=0.06940
 2025-10-07 18:49:46,751 - INFO -marigold_trainer.py - train >> iter 18586 (epoch  9): loss=0.04935
 2025-10-07 18:50:02,050 - INFO -marigold_trainer.py - train >> iter 18587 (epoch  9): loss=0.06093
 2025-10-07 18:50:17,366 - INFO -marigold_trainer.py - train >> iter 18588 (epoch  9): loss=0.05654
 2025-10-07 18:50:32,699 - INFO -marigold_trainer.py - train >> iter 18589 (epoch  9): loss=0.05426
 2025-10-07 18:50:48,002 - INFO -marigold_trainer.py - train >> iter 18590 (epoch  9): loss=0.05858
 2025-10-07 18:51:02,677 - INFO -marigold_trainer.py - train >> iter 18591 (epoch  9): loss=0.06783
 2025-10-07 18:51:17,983 - INFO -marigold_trainer.py - train >> iter 18592 (epoch  9): loss=0.05352
 2025-10-07 18:51:33,971 - INFO -marigold_trainer.py - train >> iter 18593 (epoch  9): loss=0.06043
 2025-10-07 18:51:49,941 - INFO -marigold_trainer.py - train >> iter 18594 (epoch  9): loss=0.05103
 2025-10-07 18:52:05,262 - INFO -marigold_trainer.py - train >> iter 18595 (epoch  9): loss=0.05899
 2025-10-07 18:52:21,247 - INFO -marigold_trainer.py - train >> iter 18596 (epoch  9): loss=0.06597
 2025-10-07 18:52:36,369 - INFO -marigold_trainer.py - train >> iter 18597 (epoch  9): loss=0.05469
 2025-10-07 18:52:51,888 - INFO -marigold_trainer.py - train >> iter 18598 (epoch  9): loss=0.06077
 2025-10-07 18:53:07,865 - INFO -marigold_trainer.py - train >> iter 18599 (epoch  9): loss=0.06572
 2025-10-07 18:53:24,494 - INFO -marigold_trainer.py - train >> iter 18600 (epoch  9): loss=0.06475
 2025-10-07 18:53:39,166 - INFO -marigold_trainer.py - train >> iter 18601 (epoch  9): loss=0.06145
 2025-10-07 18:53:55,769 - INFO -marigold_trainer.py - train >> iter 18602 (epoch  9): loss=0.05857
 2025-10-07 18:54:11,086 - INFO -marigold_trainer.py - train >> iter 18603 (epoch  9): loss=0.05446
 2025-10-07 18:54:27,068 - INFO -marigold_trainer.py - train >> iter 18604 (epoch  9): loss=0.05722
 2025-10-07 18:54:43,704 - INFO -marigold_trainer.py - train >> iter 18605 (epoch  9): loss=0.05885
 2025-10-07 18:54:59,483 - INFO -marigold_trainer.py - train >> iter 18606 (epoch  9): loss=0.06915
 2025-10-07 18:55:14,359 - INFO -marigold_trainer.py - train >> iter 18607 (epoch  9): loss=0.05279
 2025-10-07 18:55:29,654 - INFO -marigold_trainer.py - train >> iter 18608 (epoch  9): loss=0.05608
 2025-10-07 18:55:44,327 - INFO -marigold_trainer.py - train >> iter 18609 (epoch  9): loss=0.06121
 2025-10-07 18:56:02,039 - INFO -marigold_trainer.py - train >> iter 18610 (epoch  9): loss=0.05854
 2025-10-07 18:56:16,914 - INFO -marigold_trainer.py - train >> iter 18611 (epoch  9): loss=0.05087
 2025-10-07 18:56:32,210 - INFO -marigold_trainer.py - train >> iter 18612 (epoch  9): loss=0.05552
 2025-10-07 18:56:47,987 - INFO -marigold_trainer.py - train >> iter 18613 (epoch  9): loss=0.04894
 2025-10-07 18:57:03,514 - INFO -marigold_trainer.py - train >> iter 18614 (epoch  9): loss=0.06045
 2025-10-07 18:57:19,488 - INFO -marigold_trainer.py - train >> iter 18615 (epoch  9): loss=0.05668
 2025-10-07 18:57:36,758 - INFO -marigold_trainer.py - train >> iter 18616 (epoch  9): loss=0.05940
 2025-10-07 18:57:52,085 - INFO -marigold_trainer.py - train >> iter 18617 (epoch  9): loss=0.05573
 2025-10-07 18:58:07,388 - INFO -marigold_trainer.py - train >> iter 18618 (epoch  9): loss=0.05592
 2025-10-07 18:58:23,163 - INFO -marigold_trainer.py - train >> iter 18619 (epoch  9): loss=0.05526
 2025-10-07 18:58:38,026 - INFO -marigold_trainer.py - train >> iter 18620 (epoch  9): loss=0.05173
 2025-10-07 18:58:53,776 - INFO -marigold_trainer.py - train >> iter 18621 (epoch  9): loss=0.06015
 2025-10-07 18:59:09,960 - INFO -marigold_trainer.py - train >> iter 18622 (epoch  9): loss=0.05651
 2025-10-07 18:59:27,891 - INFO -marigold_trainer.py - train >> iter 18623 (epoch  9): loss=0.05612
 2025-10-07 18:59:44,519 - INFO -marigold_trainer.py - train >> iter 18624 (epoch  9): loss=0.06595
 2025-10-07 18:59:59,842 - INFO -marigold_trainer.py - train >> iter 18625 (epoch  9): loss=0.05830
 2025-10-07 19:00:14,500 - INFO -marigold_trainer.py - train >> iter 18626 (epoch  9): loss=0.05573
 2025-10-07 19:00:29,148 - INFO -marigold_trainer.py - train >> iter 18627 (epoch  9): loss=0.05927
 2025-10-07 19:00:44,248 - INFO -marigold_trainer.py - train >> iter 18628 (epoch  9): loss=0.05822
 2025-10-07 19:01:02,399 - INFO -marigold_trainer.py - train >> iter 18629 (epoch  9): loss=0.05932
 2025-10-07 19:01:19,038 - INFO -marigold_trainer.py - train >> iter 18630 (epoch  9): loss=0.06015
 2025-10-07 19:01:34,363 - INFO -marigold_trainer.py - train >> iter 18631 (epoch  9): loss=0.05735
 2025-10-07 19:01:49,695 - INFO -marigold_trainer.py - train >> iter 18632 (epoch  9): loss=0.04828
 2025-10-07 19:02:05,673 - INFO -marigold_trainer.py - train >> iter 18633 (epoch  9): loss=0.05550
 2025-10-07 19:02:22,951 - INFO -marigold_trainer.py - train >> iter 18634 (epoch  9): loss=0.06761
 2025-10-07 19:02:39,585 - INFO -marigold_trainer.py - train >> iter 18635 (epoch  9): loss=0.05831
 2025-10-07 19:02:56,211 - INFO -marigold_trainer.py - train >> iter 18636 (epoch  9): loss=0.05839
 2025-10-07 19:03:10,873 - INFO -marigold_trainer.py - train >> iter 18637 (epoch  9): loss=0.05228
 2025-10-07 19:03:28,133 - INFO -marigold_trainer.py - train >> iter 18638 (epoch  9): loss=0.05232
 2025-10-07 19:03:42,799 - INFO -marigold_trainer.py - train >> iter 18639 (epoch  9): loss=0.05505
 2025-10-07 19:03:58,101 - INFO -marigold_trainer.py - train >> iter 18640 (epoch  9): loss=0.05826
 2025-10-07 19:04:13,425 - INFO -marigold_trainer.py - train >> iter 18641 (epoch  9): loss=0.06605
 2025-10-07 19:04:28,085 - INFO -marigold_trainer.py - train >> iter 18642 (epoch  9): loss=0.04671
 2025-10-07 19:04:44,039 - INFO -marigold_trainer.py - train >> iter 18643 (epoch  9): loss=0.05775
 2025-10-07 19:05:00,670 - INFO -marigold_trainer.py - train >> iter 18644 (epoch  9): loss=0.06121
 2025-10-07 19:05:15,993 - INFO -marigold_trainer.py - train >> iter 18645 (epoch  9): loss=0.05794
 2025-10-07 19:05:32,627 - INFO -marigold_trainer.py - train >> iter 18646 (epoch  9): loss=0.06058
 2025-10-07 19:05:47,303 - INFO -marigold_trainer.py - train >> iter 18647 (epoch  9): loss=0.06103
 2025-10-07 19:06:01,954 - INFO -marigold_trainer.py - train >> iter 18648 (epoch  9): loss=0.06451
 2025-10-07 19:06:17,910 - INFO -marigold_trainer.py - train >> iter 18649 (epoch  9): loss=0.06149
 2025-10-07 19:06:33,897 - INFO -marigold_trainer.py - train >> iter 18650 (epoch  9): loss=0.05437
 2025-10-07 19:06:48,561 - INFO -marigold_trainer.py - train >> iter 18651 (epoch  9): loss=0.07050
 2025-10-07 19:07:04,517 - INFO -marigold_trainer.py - train >> iter 18652 (epoch  9): loss=0.05971
 2025-10-07 19:07:19,186 - INFO -marigold_trainer.py - train >> iter 18653 (epoch  9): loss=0.05525
 2025-10-07 19:07:34,488 - INFO -marigold_trainer.py - train >> iter 18654 (epoch  9): loss=0.06022
 2025-10-07 19:07:50,472 - INFO -marigold_trainer.py - train >> iter 18655 (epoch  9): loss=0.05530
 2025-10-07 19:08:06,909 - INFO -marigold_trainer.py - train >> iter 18656 (epoch  9): loss=0.06300
 2025-10-07 19:08:22,440 - INFO -marigold_trainer.py - train >> iter 18657 (epoch  9): loss=0.04835
 2025-10-07 19:08:37,110 - INFO -marigold_trainer.py - train >> iter 18658 (epoch  9): loss=0.05432
 2025-10-07 19:08:52,412 - INFO -marigold_trainer.py - train >> iter 18659 (epoch  9): loss=0.05955
 2025-10-07 19:09:07,077 - INFO -marigold_trainer.py - train >> iter 18660 (epoch  9): loss=0.05844
 2025-10-07 19:09:22,377 - INFO -marigold_trainer.py - train >> iter 18661 (epoch  9): loss=0.06477
 2025-10-07 19:09:38,353 - INFO -marigold_trainer.py - train >> iter 18662 (epoch  9): loss=0.06035
 2025-10-07 19:09:54,340 - INFO -marigold_trainer.py - train >> iter 18663 (epoch  9): loss=0.06100
 2025-10-07 19:10:09,658 - INFO -marigold_trainer.py - train >> iter 18664 (epoch  9): loss=0.05645
 2025-10-07 19:10:24,322 - INFO -marigold_trainer.py - train >> iter 18665 (epoch  9): loss=0.05200
 2025-10-07 19:10:41,585 - INFO -marigold_trainer.py - train >> iter 18666 (epoch  9): loss=0.05252
 2025-10-07 19:10:58,193 - INFO -marigold_trainer.py - train >> iter 18667 (epoch  9): loss=0.05896
 2025-10-07 19:11:13,965 - INFO -marigold_trainer.py - train >> iter 18668 (epoch  9): loss=0.05949
 2025-10-07 19:11:29,483 - INFO -marigold_trainer.py - train >> iter 18669 (epoch  9): loss=0.05963
 2025-10-07 19:11:44,800 - INFO -marigold_trainer.py - train >> iter 18670 (epoch  9): loss=0.04740
 2025-10-07 19:12:00,769 - INFO -marigold_trainer.py - train >> iter 18671 (epoch  9): loss=0.05446
 2025-10-07 19:12:16,091 - INFO -marigold_trainer.py - train >> iter 18672 (epoch  9): loss=0.05723
 2025-10-07 19:12:32,721 - INFO -marigold_trainer.py - train >> iter 18673 (epoch  9): loss=0.05621
 2025-10-07 19:12:48,043 - INFO -marigold_trainer.py - train >> iter 18674 (epoch  9): loss=0.05940
 2025-10-07 19:13:02,712 - INFO -marigold_trainer.py - train >> iter 18675 (epoch  9): loss=0.04571
 2025-10-07 19:13:19,324 - INFO -marigold_trainer.py - train >> iter 18676 (epoch  9): loss=0.05900
 2025-10-07 19:13:37,057 - INFO -marigold_trainer.py - train >> iter 18677 (epoch  9): loss=0.05148
 2025-10-07 19:13:53,234 - INFO -marigold_trainer.py - train >> iter 18678 (epoch  9): loss=0.06124
 2025-10-07 19:14:09,290 - INFO -marigold_trainer.py - train >> iter 18679 (epoch  9): loss=0.06773
 2025-10-07 19:14:25,266 - INFO -marigold_trainer.py - train >> iter 18680 (epoch  9): loss=0.05736
 2025-10-07 19:14:39,929 - INFO -marigold_trainer.py - train >> iter 18681 (epoch  9): loss=0.06177
 2025-10-07 19:14:54,576 - INFO -marigold_trainer.py - train >> iter 18682 (epoch  9): loss=0.05224
 2025-10-07 19:15:10,541 - INFO -marigold_trainer.py - train >> iter 18683 (epoch  9): loss=0.06259
 2025-10-07 19:15:26,314 - INFO -marigold_trainer.py - train >> iter 18684 (epoch  9): loss=0.05902
 2025-10-07 19:15:43,156 - INFO -marigold_trainer.py - train >> iter 18685 (epoch  9): loss=0.05897
 2025-10-07 19:15:59,138 - INFO -marigold_trainer.py - train >> iter 18686 (epoch  9): loss=0.06231
 2025-10-07 19:16:15,766 - INFO -marigold_trainer.py - train >> iter 18687 (epoch  9): loss=0.06082
 2025-10-07 19:16:32,400 - INFO -marigold_trainer.py - train >> iter 18688 (epoch  9): loss=0.05338
 2025-10-07 19:16:47,066 - INFO -marigold_trainer.py - train >> iter 18689 (epoch  9): loss=0.05730
 2025-10-07 19:17:02,369 - INFO -marigold_trainer.py - train >> iter 18690 (epoch  9): loss=0.05713
 2025-10-07 19:17:17,693 - INFO -marigold_trainer.py - train >> iter 18691 (epoch  9): loss=0.06255
 2025-10-07 19:17:33,021 - INFO -marigold_trainer.py - train >> iter 18692 (epoch  9): loss=0.06484
 2025-10-07 19:17:50,310 - INFO -marigold_trainer.py - train >> iter 18693 (epoch  9): loss=0.06019
 2025-10-07 19:18:07,596 - INFO -marigold_trainer.py - train >> iter 18694 (epoch  9): loss=0.06889
 2025-10-07 19:18:25,532 - INFO -marigold_trainer.py - train >> iter 18695 (epoch  9): loss=0.05741
 2025-10-07 19:18:40,856 - INFO -marigold_trainer.py - train >> iter 18696 (epoch  9): loss=0.05750
 2025-10-07 19:18:56,170 - INFO -marigold_trainer.py - train >> iter 18697 (epoch  9): loss=0.05955
 2025-10-07 19:19:11,491 - INFO -marigold_trainer.py - train >> iter 18698 (epoch  9): loss=0.06059
 2025-10-07 19:19:27,461 - INFO -marigold_trainer.py - train >> iter 18699 (epoch  9): loss=0.05475
 2025-10-07 19:19:42,118 - INFO -marigold_trainer.py - train >> iter 18700 (epoch  9): loss=0.05611
 2025-10-07 19:19:58,087 - INFO -marigold_trainer.py - train >> iter 18701 (epoch  9): loss=0.06201
 2025-10-07 19:20:13,418 - INFO -marigold_trainer.py - train >> iter 18702 (epoch  9): loss=0.05297
 2025-10-07 19:20:28,741 - INFO -marigold_trainer.py - train >> iter 18703 (epoch  9): loss=0.06255
 2025-10-07 19:20:44,063 - INFO -marigold_trainer.py - train >> iter 18704 (epoch  9): loss=0.05599
 2025-10-07 19:20:59,385 - INFO -marigold_trainer.py - train >> iter 18705 (epoch  9): loss=0.05824
 2025-10-07 19:21:14,715 - INFO -marigold_trainer.py - train >> iter 18706 (epoch  9): loss=0.05398
 2025-10-07 19:21:30,020 - INFO -marigold_trainer.py - train >> iter 18707 (epoch  9): loss=0.05554
 2025-10-07 19:21:45,993 - INFO -marigold_trainer.py - train >> iter 18708 (epoch  9): loss=0.05793
 2025-10-07 19:22:00,665 - INFO -marigold_trainer.py - train >> iter 18709 (epoch  9): loss=0.06035
 2025-10-07 19:22:15,316 - INFO -marigold_trainer.py - train >> iter 18710 (epoch  9): loss=0.05738
 2025-10-07 19:22:30,625 - INFO -marigold_trainer.py - train >> iter 18711 (epoch  9): loss=0.05580
 2025-10-07 19:22:46,617 - INFO -marigold_trainer.py - train >> iter 18712 (epoch  9): loss=0.05853
 2025-10-07 19:23:01,293 - INFO -marigold_trainer.py - train >> iter 18713 (epoch  9): loss=0.05566
 2025-10-07 19:23:17,246 - INFO -marigold_trainer.py - train >> iter 18714 (epoch  9): loss=0.05697
 2025-10-07 19:23:32,575 - INFO -marigold_trainer.py - train >> iter 18715 (epoch  9): loss=0.05800
 2025-10-07 19:23:47,900 - INFO -marigold_trainer.py - train >> iter 18716 (epoch  9): loss=0.06244
 2025-10-07 19:24:03,217 - INFO -marigold_trainer.py - train >> iter 18717 (epoch  9): loss=0.05514
 2025-10-07 19:24:19,840 - INFO -marigold_trainer.py - train >> iter 18718 (epoch  9): loss=0.05518
 2025-10-07 19:24:34,510 - INFO -marigold_trainer.py - train >> iter 18719 (epoch  9): loss=0.06068
 2025-10-07 19:24:51,125 - INFO -marigold_trainer.py - train >> iter 18720 (epoch  9): loss=0.05252
 2025-10-07 19:25:07,094 - INFO -marigold_trainer.py - train >> iter 18721 (epoch  9): loss=0.05422
 2025-10-07 19:25:21,765 - INFO -marigold_trainer.py - train >> iter 18722 (epoch  9): loss=0.06266
 2025-10-07 19:25:37,071 - INFO -marigold_trainer.py - train >> iter 18723 (epoch  9): loss=0.05543
 2025-10-07 19:25:52,388 - INFO -marigold_trainer.py - train >> iter 18724 (epoch  9): loss=0.05992
 2025-10-07 19:26:08,360 - INFO -marigold_trainer.py - train >> iter 18725 (epoch  9): loss=0.05753
 2025-10-07 19:26:23,685 - INFO -marigold_trainer.py - train >> iter 18726 (epoch  9): loss=0.06618
 2025-10-07 19:26:40,315 - INFO -marigold_trainer.py - train >> iter 18727 (epoch  9): loss=0.06459
 2025-10-07 19:26:55,635 - INFO -marigold_trainer.py - train >> iter 18728 (epoch  9): loss=0.05357
 2025-10-07 19:27:10,302 - INFO -marigold_trainer.py - train >> iter 18729 (epoch  9): loss=0.05731
 2025-10-07 19:27:26,910 - INFO -marigold_trainer.py - train >> iter 18730 (epoch  9): loss=0.05395
 2025-10-07 19:27:42,228 - INFO -marigold_trainer.py - train >> iter 18731 (epoch  9): loss=0.05740
 2025-10-07 19:27:58,652 - INFO -marigold_trainer.py - train >> iter 18732 (epoch  9): loss=0.05861
 2025-10-07 19:28:14,823 - INFO -marigold_trainer.py - train >> iter 18733 (epoch  9): loss=0.06012
 2025-10-07 19:28:30,792 - INFO -marigold_trainer.py - train >> iter 18734 (epoch  9): loss=0.05843
 2025-10-07 19:28:47,415 - INFO -marigold_trainer.py - train >> iter 18735 (epoch  9): loss=0.05873
 2025-10-07 19:29:02,743 - INFO -marigold_trainer.py - train >> iter 18736 (epoch  9): loss=0.05491
 2025-10-07 19:29:19,371 - INFO -marigold_trainer.py - train >> iter 18737 (epoch  9): loss=0.05870
 2025-10-07 19:29:35,358 - INFO -marigold_trainer.py - train >> iter 18738 (epoch  9): loss=0.06020
 2025-10-07 19:29:50,676 - INFO -marigold_trainer.py - train >> iter 18739 (epoch  9): loss=0.05509
 2025-10-07 19:30:06,449 - INFO -marigold_trainer.py - train >> iter 18740 (epoch  9): loss=0.05848
 2025-10-07 19:30:21,320 - INFO -marigold_trainer.py - train >> iter 18741 (epoch  9): loss=0.05238
 2025-10-07 19:30:37,934 - INFO -marigold_trainer.py - train >> iter 18742 (epoch  9): loss=0.06135
 2025-10-07 19:30:52,600 - INFO -marigold_trainer.py - train >> iter 18743 (epoch  9): loss=0.05830
 2025-10-07 19:31:07,252 - INFO -marigold_trainer.py - train >> iter 18744 (epoch  9): loss=0.05208
 2025-10-07 19:31:23,208 - INFO -marigold_trainer.py - train >> iter 18745 (epoch  9): loss=0.05594
 2025-10-07 19:31:40,491 - INFO -marigold_trainer.py - train >> iter 18746 (epoch  9): loss=0.05940
 2025-10-07 19:31:56,913 - INFO -marigold_trainer.py - train >> iter 18747 (epoch  9): loss=0.05478
 2025-10-07 19:32:11,783 - INFO -marigold_trainer.py - train >> iter 18748 (epoch  9): loss=0.05985
 2025-10-07 19:32:29,706 - INFO -marigold_trainer.py - train >> iter 18749 (epoch  9): loss=0.05587
 2025-10-07 19:32:45,483 - INFO -marigold_trainer.py - train >> iter 18750 (epoch  9): loss=0.05372
 2025-10-07 19:32:45,483 - INFO -marigold_trainer.py - save_checkpoint >> Saving checkpoint to: output/train_marigold/checkpoint/latest
 2025-10-07 19:32:45,483 - DEBUG -marigold_trainer.py - save_checkpoint >> Old checkpoint is backed up at: output/train_marigold/checkpoint/_old_latest
 2025-10-07 19:32:49,015 - INFO -marigold_trainer.py - save_checkpoint >> UNet is saved to: output/train_marigold/checkpoint/latest/unet
 2025-10-07 19:32:55,310 - INFO -marigold_trainer.py - save_checkpoint >> Trainer state is saved to: output/train_marigold/checkpoint/latest/trainer.ckpt
 2025-10-07 19:32:55,906 - DEBUG -marigold_trainer.py - save_checkpoint >> Old checkpoint backup is removed.
 2025-10-07 19:33:11,593 - INFO -marigold_trainer.py - train >> iter 18751 (epoch  9): loss=0.05625
 2025-10-07 19:33:26,919 - INFO -marigold_trainer.py - train >> iter 18752 (epoch  9): loss=0.05085
 2025-10-07 19:33:43,547 - INFO -marigold_trainer.py - train >> iter 18753 (epoch  9): loss=0.05897
 2025-10-07 19:33:58,881 - INFO -marigold_trainer.py - train >> iter 18754 (epoch  9): loss=0.05569
 2025-10-07 19:34:15,515 - INFO -marigold_trainer.py - train >> iter 18755 (epoch  9): loss=0.06358
 2025-10-07 19:34:32,798 - INFO -marigold_trainer.py - train >> iter 18756 (epoch  9): loss=0.05488
 2025-10-07 19:34:48,132 - INFO -marigold_trainer.py - train >> iter 18757 (epoch  9): loss=0.05609
 2025-10-07 19:35:03,463 - INFO -marigold_trainer.py - train >> iter 18758 (epoch  9): loss=0.05499
 2025-10-07 19:35:18,783 - INFO -marigold_trainer.py - train >> iter 18759 (epoch  9): loss=0.05136
 2025-10-07 19:35:34,111 - INFO -marigold_trainer.py - train >> iter 18760 (epoch  9): loss=0.05284
 2025-10-07 19:35:49,443 - INFO -marigold_trainer.py - train >> iter 18761 (epoch  9): loss=0.05821
 2025-10-07 19:36:04,773 - INFO -marigold_trainer.py - train >> iter 18762 (epoch  9): loss=0.05448
 2025-10-07 19:36:20,095 - INFO -marigold_trainer.py - train >> iter 18763 (epoch  9): loss=0.06231
 2025-10-07 19:36:34,762 - INFO -marigold_trainer.py - train >> iter 18764 (epoch  9): loss=0.05718
 2025-10-07 19:36:49,411 - INFO -marigold_trainer.py - train >> iter 18765 (epoch  9): loss=0.05618
 2025-10-07 19:37:04,712 - INFO -marigold_trainer.py - train >> iter 18766 (epoch  9): loss=0.05824
 2025-10-07 19:37:19,384 - INFO -marigold_trainer.py - train >> iter 18767 (epoch  9): loss=0.06293
 2025-10-07 19:37:34,681 - INFO -marigold_trainer.py - train >> iter 18768 (epoch  9): loss=0.05739
 2025-10-07 19:37:52,605 - INFO -marigold_trainer.py - train >> iter 18769 (epoch  9): loss=0.05376
 2025-10-07 19:38:08,577 - INFO -marigold_trainer.py - train >> iter 18770 (epoch  9): loss=0.05617
 2025-10-07 19:38:25,101 - INFO -marigold_trainer.py - train >> iter 18771 (epoch  9): loss=0.06546
 2025-10-07 19:38:41,280 - INFO -marigold_trainer.py - train >> iter 18772 (epoch  9): loss=0.05679
 2025-10-07 19:38:57,257 - INFO -marigold_trainer.py - train >> iter 18773 (epoch  9): loss=0.06567
 2025-10-07 19:39:12,579 - INFO -marigold_trainer.py - train >> iter 18774 (epoch  9): loss=0.05211
 2025-10-07 19:39:27,252 - INFO -marigold_trainer.py - train >> iter 18775 (epoch  9): loss=0.05974
 2025-10-07 19:39:42,358 - INFO -marigold_trainer.py - train >> iter 18776 (epoch  9): loss=0.05204
 2025-10-07 19:39:57,225 - INFO -marigold_trainer.py - train >> iter 18777 (epoch  9): loss=0.04982
 2025-10-07 19:40:13,178 - INFO -marigold_trainer.py - train >> iter 18778 (epoch  9): loss=0.05686
 2025-10-07 19:40:28,500 - INFO -marigold_trainer.py - train >> iter 18779 (epoch  9): loss=0.06145
 2025-10-07 19:40:44,470 - INFO -marigold_trainer.py - train >> iter 18780 (epoch  9): loss=0.05413
 2025-10-07 19:41:00,443 - INFO -marigold_trainer.py - train >> iter 18781 (epoch  9): loss=0.05822
 2025-10-07 19:41:17,079 - INFO -marigold_trainer.py - train >> iter 18782 (epoch  9): loss=0.06324
 2025-10-07 19:41:33,044 - INFO -marigold_trainer.py - train >> iter 18783 (epoch  9): loss=0.06159
 2025-10-07 19:41:47,713 - INFO -marigold_trainer.py - train >> iter 18784 (epoch  9): loss=0.05445
 2025-10-07 19:42:03,669 - INFO -marigold_trainer.py - train >> iter 18785 (epoch  9): loss=0.06458
 2025-10-07 19:42:20,293 - INFO -marigold_trainer.py - train >> iter 18786 (epoch  9): loss=0.05844
 2025-10-07 19:42:36,273 - INFO -marigold_trainer.py - train >> iter 18787 (epoch  9): loss=0.05510
 2025-10-07 19:42:51,596 - INFO -marigold_trainer.py - train >> iter 18788 (epoch  9): loss=0.05935
 2025-10-07 19:43:06,914 - INFO -marigold_trainer.py - train >> iter 18789 (epoch  9): loss=0.05300
 2025-10-07 19:43:22,241 - INFO -marigold_trainer.py - train >> iter 18790 (epoch  9): loss=0.06130
 2025-10-07 19:43:38,223 - INFO -marigold_trainer.py - train >> iter 18791 (epoch  9): loss=0.06971
 2025-10-07 19:43:54,851 - INFO -marigold_trainer.py - train >> iter 18792 (epoch  9): loss=0.06378
 2025-10-07 19:44:10,171 - INFO -marigold_trainer.py - train >> iter 18793 (epoch  9): loss=0.06654
 2025-10-07 19:44:26,144 - INFO -marigold_trainer.py - train >> iter 18794 (epoch  9): loss=0.05985
 2025-10-07 19:44:43,223 - INFO -marigold_trainer.py - train >> iter 18795 (epoch  9): loss=0.05338
 2025-10-07 19:44:58,754 - INFO -marigold_trainer.py - train >> iter 18796 (epoch  9): loss=0.05252
 2025-10-07 19:45:15,390 - INFO -marigold_trainer.py - train >> iter 18797 (epoch  9): loss=0.05946
 2025-10-07 19:45:30,714 - INFO -marigold_trainer.py - train >> iter 18798 (epoch  9): loss=0.05965
 2025-10-07 19:45:47,150 - INFO -marigold_trainer.py - train >> iter 18799 (epoch  9): loss=0.06120
 2025-10-07 19:46:03,771 - INFO -marigold_trainer.py - train >> iter 18800 (epoch  9): loss=0.05725
 2025-10-07 19:46:19,948 - INFO -marigold_trainer.py - train >> iter 18801 (epoch  9): loss=0.05069
 2025-10-07 19:46:35,279 - INFO -marigold_trainer.py - train >> iter 18802 (epoch  9): loss=0.06467
 2025-10-07 19:46:50,603 - INFO -marigold_trainer.py - train >> iter 18803 (epoch  9): loss=0.05827
 2025-10-07 19:47:07,224 - INFO -marigold_trainer.py - train >> iter 18804 (epoch  9): loss=0.06196
 2025-10-07 19:47:22,547 - INFO -marigold_trainer.py - train >> iter 18805 (epoch  9): loss=0.06239
 2025-10-07 19:47:37,863 - INFO -marigold_trainer.py - train >> iter 18806 (epoch  9): loss=0.05944
 2025-10-07 19:47:53,183 - INFO -marigold_trainer.py - train >> iter 18807 (epoch  9): loss=0.05883
 2025-10-07 19:48:08,500 - INFO -marigold_trainer.py - train >> iter 18808 (epoch  9): loss=0.05224
 2025-10-07 19:48:23,923 - INFO -marigold_trainer.py - train >> iter 18809 (epoch  9): loss=0.05385
"""

iterations = []
losses = []

pattern = r'iter\s+(\d+).*?loss=([\d.]+)'
matches = re.findall(pattern, log_data)

for match in matches:
    iterations.append(int(match[0]))
    losses.append(float(match[1]))

plt.figure(figsize=(15, 8))
plt.plot(iterations, losses, linewidth=1, alpha=0.7)
plt.title('Training Loss Over Iterations', fontsize=16, fontweight='bold')
plt.xlabel('Iteration', fontsize=12)
plt.ylabel('Loss', fontsize=12)
plt.grid(True, alpha=0.3)

window_size = 50
if len(losses) > window_size:
    moving_avg = []
    for i in range(len(losses) - window_size + 1):
        window = losses[i:i + window_size]
        moving_avg.append(sum(window) / len(window))
    
    plt.plot(iterations[window_size-1:], moving_avg, 
             color='red', linewidth=2, label=f'{window_size}-iter Moving Average')
    plt.legend()

plt.tight_layout()
plt.show()

# Print some info
print(f"Total iterations: {len(iterations)}")
print(f"Loss range: {min(losses):.4f} - {max(losses):.4f}")
print(f"Average loss: {sum(losses)/len(losses):.4f}")
print(f"Final loss: {losses[-1]:.4f}")